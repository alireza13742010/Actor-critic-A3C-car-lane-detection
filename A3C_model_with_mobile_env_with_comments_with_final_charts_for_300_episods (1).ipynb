{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ***Installing the essential libraries***"
      ],
      "metadata": {
        "id": "XWvGJLOCr9Zi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipython\n",
        "!pip install redis\n",
        "!pip install statistics\n",
        "!pip install gym\n",
        "!pip install typing\n",
        "!pip install shapely\n",
        "!pip install svgpath2mpl\n",
        "!pip install abcplus\n",
        "!pip install pygame"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vza9N-ncs4wl",
        "outputId": "9b981c7f-97d8-4354-b6ce-fa8bffedf558"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (7.34.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython) (75.1.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython) (0.2.13)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-5 (attachment_entry):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/debugpy/server/api.py\", line 237, in listen\n",
            "    sock, _ = endpoints_listener.accept()\n",
            "  File \"/usr/lib/python3.10/socket.py\", line 293, in accept\n",
            "    fd, addr = self._accept()\n",
            "TimeoutError: timed out\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/colab/_debugpy.py\", line 52, in attachment_entry\n",
            "    debugpy.listen(_dap_port)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/debugpy/public_api.py\", line 31, in wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/debugpy/server/api.py\", line 143, in debug\n",
            "    log.reraise_exception(\"{0}() failed:\", func.__name__, level=\"info\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/debugpy/server/api.py\", line 141, in debug\n",
            "    return func(address, settrace_kwargs, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/debugpy/server/api.py\", line 251, in listen\n",
            "    raise RuntimeError(\"timed out waiting for adapter to connect\")\n",
            "RuntimeError: timed out waiting for adapter to connect\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: redis in /usr/local/lib/python3.10/dist-packages (4.1.1)\n",
            "Requirement already satisfied: deprecated>=1.2.3 in /usr/local/lib/python3.10/dist-packages (from redis) (1.2.14)\n",
            "Requirement already satisfied: packaging>=20.4 in /usr/local/lib/python3.10/dist-packages (from redis) (24.1)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.3->redis) (1.16.0)\n",
            "Requirement already satisfied: statistics in /usr/local/lib/python3.10/dist-packages (1.0.3.5)\n",
            "Requirement already satisfied: docutils>=0.3 in /usr/local/lib/python3.10/dist-packages (from statistics) (0.18.1)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.10/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym) (3.1.0)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym) (0.0.8)\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.10/dist-packages (3.7.4.3)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.10/dist-packages (2.0.6)\n",
            "Requirement already satisfied: numpy<3,>=1.14 in /usr/local/lib/python3.10/dist-packages (from shapely) (1.26.4)\n",
            "Requirement already satisfied: svgpath2mpl in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from svgpath2mpl) (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from svgpath2mpl) (3.7.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->svgpath2mpl) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->svgpath2mpl) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->svgpath2mpl) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->svgpath2mpl) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->svgpath2mpl) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->svgpath2mpl) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->svgpath2mpl) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->svgpath2mpl) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->svgpath2mpl) (1.16.0)\n",
            "Requirement already satisfied: abcplus in /usr/local/lib/python3.10/dist-packages (0.1.0)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.10/dist-packages (2.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib==3.7.3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "MVY7taUaxeDS",
        "outputId": "48d69534-e4fa-480f-f635-37daed0c50ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting matplotlib==3.7.3\n",
            "  Downloading matplotlib-3.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.3) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.3) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.3) (1.4.7)\n",
            "Requirement already satisfied: numpy<2,>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.3) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.3) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.3) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.3) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.3) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib==3.7.3) (1.16.0)\n",
            "Downloading matplotlib-3.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: matplotlib\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.8.0\n",
            "    Uninstalling matplotlib-3.8.0:\n",
            "      Successfully uninstalled matplotlib-3.8.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "plotnine 0.14.0 requires matplotlib>=3.8.0, but you have matplotlib 3.7.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed matplotlib-3.7.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              },
              "id": "af9c4734124341d3918216f621ba4315"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib\n",
        "print(matplotlib.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIPUBAn4x-WT",
        "outputId": "43132fe7-779a-47ad-9dd5-7debadaea258"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.7.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.image as mpimg\n"
      ],
      "metadata": {
        "id": "vdj0vm1ox8fL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ricsdl==3.1.1\n",
        "!pip install pandas>=1.1.3\n",
        "!pip install joblib>=0.3.2\n",
        "!pip install Scikit-learn>=0.21\n",
        "!pip install schedule>=0.0.0\n",
        "!pip install influxdb\n",
        "!pip install numpy >= 1.16.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaXD6AYRrn_U",
        "outputId": "0364169b-94c6-44dd-9398-cbc2444973db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ricsdl==3.1.1 in /usr/local/lib/python3.10/dist-packages (3.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from ricsdl==3.1.1) (75.1.0)\n",
            "Requirement already satisfied: redis==4.1.1 in /usr/local/lib/python3.10/dist-packages (from ricsdl==3.1.1) (4.1.1)\n",
            "Requirement already satisfied: hiredis==2.0.0 in /usr/local/lib/python3.10/dist-packages (from ricsdl==3.1.1) (2.0.0)\n",
            "Requirement already satisfied: deprecated>=1.2.3 in /usr/local/lib/python3.10/dist-packages (from redis==4.1.1->ricsdl==3.1.1) (1.2.14)\n",
            "Requirement already satisfied: packaging>=20.4 in /usr/local/lib/python3.10/dist-packages (from redis==4.1.1->ricsdl==3.1.1) (24.1)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.3->redis==4.1.1->ricsdl==3.1.1) (1.16.0)\n",
            "Collecting influxdb\n",
            "  Downloading influxdb-5.3.2-py2.py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from influxdb) (2.8.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from influxdb) (2024.2)\n",
            "Requirement already satisfied: requests>=2.17.0 in /usr/local/lib/python3.10/dist-packages (from influxdb) (2.32.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from influxdb) (1.16.0)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from influxdb) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.17.0->influxdb) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.17.0->influxdb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.17.0->influxdb) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.17.0->influxdb) (2024.8.30)\n",
            "Downloading influxdb-5.3.2-py2.py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.4/79.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: influxdb\n",
            "Successfully installed influxdb-5.3.2\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement 1.16.2 (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for 1.16.2\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Importing the essential libraries***"
      ],
      "metadata": {
        "id": "Niwx1jJfsNnQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "import math\n",
        "import torch.multiprocessing as mp\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import gym\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import deque\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statistics\n",
        "from statistics import mean\n",
        "import IPython\n",
        "from IPython import display\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "kjkWZm-SrwTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import schedule\n",
        "import datetime\n",
        "from zipfile import ZipFile\n",
        "import json\n",
        "from os import getenv\n"
      ],
      "metadata": {
        "id": "MRQSrwIf16IW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fd1969f-4038-4eac-c1a1-1622e79868c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Adding the path to the envionment for creating the mobile network***"
      ],
      "metadata": {
        "id": "14fSBqWOsUCS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "YqnBhgX_JomK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Warning***\n",
        " **please change the path based on your environment locations**"
      ],
      "metadata": {
        "id": "6xbeUnHZs-Qd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sys.path.append('/content/Reinforcement-Learning-Base-xApp/mr')\n"
      ],
      "metadata": {
        "id": "_yzwOwqLz344"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Cloning the base for the environment and prviding the libraries for it***"
      ],
      "metadata": {
        "id": "sZxvQAkEsrso"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AALhD60LrT5e",
        "outputId": "8478e2e0-b466-448b-a903-58a1b2c211b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Reinforcement-Learning-Base-xApp'...\n",
            "remote: Enumerating objects: 189, done.\u001b[K\n",
            "remote: Counting objects: 100% (189/189), done.\u001b[K\n",
            "remote: Compressing objects: 100% (120/120), done.\u001b[K\n",
            "remote: Total 189 (delta 69), reused 179 (delta 63), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (189/189), 14.59 MiB | 14.35 MiB/s, done.\n",
            "Resolving deltas: 100% (69/69), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/mrkouchaki/Reinforcement-Learning-Base-xApp.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/Reinforcement-Learning-Base-xApp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nDStSjt0ibb",
        "outputId": "d309c4c0-8371-452a-be04-a93ccf83b0b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Reinforcement-Learning-Base-xApp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KE1hiK87rk5K",
        "outputId": "39a9ecae-d36f-4c79-f655-55165ef7f554"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "container-tag.yaml  \u001b[0m\u001b[01;34minit\u001b[0m/        \u001b[01;34mmr\u001b[0m/                    README.md         setup.py\n",
            "Dockerfile          LICENSE.txt  mr10-config-file.json  \u001b[01;34mrelease\u001b[0m/\n",
            "INFO.yaml           local.rt     mr10-onboard.url       rmr-version.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Importing the essential libraries for the environment***"
      ],
      "metadata": {
        "id": "b2b0cNSms16t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from mobile_env.handlers.central import MComCentralHandler\n",
        "from mobile_env.core.base import MComCore\n",
        "from mobile_env.core.entities import BaseStation, UserEquipment\n",
        "from mobile_env.scenarios.small import MComSmall\n",
        "import mobile_env"
      ],
      "metadata": {
        "id": "-qtizw2B02_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Importing the essential libraries for the model.***\n",
        "\n",
        "\n",
        "1.   For training A2C model we have used Keras\n",
        "2.   For training AC model we have used pytorch\n",
        "\n"
      ],
      "metadata": {
        "id": "BdlfK4MktKIB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from influxdb import DataFrameClient\n",
        "import datetime\n",
        "import tensorflow as tf\n",
        "import gym\n",
        "import statistics\n",
        "from statistics import mean\n",
        "import IPython\n",
        "from IPython import display\n",
        "import os\n",
        "import sys\n",
        "import mobile_env\n",
        "from mobile_env.handlers.central import MComCentralHandler\n",
        "from mobile_env.core.base import MComCore\n",
        "from mobile_env.core.entities import BaseStation, UserEquipment\n",
        "# predefined small scenarios\n",
        "from mobile_env.scenarios.small import MComSmall\n",
        "import logging\n",
        "from numpy import zeros, newaxis\n",
        "from db import DATABASE, DUMMY"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PWWFmQ42eI-",
        "outputId": "bda2d92d-1560-474c-c0eb-afb1e6f741f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "///////////enter class DBCreatDrop/////////////\n",
            "///////////enter class DATABASE(object)////////////////////\n",
            "////////enter class Error in db////////////////\n",
            "////////enter class NoDataError in db//////////////////\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Specifying the shape of the input state and size for teh action***"
      ],
      "metadata": {
        "id": "21oObX2RvQus"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MComSmall.default_config()\n",
        "\n",
        "env = gym.make(\"mobile-small-central-v0\")\n",
        "xapp = None\n",
        "pos = 0\n",
        "RAN_data = None\n",
        "rmr_xapp = None\n",
        "\n",
        "num_states = 7\n",
        "print(\"Size of State Space ->  {}\".format(num_states))\n",
        "num_whole_states = 35\n",
        "print(\"Size of Whole State Space ->  {}\".format(num_whole_states))\n",
        "num_actions = 4\n",
        "print(\"Size of Action Space ->  {}\".format(num_actions))\n",
        "num_ues = 5\n",
        "upper_bound = env.NUM_STATIONS\n",
        "lower_bound = 0\n",
        "print(\"Max Value of Action ->  {}\".format(upper_bound))\n",
        "print(\"Min Value of Action ->  {}\".format(lower_bound))\n",
        "# Configuration parameters for the whole setup\n",
        "gamma = 0.99  # Discount factor for past rewards\n",
        "max_steps_per_episode = 300000\n",
        "eps = np.finfo(np.float32).eps.item()  # Smallest number such that 1.0 + eps != 1.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aw7znGwn4Ckj",
        "outputId": "f862f0af-81d0-456e-e9b1-2ff40db1990e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of State Space ->  7\n",
            "Size of Whole State Space ->  35\n",
            "Size of Action Space ->  4\n",
            "Max Value of Action ->  3\n",
            "Min Value of Action ->  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Model architecture as the agent for A2C model***"
      ],
      "metadata": {
        "id": "nr0CsP0-vYfD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# num_inputs = 4\n",
        "# num_actions = 2\n",
        "num_hidden1 = 400\n",
        "num_hidden2 = 200\n",
        "\n",
        "inputs = layers.Input(shape=(num_states,))\n",
        "common1 = layers.Dense(num_hidden1, activation=\"relu\")(inputs)\n",
        "common2 = layers.Dense(num_hidden2, activation=\"relu\")(common1)\n",
        "action = layers.Dense(num_actions, activation=\"softmax\")(common2)\n",
        "critic = layers.Dense(1, activation=\"linear\")(common2)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=[action, critic])"
      ],
      "metadata": {
        "id": "uXNqVb2u4FSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Demonstarte the summary for the model***"
      ],
      "metadata": {
        "id": "4UZkQwynvfk_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('model.summary in get_actor',model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "xo9FIXQD4hUF",
        "outputId": "46c105fc-120b-471a-8871-48a9126c8ab6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m)            │          \u001b[38;5;34m3,200\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │         \u001b[38;5;34m80,200\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │            \u001b[38;5;34m804\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m201\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">3,200</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">80,200</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">804</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">201</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m84,405\u001b[0m (329.71 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">84,405</span> (329.71 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m84,405\u001b[0m (329.71 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">84,405</span> (329.71 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model.summary in get_actor None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.AdamW(learning_rate=0.00001,weight_decay=0.004)\n",
        "huber_loss = keras.losses.Huber()\n",
        "action_probs_history = []\n",
        "actions_probs_history = []\n",
        "action_probs_history_test = []\n",
        "critic_value_history = []\n",
        "critic_value_history_test = []\n",
        "rewards_history = []\n",
        "reward_history_for_plot = []\n",
        "running_rewards_history = []\n",
        "episode_reward_history = []\n",
        "running_reward = 0\n",
        "episode_count = 0\n",
        "iteration = 1000000\n",
        "utility_history = []\n",
        "episode_utility = 0\n",
        "episode_utility_history = []\n",
        "mean_utility_history = []\n",
        "actor_loss_history = []\n",
        "critic_loss_history = []\n",
        "critic_loss_history_test = []\n",
        "loss_value_history_whole = []\n",
        "while True:  # Run until solved\n",
        "    state = env.reset()\n",
        "    print('tensor state in while True=', state)\n",
        "    episode_reward = 0\n",
        "    with tf.GradientTape() as tape:\n",
        "        for timestep in range(1, max_steps_per_episode):\n",
        "            print('timestep=', timestep)\n",
        "            env.render(); #Adding this line would show the attempts\n",
        "            # of the agent in a pop up window.\n",
        "            prev_state = state\n",
        "            state_per_user = [0]*num_states\n",
        "            for index in range (num_ues):\n",
        "                state_per_user[index] = state[(index*num_states):((index*num_states)+num_states)]\n",
        "            state_all_users = []\n",
        "            for i in range (num_ues):\n",
        "                state_all_users.append(state_per_user[:][i])\n",
        "            #print('state_all_users=', state_all_users)\n",
        "            state_all_users = tf.convert_to_tensor(state_all_users)\n",
        "            action_probs, critic_value = model(state_all_users)\n",
        "            critic_value_history.append(critic_value[:, 0])\n",
        "            critic_value_history_test.append(critic_value)\n",
        "            #print(\"action probability is: \", action_probs)\n",
        "            actions = [0]*num_ues\n",
        "            action_probs_per_action = []\n",
        "            p_whole = []\n",
        "            for i in range(num_ues):\n",
        "\n",
        "                action = np.random.choice(num_actions, p=np.squeeze(action_probs[i]))\n",
        "                actions[i]=action\n",
        "                action_probs_per_action.append(action_probs[i, action])\n",
        "                action_probs_history.append(tf.math.log(action_probs[i, action]))\n",
        "            action_probs_history_test.append(tf.math.log(action_probs_per_action))\n",
        "            actions_probs_history.append(action_probs_history)\n",
        "            actions_tensor = tf.convert_to_tensor(actions)\n",
        "            #print('actions_tensor=', actions_tensor)\n",
        "            actions = np.asarray(actions, dtype=np.int64)\n",
        "            #print(\"*******The defined action length is *******:\", actions)\n",
        "            state, reward, done, _ = env.step(actions)\n",
        "            #print(\"*******The defined state length is *******:\", state)\n",
        "            state = np.array(state, dtype='float32')\n",
        "            #print('reward:(actions)=', reward)\n",
        "            #print('done=env.step(actions)=', done)\n",
        "            rewards_history.append(reward)\n",
        "            reward_history_for_plot.append(reward)\n",
        "            episode_reward += reward\n",
        "            episode_reward_history.append(episode_reward)\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "        print('if done break out of loop')\n",
        "        iteration +=1\n",
        "        scalar_results_1 = env.monitor.load_results()\n",
        "        mean_utility_history.append(scalar_results_1['mean utility'].tolist())\n",
        "        running_reward = 0.05 * episode_reward + (1 - 0.05) * running_reward\n",
        "        running_rewards_history.append(running_reward)\n",
        "        returns = []\n",
        "        discounted_sum = 0\n",
        "        for r in rewards_history[::-1]:\n",
        "            discounted_sum = r + gamma * discounted_sum\n",
        "            returns.insert(0, discounted_sum)\n",
        "        returns = np.array(returns)\n",
        "        returns = (returns - np.mean(returns)) / (np.std(returns) + eps)\n",
        "        returns = returns.tolist()\n",
        "        history = zip(action_probs_history_test, critic_value_history, returns, critic_value_history_test)\n",
        "        actor_losses = []\n",
        "        critic_losses = []\n",
        "        critic_losses_test = []\n",
        "        for log_prob, value, ret, value_test in history:\n",
        "            diff = ret - value\n",
        "            actor_losses.append(-log_prob*diff)  # actor loss\n",
        "            actor_loss_history.append(actor_losses)\n",
        "            critic_losses.append(\n",
        "                huber_loss(tf.expand_dims(value, 0), tf.expand_dims(ret, 0))\n",
        "            )\n",
        "            critic_loss_history.append(critic_losses)\n",
        "        # Backpropagation\n",
        "        loss_value_history = []\n",
        "        grads_history = []\n",
        "        #print('actor_losses=', actor_losses)\n",
        "        #print('critic_losses=', critic_losses)\n",
        "        print('sum(actor_losses)=', sum(actor_losses))\n",
        "        print('sum(critic_losses)=', sum(critic_losses))\n",
        "        loss_value = sum(actor_losses) + sum(critic_losses)\n",
        "        print('loss_value = sum(actor_losses) + sum(critic_losses)=', loss_value)\n",
        "        loss_value_history.append(loss_value)\n",
        "        loss_value_history_whole.append(loss_value)\n",
        "        print('loss_value for backprpagation=', loss_value)\n",
        "        grads = tape.gradient(loss_value, model.trainable_variables)\n",
        "        #print('grads = tape.gradient(loss_value, model.trainable_variables)=', grads)\n",
        "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "        grads_history.append(grads)\n",
        "        print('iteration=', iteration)\n",
        "        action_probs_history.clear()\n",
        "        critic_value_history.clear()\n",
        "        rewards_history.clear()\n",
        "    episode_count += 1\n",
        "    print(\"The calculated reward: \", running_reward)\n",
        "    print('episode_count += 1=', episode_count)\n",
        "    if episode_count % 10 == 0:\n",
        "        template = \"running reward: {:.2f} at episode {}\"\n",
        "        print(template.format(running_reward, episode_count))\n",
        "    scalar_results_2 = env.monitor.load_results()\n",
        "    if episode_count > 1:  # Condition to consider the task solved\n",
        "        print(\"Solved at episode {}!\".format(episode_count))\n",
        "        print(\"Solved at episode {}!\".format(episode_count))\n",
        "        print(\"Solved at episode {}!\".format(episode_count))\n",
        "        scalar_results_2 = env.monitor.load_results()\n",
        "\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZkBu7Aomh04",
        "outputId": "a51a187a-b0ca-4cbe-99fe-a63602463aa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor state in while True= [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  1.0000000e+00\n",
            "  6.4833045e-01  8.1199668e-02 -1.0000000e+00  0.0000000e+00\n",
            "  0.0000000e+00  0.0000000e+00  1.0000000e+00  1.1800351e-01\n",
            "  3.8437236e-02 -1.0000000e+00  0.0000000e+00  0.0000000e+00\n",
            "  0.0000000e+00  3.8156830e-02  1.0000000e+00  2.7852383e-01\n",
            " -1.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
            "  1.0000000e+00  4.5251416e-04  9.1455171e-05 -1.0000000e+00\n",
            "  0.0000000e+00  0.0000000e+00  0.0000000e+00  1.0000000e+00\n",
            "  1.9392401e-01  3.2648811e-01 -1.0000000e+00]\n",
            "timestep= 1\n",
            "timestep= 2\n",
            "timestep= 3\n",
            "timestep= 4\n",
            "if done break out of loop\n",
            "scalar_results=    number connections  number connected  mean utility  mean datarate\n",
            "0                   1                 1    -12.000000     827.431330\n",
            "1                   4                 3     -4.356892     571.436457\n",
            "2                   2                 2     -8.229509    1943.985492\n",
            "3                   3                 3     -3.602935   13445.161320\n",
            "scalar_results.index.names=            number connections  number connected  mean utility  mean datarate\n",
            "Time Step                                                                   \n",
            "0                           1                 1    -12.000000     827.431330\n",
            "1                           4                 3     -4.356892     571.436457\n",
            "2                           2                 2     -8.229509    1943.985492\n",
            "3                           3                 3     -3.602935   13445.161320\n",
            "sum(actor_losses)= tf.Tensor([-1.2897106  -1.7012334  -0.29829204 -0.1985197  -1.1590118 ], shape=(5,), dtype=float32)\n",
            "sum(critic_losses)= tf.Tensor(1.6643033, shape=(), dtype=float32)\n",
            "loss_value = sum(actor_losses) + sum(critic_losses)= tf.Tensor([ 0.37459266 -0.03693008  1.3660113   1.4657836   0.50529146], shape=(5,), dtype=float32)\n",
            "loss_value for backprpagation= tf.Tensor([ 0.37459266 -0.03693008  1.3660113   1.4657836   0.50529146], shape=(5,), dtype=float32)\n",
            "iteration= 1000001\n",
            "The calculated reward:  -0.0704733389974215\n",
            "episode_count += 1= 1\n",
            "scalar_results=    number connections  number connected  mean utility  mean datarate\n",
            "0                   1                 1    -12.000000     827.431330\n",
            "1                   4                 3     -4.356892     571.436457\n",
            "2                   2                 2     -8.229509    1943.985492\n",
            "3                   3                 3     -3.602935   13445.161320\n",
            "scalar_results.index.names=            number connections  number connected  mean utility  mean datarate\n",
            "Time Step                                                                   \n",
            "0                           1                 1    -12.000000     827.431330\n",
            "1                           4                 3     -4.356892     571.436457\n",
            "2                           2                 2     -8.229509    1943.985492\n",
            "3                           3                 3     -3.602935   13445.161320\n",
            "tensor state in while True= [ 0.          0.          0.          0.06776293  1.          0.88979834\n",
            " -1.          0.          0.          0.          1.          0.46016175\n",
            "  0.10023493 -1.          0.          0.          0.          0.577236\n",
            "  0.23644413  1.         -1.          0.          0.          0.\n",
            "  0.01249796  0.02113287  1.         -1.          0.          0.\n",
            "  0.          1.          0.21263906  0.41242316 -1.        ]\n",
            "timestep= 1\n",
            "timestep= 2\n",
            "timestep= 3\n",
            "timestep= 4\n",
            "timestep= 5\n",
            "timestep= 6\n",
            "timestep= 7\n",
            "timestep= 8\n",
            "timestep= 9\n",
            "timestep= 10\n",
            "timestep= 11\n",
            "timestep= 12\n",
            "timestep= 13\n",
            "timestep= 14\n",
            "timestep= 15\n",
            "timestep= 16\n",
            "timestep= 17\n",
            "timestep= 18\n",
            "timestep= 19\n",
            "timestep= 20\n",
            "timestep= 21\n",
            "timestep= 22\n",
            "timestep= 23\n",
            "timestep= 24\n",
            "timestep= 25\n",
            "timestep= 26\n",
            "timestep= 27\n",
            "timestep= 28\n",
            "timestep= 29\n",
            "timestep= 30\n",
            "timestep= 31\n",
            "timestep= 32\n",
            "timestep= 33\n",
            "timestep= 34\n",
            "timestep= 35\n",
            "timestep= 36\n",
            "timestep= 37\n",
            "timestep= 38\n",
            "timestep= 39\n",
            "timestep= 40\n",
            "timestep= 41\n",
            "timestep= 42\n",
            "timestep= 43\n",
            "timestep= 44\n",
            "timestep= 45\n",
            "timestep= 46\n",
            "timestep= 47\n",
            "timestep= 48\n",
            "timestep= 49\n",
            "timestep= 50\n",
            "if done break out of loop\n",
            "scalar_results=     number connections  number connected  mean utility  mean datarate\n",
            "0                    1                 1    -16.018496       0.978931\n",
            "1                    1                 1    -16.028623       0.967584\n",
            "2                    2                 1    -15.388164       2.022636\n",
            "3                    2                 1    -15.334882       2.150597\n",
            "4                    2                 2    -11.725134       1.353492\n",
            "5                    2                 2    -11.520381       1.552607\n",
            "6                    3                 2    -10.632685       2.237731\n",
            "7                    3                 2    -10.560972       2.337874\n",
            "8                    1                 1    -15.306069       2.223134\n",
            "9                    3                 2    -10.220372       2.891323\n",
            "10                   2                 2    -10.331855       4.277454\n",
            "11                   2                 2    -10.204350       5.147724\n",
            "12                   3                 2     -9.795318       3.739120\n",
            "13                   2                 2     -9.791598       4.044565\n",
            "14                   2                 1    -14.513455       5.536976\n",
            "15                   2                 1    -14.370313       6.528955\n",
            "16                   2                 1    -14.282746       7.221490\n",
            "17                   1                 1    -16.345100       0.672125\n",
            "18                   2                 2    -10.073473       7.107019\n",
            "19                   2                 2    -10.766196       7.785403\n",
            "20                   2                 2    -13.559419       0.438118\n",
            "21                   3                 3     -7.182889       5.388932\n",
            "22                   1                 1    -13.749856      13.337430\n",
            "23                   2                 2     -8.348287       8.505922\n",
            "24                   2                 2    -10.759055       6.129465\n",
            "25                   3                 3     -7.451180       3.907934\n",
            "26                   3                 2     -9.660183      19.934187\n",
            "27                   3                 3     -4.928613       7.898534\n",
            "28                   4                 3     -6.872500       6.242111\n",
            "29                   4                 3     -6.768213       6.798873\n",
            "30                   4                 4     -4.027056       4.770171\n",
            "31                   4                 3     -6.012601       9.742601\n",
            "32                   5                 4     -4.497469       5.213825\n",
            "33                   2                 2     -8.634618      12.270807\n",
            "34                   2                 2    -10.781014      10.960742\n",
            "35                   3                 2     -8.886996      11.463787\n",
            "36                   3                 2    -10.364663      16.421953\n",
            "37                   4                 3     -5.379963       5.605017\n",
            "38                   4                 3     -5.461580       5.251211\n",
            "39                   4                 3     -7.119475       3.702596\n",
            "40                   3                 3     -7.004695       6.232824\n",
            "41                   5                 4     -4.547340       1.674506\n",
            "42                   6                 4     -4.782774       1.372225\n",
            "43                   6                 3     -7.891548       1.538216\n",
            "44                   4                 3     -8.343300       1.838978\n",
            "45                   3                 3     -7.463667       1.643255\n",
            "46                   3                 2    -11.183839       1.972466\n",
            "47                   2                 2    -11.818742       1.544334\n",
            "48                   5                 4     -4.844511       0.985387\n",
            "49                   8                 5     -2.147724       0.715164\n",
            "scalar_results.index.names=            number connections  number connected  mean utility  mean datarate\n",
            "Time Step                                                                   \n",
            "0                           1                 1    -16.018496       0.978931\n",
            "1                           1                 1    -16.028623       0.967584\n",
            "2                           2                 1    -15.388164       2.022636\n",
            "3                           2                 1    -15.334882       2.150597\n",
            "4                           2                 2    -11.725134       1.353492\n",
            "5                           2                 2    -11.520381       1.552607\n",
            "6                           3                 2    -10.632685       2.237731\n",
            "7                           3                 2    -10.560972       2.337874\n",
            "8                           1                 1    -15.306069       2.223134\n",
            "9                           3                 2    -10.220372       2.891323\n",
            "10                          2                 2    -10.331855       4.277454\n",
            "11                          2                 2    -10.204350       5.147724\n",
            "12                          3                 2     -9.795318       3.739120\n",
            "13                          2                 2     -9.791598       4.044565\n",
            "14                          2                 1    -14.513455       5.536976\n",
            "15                          2                 1    -14.370313       6.528955\n",
            "16                          2                 1    -14.282746       7.221490\n",
            "17                          1                 1    -16.345100       0.672125\n",
            "18                          2                 2    -10.073473       7.107019\n",
            "19                          2                 2    -10.766196       7.785403\n",
            "20                          2                 2    -13.559419       0.438118\n",
            "21                          3                 3     -7.182889       5.388932\n",
            "22                          1                 1    -13.749856      13.337430\n",
            "23                          2                 2     -8.348287       8.505922\n",
            "24                          2                 2    -10.759055       6.129465\n",
            "25                          3                 3     -7.451180       3.907934\n",
            "26                          3                 2     -9.660183      19.934187\n",
            "27                          3                 3     -4.928613       7.898534\n",
            "28                          4                 3     -6.872500       6.242111\n",
            "29                          4                 3     -6.768213       6.798873\n",
            "30                          4                 4     -4.027056       4.770171\n",
            "31                          4                 3     -6.012601       9.742601\n",
            "32                          5                 4     -4.497469       5.213825\n",
            "33                          2                 2     -8.634618      12.270807\n",
            "34                          2                 2    -10.781014      10.960742\n",
            "35                          3                 2     -8.886996      11.463787\n",
            "36                          3                 2    -10.364663      16.421953\n",
            "37                          4                 3     -5.379963       5.605017\n",
            "38                          4                 3     -5.461580       5.251211\n",
            "39                          4                 3     -7.119475       3.702596\n",
            "40                          3                 3     -7.004695       6.232824\n",
            "41                          5                 4     -4.547340       1.674506\n",
            "42                          6                 4     -4.782774       1.372225\n",
            "43                          6                 3     -7.891548       1.538216\n",
            "44                          4                 3     -8.343300       1.838978\n",
            "45                          3                 3     -7.463667       1.643255\n",
            "46                          3                 2    -11.183839       1.972466\n",
            "47                          2                 2    -11.818742       1.544334\n",
            "48                          5                 4     -4.844511       0.985387\n",
            "49                          8                 5     -2.147724       0.715164\n",
            "sum(actor_losses)= tf.Tensor([-16.805151  -7.29497  -18.959805 -15.537516 -13.150434], shape=(5,), dtype=float32)\n",
            "sum(critic_losses)= tf.Tensor(24.695438, shape=(), dtype=float32)\n",
            "loss_value = sum(actor_losses) + sum(critic_losses)= tf.Tensor([ 7.8902874 17.400469   5.735634   9.157923  11.545005 ], shape=(5,), dtype=float32)\n",
            "loss_value for backprpagation= tf.Tensor([ 7.8902874 17.400469   5.735634   9.157923  11.545005 ], shape=(5,), dtype=float32)\n",
            "iteration= 1000002\n",
            "The calculated reward:  -1.2761595425137733\n",
            "episode_count += 1= 2\n",
            "scalar_results=     number connections  number connected  mean utility  mean datarate\n",
            "0                    1                 1    -16.018496       0.978931\n",
            "1                    1                 1    -16.028623       0.967584\n",
            "2                    2                 1    -15.388164       2.022636\n",
            "3                    2                 1    -15.334882       2.150597\n",
            "4                    2                 2    -11.725134       1.353492\n",
            "5                    2                 2    -11.520381       1.552607\n",
            "6                    3                 2    -10.632685       2.237731\n",
            "7                    3                 2    -10.560972       2.337874\n",
            "8                    1                 1    -15.306069       2.223134\n",
            "9                    3                 2    -10.220372       2.891323\n",
            "10                   2                 2    -10.331855       4.277454\n",
            "11                   2                 2    -10.204350       5.147724\n",
            "12                   3                 2     -9.795318       3.739120\n",
            "13                   2                 2     -9.791598       4.044565\n",
            "14                   2                 1    -14.513455       5.536976\n",
            "15                   2                 1    -14.370313       6.528955\n",
            "16                   2                 1    -14.282746       7.221490\n",
            "17                   1                 1    -16.345100       0.672125\n",
            "18                   2                 2    -10.073473       7.107019\n",
            "19                   2                 2    -10.766196       7.785403\n",
            "20                   2                 2    -13.559419       0.438118\n",
            "21                   3                 3     -7.182889       5.388932\n",
            "22                   1                 1    -13.749856      13.337430\n",
            "23                   2                 2     -8.348287       8.505922\n",
            "24                   2                 2    -10.759055       6.129465\n",
            "25                   3                 3     -7.451180       3.907934\n",
            "26                   3                 2     -9.660183      19.934187\n",
            "27                   3                 3     -4.928613       7.898534\n",
            "28                   4                 3     -6.872500       6.242111\n",
            "29                   4                 3     -6.768213       6.798873\n",
            "30                   4                 4     -4.027056       4.770171\n",
            "31                   4                 3     -6.012601       9.742601\n",
            "32                   5                 4     -4.497469       5.213825\n",
            "33                   2                 2     -8.634618      12.270807\n",
            "34                   2                 2    -10.781014      10.960742\n",
            "35                   3                 2     -8.886996      11.463787\n",
            "36                   3                 2    -10.364663      16.421953\n",
            "37                   4                 3     -5.379963       5.605017\n",
            "38                   4                 3     -5.461580       5.251211\n",
            "39                   4                 3     -7.119475       3.702596\n",
            "40                   3                 3     -7.004695       6.232824\n",
            "41                   5                 4     -4.547340       1.674506\n",
            "42                   6                 4     -4.782774       1.372225\n",
            "43                   6                 3     -7.891548       1.538216\n",
            "44                   4                 3     -8.343300       1.838978\n",
            "45                   3                 3     -7.463667       1.643255\n",
            "46                   3                 2    -11.183839       1.972466\n",
            "47                   2                 2    -11.818742       1.544334\n",
            "48                   5                 4     -4.844511       0.985387\n",
            "49                   8                 5     -2.147724       0.715164\n",
            "scalar_results.index.names=            number connections  number connected  mean utility  mean datarate\n",
            "Time Step                                                                   \n",
            "0                           1                 1    -16.018496       0.978931\n",
            "1                           1                 1    -16.028623       0.967584\n",
            "2                           2                 1    -15.388164       2.022636\n",
            "3                           2                 1    -15.334882       2.150597\n",
            "4                           2                 2    -11.725134       1.353492\n",
            "5                           2                 2    -11.520381       1.552607\n",
            "6                           3                 2    -10.632685       2.237731\n",
            "7                           3                 2    -10.560972       2.337874\n",
            "8                           1                 1    -15.306069       2.223134\n",
            "9                           3                 2    -10.220372       2.891323\n",
            "10                          2                 2    -10.331855       4.277454\n",
            "11                          2                 2    -10.204350       5.147724\n",
            "12                          3                 2     -9.795318       3.739120\n",
            "13                          2                 2     -9.791598       4.044565\n",
            "14                          2                 1    -14.513455       5.536976\n",
            "15                          2                 1    -14.370313       6.528955\n",
            "16                          2                 1    -14.282746       7.221490\n",
            "17                          1                 1    -16.345100       0.672125\n",
            "18                          2                 2    -10.073473       7.107019\n",
            "19                          2                 2    -10.766196       7.785403\n",
            "20                          2                 2    -13.559419       0.438118\n",
            "21                          3                 3     -7.182889       5.388932\n",
            "22                          1                 1    -13.749856      13.337430\n",
            "23                          2                 2     -8.348287       8.505922\n",
            "24                          2                 2    -10.759055       6.129465\n",
            "25                          3                 3     -7.451180       3.907934\n",
            "26                          3                 2     -9.660183      19.934187\n",
            "27                          3                 3     -4.928613       7.898534\n",
            "28                          4                 3     -6.872500       6.242111\n",
            "29                          4                 3     -6.768213       6.798873\n",
            "30                          4                 4     -4.027056       4.770171\n",
            "31                          4                 3     -6.012601       9.742601\n",
            "32                          5                 4     -4.497469       5.213825\n",
            "33                          2                 2     -8.634618      12.270807\n",
            "34                          2                 2    -10.781014      10.960742\n",
            "35                          3                 2     -8.886996      11.463787\n",
            "36                          3                 2    -10.364663      16.421953\n",
            "37                          4                 3     -5.379963       5.605017\n",
            "38                          4                 3     -5.461580       5.251211\n",
            "39                          4                 3     -7.119475       3.702596\n",
            "40                          3                 3     -7.004695       6.232824\n",
            "41                          5                 4     -4.547340       1.674506\n",
            "42                          6                 4     -4.782774       1.372225\n",
            "43                          6                 3     -7.891548       1.538216\n",
            "44                          4                 3     -8.343300       1.838978\n",
            "45                          3                 3     -7.463667       1.643255\n",
            "46                          3                 2    -11.183839       1.972466\n",
            "47                          2                 2    -11.818742       1.544334\n",
            "48                          5                 4     -4.844511       0.985387\n",
            "49                          8                 5     -2.147724       0.715164\n",
            "Solved at episode 2!\n",
            "Solved at episode 2!\n",
            "Solved at episode 2!\n",
            "scalar_results=     number connections  number connected  mean utility  mean datarate\n",
            "0                    1                 1    -16.018496       0.978931\n",
            "1                    1                 1    -16.028623       0.967584\n",
            "2                    2                 1    -15.388164       2.022636\n",
            "3                    2                 1    -15.334882       2.150597\n",
            "4                    2                 2    -11.725134       1.353492\n",
            "5                    2                 2    -11.520381       1.552607\n",
            "6                    3                 2    -10.632685       2.237731\n",
            "7                    3                 2    -10.560972       2.337874\n",
            "8                    1                 1    -15.306069       2.223134\n",
            "9                    3                 2    -10.220372       2.891323\n",
            "10                   2                 2    -10.331855       4.277454\n",
            "11                   2                 2    -10.204350       5.147724\n",
            "12                   3                 2     -9.795318       3.739120\n",
            "13                   2                 2     -9.791598       4.044565\n",
            "14                   2                 1    -14.513455       5.536976\n",
            "15                   2                 1    -14.370313       6.528955\n",
            "16                   2                 1    -14.282746       7.221490\n",
            "17                   1                 1    -16.345100       0.672125\n",
            "18                   2                 2    -10.073473       7.107019\n",
            "19                   2                 2    -10.766196       7.785403\n",
            "20                   2                 2    -13.559419       0.438118\n",
            "21                   3                 3     -7.182889       5.388932\n",
            "22                   1                 1    -13.749856      13.337430\n",
            "23                   2                 2     -8.348287       8.505922\n",
            "24                   2                 2    -10.759055       6.129465\n",
            "25                   3                 3     -7.451180       3.907934\n",
            "26                   3                 2     -9.660183      19.934187\n",
            "27                   3                 3     -4.928613       7.898534\n",
            "28                   4                 3     -6.872500       6.242111\n",
            "29                   4                 3     -6.768213       6.798873\n",
            "30                   4                 4     -4.027056       4.770171\n",
            "31                   4                 3     -6.012601       9.742601\n",
            "32                   5                 4     -4.497469       5.213825\n",
            "33                   2                 2     -8.634618      12.270807\n",
            "34                   2                 2    -10.781014      10.960742\n",
            "35                   3                 2     -8.886996      11.463787\n",
            "36                   3                 2    -10.364663      16.421953\n",
            "37                   4                 3     -5.379963       5.605017\n",
            "38                   4                 3     -5.461580       5.251211\n",
            "39                   4                 3     -7.119475       3.702596\n",
            "40                   3                 3     -7.004695       6.232824\n",
            "41                   5                 4     -4.547340       1.674506\n",
            "42                   6                 4     -4.782774       1.372225\n",
            "43                   6                 3     -7.891548       1.538216\n",
            "44                   4                 3     -8.343300       1.838978\n",
            "45                   3                 3     -7.463667       1.643255\n",
            "46                   3                 2    -11.183839       1.972466\n",
            "47                   2                 2    -11.818742       1.544334\n",
            "48                   5                 4     -4.844511       0.985387\n",
            "49                   8                 5     -2.147724       0.715164\n",
            "scalar_results.index.names=            number connections  number connected  mean utility  mean datarate\n",
            "Time Step                                                                   \n",
            "0                           1                 1    -16.018496       0.978931\n",
            "1                           1                 1    -16.028623       0.967584\n",
            "2                           2                 1    -15.388164       2.022636\n",
            "3                           2                 1    -15.334882       2.150597\n",
            "4                           2                 2    -11.725134       1.353492\n",
            "5                           2                 2    -11.520381       1.552607\n",
            "6                           3                 2    -10.632685       2.237731\n",
            "7                           3                 2    -10.560972       2.337874\n",
            "8                           1                 1    -15.306069       2.223134\n",
            "9                           3                 2    -10.220372       2.891323\n",
            "10                          2                 2    -10.331855       4.277454\n",
            "11                          2                 2    -10.204350       5.147724\n",
            "12                          3                 2     -9.795318       3.739120\n",
            "13                          2                 2     -9.791598       4.044565\n",
            "14                          2                 1    -14.513455       5.536976\n",
            "15                          2                 1    -14.370313       6.528955\n",
            "16                          2                 1    -14.282746       7.221490\n",
            "17                          1                 1    -16.345100       0.672125\n",
            "18                          2                 2    -10.073473       7.107019\n",
            "19                          2                 2    -10.766196       7.785403\n",
            "20                          2                 2    -13.559419       0.438118\n",
            "21                          3                 3     -7.182889       5.388932\n",
            "22                          1                 1    -13.749856      13.337430\n",
            "23                          2                 2     -8.348287       8.505922\n",
            "24                          2                 2    -10.759055       6.129465\n",
            "25                          3                 3     -7.451180       3.907934\n",
            "26                          3                 2     -9.660183      19.934187\n",
            "27                          3                 3     -4.928613       7.898534\n",
            "28                          4                 3     -6.872500       6.242111\n",
            "29                          4                 3     -6.768213       6.798873\n",
            "30                          4                 4     -4.027056       4.770171\n",
            "31                          4                 3     -6.012601       9.742601\n",
            "32                          5                 4     -4.497469       5.213825\n",
            "33                          2                 2     -8.634618      12.270807\n",
            "34                          2                 2    -10.781014      10.960742\n",
            "35                          3                 2     -8.886996      11.463787\n",
            "36                          3                 2    -10.364663      16.421953\n",
            "37                          4                 3     -5.379963       5.605017\n",
            "38                          4                 3     -5.461580       5.251211\n",
            "39                          4                 3     -7.119475       3.702596\n",
            "40                          3                 3     -7.004695       6.232824\n",
            "41                          5                 4     -4.547340       1.674506\n",
            "42                          6                 4     -4.782774       1.372225\n",
            "43                          6                 3     -7.891548       1.538216\n",
            "44                          4                 3     -8.343300       1.838978\n",
            "45                          3                 3     -7.463667       1.643255\n",
            "46                          3                 2    -11.183839       1.972466\n",
            "47                          2                 2    -11.818742       1.544334\n",
            "48                          5                 4     -4.844511       0.985387\n",
            "49                          8                 5     -2.147724       0.715164\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A_L = []\n",
        "C_L = []\n",
        "for x in actor_losses:\n",
        "  for z in x:\n",
        "    A_L.append(z)\n",
        "for y in critic_losses:\n",
        "  C_L.append(np.array(y).mean())"
      ],
      "metadata": {
        "id": "38dunWzAR6XU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(np.arange(len(C_L)),C_L, label = \"Critic Loss\")\n",
        "plt.scatter(np.arange(len(A_L)),A_L, label = \"Actor Loss\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"The episode counts\")\n",
        "plt.ylabel(\"The calculated loss\")\n",
        "plt.title(\"The A2C model on the mobile environment\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "ooXWRsOPUSQ8",
        "outputId": "2eaae016-fc44-48e0-d042-0e8ab57c0733"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'The A2C model on the mobile environment')"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(np.arange(len(reward_history_for_plot)),reward_history_for_plot, label = \"A2C rewards\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"The episode counts\")\n",
        "plt.ylabel(\"The rewards\")\n",
        "plt.title(\"The A2C model on the mobile environment\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "wSDDcoggTVmw",
        "outputId": "5dfed3f2-0970-401a-f187-87d9fb203f9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'The A2C model on the mobile environment')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Defining the optimizer for A3C model***\n",
        "\n",
        "\n",
        "1.   The optimizer for the model is adam\n",
        "2.   The optimizer performs the same as regular optimizer and it just shares the weights based on the using various models ad environments.\n",
        "\n"
      ],
      "metadata": {
        "id": "tfoH7fmr0Rcm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "class SharedAdam(torch.optim.Adam):\n",
        "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.99), eps=1e-8,\n",
        "                 weight_decay=0):\n",
        "        super(SharedAdam, self).__init__(params, lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n",
        "        # State initialization\n",
        "        for group in self.param_groups:\n",
        "            for p in group['params']:\n",
        "                state = self.state[p]\n",
        "                state['step'] = 0\n",
        "                state['exp_avg'] = torch.zeros_like(p.data)\n",
        "                state['exp_avg_sq'] = torch.zeros_like(p.data)\n",
        "\n",
        "                # share in memory\n",
        "                state['exp_avg'].share_memory_()\n",
        "                state['exp_avg_sq'].share_memory_()"
      ],
      "metadata": {
        "id": "ewLEQPl_aePj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Defining the model architectures and providing the formula for loss on critic and action models***\n",
        "\n",
        "\n",
        "*   Defined loss here is based on using entropy.\n",
        "*   The calculated loss is propagated through both of the models weights.\n",
        "\n"
      ],
      "metadata": {
        "id": "MqPmYk580sZw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# a neural network used for actors and critic\n",
        "class ACNetwork(torch.nn.Module):\n",
        "    def __init__(self, state_dim = 7, action_dim = 5):\n",
        "        super(ACNetwork,self).__init__()\n",
        "        self.state_dim = 7\n",
        "        self.action_dim = 4\n",
        "        # define action generated by actor\n",
        "        self.actor_hidden = torch.nn.Linear(state_dim, 400)\n",
        "        self.action = torch.nn.Linear(400, action_dim)\n",
        "        self.sigma = torch.nn.Linear(400, action_dim)\n",
        "        # define value generated by critic\n",
        "        self.critic_hidden = torch.nn.Linear(state_dim,200)\n",
        "        self.value = torch.nn.Linear(200, 1)\n",
        "        # initialize the weights of the above layers\n",
        "        self._set_init([self.actor_hidden, self.action, self.sigma, self.critic_hidden, self.value])\n",
        "\n",
        "    def _set_init(self, layers):\n",
        "        for layer in layers:\n",
        "            torch.nn.init.normal_(layer.weight, mean=0., std=0.1)\n",
        "            torch.nn.init.constant_(layer.bias, 0.)\n",
        "\n",
        "    def forward(self, x):\n",
        "        actor_hidden = F.relu(self.actor_hidden(x))\n",
        "        actions = F.softmax(self.action(actor_hidden))\n",
        "        sigma = F.softplus(self.sigma(actor_hidden)) + 0.001\n",
        "        critic_hidden = F.relu(self.critic_hidden(x))\n",
        "        values = self.value(critic_hidden)\n",
        "\n",
        "        return actions, sigma, values\n",
        "\n",
        "\n",
        "\n",
        "    def loss(self, s, a, v_t, entropy_beat =0.005):\n",
        "        \"\"\"\n",
        "        define loss functions for actor and critic.\n",
        "        :param s: state\n",
        "        :param a: action\n",
        "        :param v_t: value target\n",
        "        :return: total loss\n",
        "        \"\"\"\n",
        "        state = s[-1]\n",
        "        num_states = 7\n",
        "        state_per_user = [0]*5\n",
        "        for index in range (5):\n",
        "            state_per_user[index] = state[(index*num_states):((index*num_states)+num_states)]\n",
        "        state_all_users = []\n",
        "        for i in range (5):\n",
        "            state_all_users.append(state_per_user[:][i])\n",
        "            #print('state_all_users=', state_all_users)\n",
        "        state_all_users = np.array(state_all_users)\n",
        "\n",
        "\n",
        "        self.train()\n",
        "        action, sigma, values = self.forward(torch.from_numpy(state_all_users))\n",
        "        # calculate critic loss\n",
        "\n",
        "        #print(values)\n",
        "        min_idx = min(v_t.shape[0],values.shape[0])\n",
        "        td_error = v_t[0:min_idx] - values[0:min_idx]\n",
        "        critic_loss = td_error.pow(2)\n",
        "        print(\"*******$$The Critic loss $$********: \", critic_loss.mean())\n",
        "\n",
        "        # calculate actor loss. This part could be replaced with other algorithm, such as PPO\n",
        "        action_hist = torch.distributions.Normal(action, sigma)\n",
        "        log_prob = action_hist.log_prob(a[-1])\n",
        "        # entropy = action_hist.entropy()\n",
        "        entropy = 0.5 + 0.5 * math.log(2 * math.pi) + torch.log(action_hist.scale)\n",
        "        exp_v = log_prob[0:min_idx] * td_error.detach() + entropy_beat * entropy[0:min_idx]\n",
        "        actor_loss = -exp_v\n",
        "        print(\"*******$$The Actor loss $$********: \", actor_loss.mean())\n",
        "        # calculate total loss\n",
        "        if critic_loss.shape[0] == actor_loss.shape[0]:\n",
        "            total_loss = (critic_loss + actor_loss).mean()\n",
        "        else:\n",
        "            total_loss = (actor_loss).mean()\n",
        "\n",
        "            total_loss = torch.tensor(total_loss, requires_grad=True)\n",
        "        return total_loss\n"
      ],
      "metadata": {
        "id": "jL88kZlqrIWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchsummary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPEHG8AN1cVA",
        "outputId": "e673c5eb-b1ce-4151-a7bb-a8b9ce5edf2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device_gpu = torch.device(\"cuda\")\n",
        "device_cpu = torch.device(\"cpu\")\n"
      ],
      "metadata": {
        "id": "OUxCdaEx18np"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Checking the model architecture and number of used parameters***"
      ],
      "metadata": {
        "id": "Z6JKupoM3EzV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "input = torch.randn(5, 7)\n",
        "model = ACNetwork(7, 4)\n",
        "actions, sigma, values = model(input)\n",
        "print(\"The action size and space is: \",actions)\n",
        "print(\"The sigma size and space is: \", sigma)\n",
        "model.to(device_cpu)\n",
        "summary(model, input_size=(1, 7),)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1QjeGXlciQ6",
        "outputId": "8dc8ead1-380e-4942-e40d-aab4fd33b500"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The action size and space is:  tensor([[0.2355, 0.1449, 0.2201, 0.3995],\n",
            "        [0.2374, 0.1850, 0.2423, 0.3352],\n",
            "        [0.2066, 0.1308, 0.2562, 0.4064],\n",
            "        [0.2323, 0.1494, 0.3252, 0.2931],\n",
            "        [0.1127, 0.1559, 0.3650, 0.3663]], grad_fn=<SoftmaxBackward0>)\n",
            "The sigma size and space is:  tensor([[1.0336, 0.6566, 0.6753, 0.8758],\n",
            "        [0.7639, 0.6431, 0.6962, 0.7326],\n",
            "        [1.0526, 0.6237, 0.5956, 1.1086],\n",
            "        [1.0298, 0.8079, 0.6807, 0.9836],\n",
            "        [0.9309, 0.7372, 0.5173, 1.1382]], grad_fn=<AddBackward0>)\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1               [-1, 1, 400]           3,200\n",
            "            Linear-2                 [-1, 1, 4]           1,604\n",
            "            Linear-3                 [-1, 1, 4]           1,604\n",
            "            Linear-4               [-1, 1, 200]           1,600\n",
            "            Linear-5                 [-1, 1, 1]             201\n",
            "================================================================\n",
            "Total params: 8,209\n",
            "Trainable params: 8,209\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.03\n",
            "Estimated Total Size (MB): 0.04\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***The following code specifies the process of training the model  ***\n",
        "\n",
        "\n",
        "\n",
        "*   The number of iterations for training the model for self.MAX_EP = 250.\n",
        "*   The number of iterations for training the model for self.MAX_EP_STEP = 10\n",
        "\n",
        "\n",
        "*   The process of updating the model is on each 20 iterations.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ozeqzf8q987r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Worker(mp.Process):\n",
        "    \"\"\"\n",
        "    a class to generate asynchronous workers\n",
        "    \"\"\"\n",
        "    def __init__(self, gnet, opt, global_ep, global_ep_r, res_queue, i):\n",
        "        \"\"\"\n",
        "        :param gnet: global network\n",
        "        :param opt: optimization network\n",
        "        :param global_ep: global_episodes\n",
        "        :param global_ep_r: global_episodes reward\n",
        "        :param res_queue:\n",
        "        :param i:\n",
        "        \"\"\"\n",
        "        super(Worker, self).__init__()\n",
        "        self.name = 'w_%i' %i\n",
        "        self. g_ep, self.g_ep_r, self.res_queue = global_ep, global_ep_r, res_queue\n",
        "        self.gnet, self.opt = gnet, opt\n",
        "        env = gym.make(\"mobile-small-central-v0\")\n",
        "        state_space_dim = 7\n",
        "        action_space_dim = 4\n",
        "        self.lnet = ACNetwork(state_space_dim, action_space_dim)\n",
        "        self.env = env.unwrapped\n",
        "        # parameters\n",
        "        self.UPDATE_GLOBAL_ITER = 20\n",
        "        self.GAMMA = 0.9\n",
        "        self.MAX_EP = 300\n",
        "        self.MAX_EP_STEP = 5\n",
        "    def v_wrap_(self, np_array, dtype=np.float32):\n",
        "        if np_array.dtype != dtype:\n",
        "            np_array = np_array.astype(dtype)\n",
        "        return torch.from_numpy(np_array)\n",
        "\n",
        "    def push_and_pull_(self, opt, lnet, gnet, done, s_, bs, ba, br, gamma):\n",
        "        if done:\n",
        "            v_s_ = 0.0\n",
        "        else:\n",
        "            state = s_\n",
        "            num_states = 7\n",
        "            state_per_user = [0]*5\n",
        "            for index in range (5):\n",
        "                state_per_user[index] = state[(index*num_states):((index*num_states)+num_states)]\n",
        "            state_all_users = []\n",
        "            for i in range (5):\n",
        "                state_all_users.append(state_per_user[:][i])\n",
        "                #print('state_all_users=', state_all_users)\n",
        "            state_all_users = np.array(state_all_users)\n",
        "            #print(\"The shape of state for wraper is: \",state_all_users.shape)\n",
        "            v_s_ = lnet.forward(self.v_wrap_(state_all_users))[-1].data.numpy()[0, 0]\n",
        "            print(\"v_s_ is: \", v_s_)\n",
        "        buffer_v_target = []\n",
        "        for r in br[: : -1]:\n",
        "            v_s_ = r + gamma * v_s_\n",
        "            buffer_v_target.append(v_s_)\n",
        "        buffer_v_target.reverse()\n",
        "\n",
        "        s = self.v_wrap_(np.stack(bs))\n",
        "        a = self.v_wrap_(np.array(ba, dtype=np.int64)) if ba[0].dtype == np.int64 else self.v_wrap_(np.vstack(ba))\n",
        "        v_t = self.v_wrap_(np.array(buffer_v_target)[:, None])\n",
        "        loss = lnet.loss(s, a, v_t)\n",
        "        #print(\"Calculating loss is \", loss)\n",
        "        # calculate local gradients and push local parameters to global\n",
        "        #opt.zero_grad()\n",
        "        loss.backward()\n",
        "        for lp, gp in zip(lnet.parameters(), gnet.parameters()):\n",
        "            gp._grad = lp.grad\n",
        "            opt.zero_grad()\n",
        "\n",
        "        opt.step()\n",
        "        lnet.load_state_dict(gnet.state_dict())\n",
        "\n",
        "    def print_record_(self, global_ep, global_ep_r, ep_r, res_queue, name):\n",
        "        with global_ep.get_lock():\n",
        "            global_ep.value += 1\n",
        "        with global_ep_r.get_lock():\n",
        "            if global_ep_r.value == 0.:\n",
        "                global_ep_r.value = ep_r\n",
        "            else:\n",
        "                global_ep_r.value = global_ep_r.value * 0.99 + ep_r * 0.01\n",
        "        res_queue.put(global_ep_r.value)\n",
        "        print(\n",
        "            name,\n",
        "            \"Ep:\", global_ep.value,\n",
        "            \"| Ep_r: %.0f\" % global_ep_r.value,\n",
        "        )\n",
        "\n",
        "    def run(self):\n",
        "        total_step = 1\n",
        "        while self.g_ep.value < self.MAX_EP:\n",
        "            s = self.env.reset()\n",
        "            state = s\n",
        "            buffer_s, buffer_a, buffer_r = [], [], []\n",
        "            ep_r = 0.0\n",
        "            for t in range(self.MAX_EP_STEP):\n",
        "                if self.name == 'w_0':\n",
        "                    self.env.render()\n",
        "                num_states = 7\n",
        "                state_per_user = [0]*5\n",
        "                for index in range (5):\n",
        "                    state_per_user[index] = state[(index*num_states):((index*num_states)+num_states)]\n",
        "                state_all_users = []\n",
        "                for i in range (5):\n",
        "                    state_all_users.append(state_per_user[:][i])\n",
        "                    #print('state_all_users=', state_all_users)\n",
        "                state_all_users = np.array(state_all_users)\n",
        "                a,_,_ = self.lnet.forward(self.v_wrap_(state_all_users))\n",
        "                a = a.detach().numpy()\n",
        "                actions = [0]* 5\n",
        "                for i in range(5):\n",
        "                    action = np.random.choice(4, p=np.squeeze(a[i]))\n",
        "                    actions[i]=action\n",
        "\n",
        "                #print('actions_tensor=', actions_tensor)\n",
        "                actions = np.asarray(actions, dtype=np.int64)\n",
        "                s_, r, done, _ = self.env.step(actions)\n",
        "                print(\"The reward is: \", r)\n",
        "                print(\"The training process is: \", done)\n",
        "                if t == self.MAX_EP_STEP - 1:\n",
        "                    done = True\n",
        "                ep_r +=r\n",
        "                buffer_a.append(a)\n",
        "                buffer_s.append(s)\n",
        "                buffer_r.append((r+8.1)/8.1)\n",
        "                # update global and assign to local network\n",
        "                if total_step % self.UPDATE_GLOBAL_ITER == 0 or done:\n",
        "                    # sync\n",
        "                    print(\"******** sync has started ********\")\n",
        "                    self.push_and_pull_(self.opt, self.lnet, self.gnet, done, s_, buffer_s, buffer_a, buffer_r, self.GAMMA)\n",
        "                    buffer_s, buffer_a, buffer_r = [], [], []\n",
        "                    print(\"****** sync is finished **********\")\n",
        "                    if done:\n",
        "                        self.print_record_(self.g_ep, self.g_ep_r, ep_r, self.res_queue, self.name)\n",
        "                        break\n",
        "                s = s_\n",
        "                total_step += 1\n",
        "\n",
        "        self.res_queue.put(None)\n",
        "\n"
      ],
      "metadata": {
        "id": "vp0rLqzFb7GE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluating the model on the proposed environment for mobile netwwork**\n",
        "\n",
        "\n",
        "*   Checking the results on reward and loss on each iterations.\n",
        "*   Providing the GUI to see how the radio station is supporting every user.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LgWR6wmR3y5o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    env = gym.make(\"mobile-small-central-v0\")\n",
        "    N_S = 7\n",
        "    N_A = 4\n",
        "    gnet = ACNetwork(N_S, N_A)        # global network\n",
        "    gnet.share_memory()         # share the global parameters in multiprocessing\n",
        "    opt = SharedAdam(gnet.parameters(), lr=1e-4, betas=(0.95, 0.999))  # global optimizer\n",
        "    global_ep, global_ep_r, res_queue = mp.Value('i', 0), mp.Value('d', 0.), mp.Queue()\n",
        "    w = Worker(gnet, opt, global_ep, global_ep_r, res_queue, 0)\n",
        "    w.run()"
      ],
      "metadata": {
        "id": "TVmCu1qqhZlN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaae20b8-643d-402c-ae7d-d1b409121990"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The reward is:  -0.4916141954268337\n",
            "The training process is:  False\n",
            "The reward is:  -0.6478895139423136\n",
            "The training process is:  False\n",
            "The reward is:  -0.6308074652520862\n",
            "The training process is:  False\n",
            "The reward is:  -0.6273723100574256\n",
            "The training process is:  False\n",
            "The reward is:  -0.7847765451637156\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(4.7054, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(352.9140, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 1 | Ep_r: -3\n",
            "The reward is:  -0.7542096226285231\n",
            "The training process is:  False\n",
            "The reward is:  -0.41317259386228483\n",
            "The training process is:  False\n",
            "The reward is:  -0.4052286097447789\n",
            "The training process is:  False\n",
            "The reward is:  -0.5859824241335273\n",
            "The training process is:  False\n",
            "The reward is:  -0.4330829869902277\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.8600, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.2888, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 2 | Ep_r: -3\n",
            "The reward is:  -0.8009247954605424\n",
            "The training process is:  False\n",
            "The reward is:  -0.8014311339567677\n",
            "The training process is:  False\n",
            "The reward is:  -0.7694082167255469\n",
            "The training process is:  False\n",
            "The reward is:  -0.5209537279709113\n",
            "The training process is:  False\n",
            "The reward is:  -0.5670686298341191\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(4.3728, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.9768, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 3 | Ep_r: -3\n",
            "The reward is:  -0.7363938328056616\n",
            "The training process is:  False\n",
            "The reward is:  -0.7289980989012694\n",
            "The training process is:  False\n",
            "The reward is:  -0.72752045192895\n",
            "The training process is:  False\n",
            "The reward is:  -0.7218359844428226\n",
            "The training process is:  False\n",
            "The reward is:  -0.5135099350435006\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.8714, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.2242, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 4 | Ep_r: -3\n",
            "The reward is:  -0.7993844593306625\n",
            "The training process is:  False\n",
            "The reward is:  -0.5377583918423704\n",
            "The training process is:  False\n",
            "The reward is:  -0.5183795057157682\n",
            "The training process is:  False\n",
            "The reward is:  -0.6604466721929427\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.7616946\n",
            "*******$$The Critic loss $$********:  tensor(7.4991, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.4766, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.6470777713309867\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(0.7083, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.2278, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 5 | Ep_r: -3\n",
            "The reward is:  -0.3533114089144683\n",
            "The training process is:  False\n",
            "The reward is:  -0.3485818434711734\n",
            "The training process is:  False\n",
            "The reward is:  -0.6610426887939006\n",
            "The training process is:  False\n",
            "The reward is:  -0.6324660275154191\n",
            "The training process is:  False\n",
            "The reward is:  -0.6318721715672454\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.5898, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.2188, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 6 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.776134544045629\n",
            "The training process is:  False\n",
            "The reward is:  -0.6098369387984094\n",
            "The training process is:  False\n",
            "The reward is:  -0.4463887624545212\n",
            "The training process is:  False\n",
            "The reward is:  -0.26860714606302755\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(3.8603, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.6814, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 7 | Ep_r: -3\n",
            "The reward is:  -0.7133710695577793\n",
            "The training process is:  False\n",
            "The reward is:  -0.5656004041481184\n",
            "The training process is:  False\n",
            "The reward is:  -0.7096641862000217\n",
            "The training process is:  False\n",
            "The reward is:  -0.7063521077963489\n",
            "The training process is:  False\n",
            "The reward is:  -0.34455653838957245\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.0202, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.2707, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 8 | Ep_r: -3\n",
            "The reward is:  -0.6574394144517319\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.8384806753266181\n",
            "The training process is:  False\n",
            "The reward is:  -0.8367763410399046\n",
            "The training process is:  False\n",
            "The reward is:  -0.7490789839750779\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.5290, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.8920, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 9 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.782760460416266\n",
            "The training process is:  False\n",
            "The reward is:  -0.7824124910729464\n",
            "The training process is:  False\n",
            "The reward is:  -0.7662205878545552\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.8258296\n",
            "*******$$The Critic loss $$********:  tensor(4.9486, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.0431, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.6622508220093549\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(0.8237, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.1691, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 10 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.7952944504892825\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.9564, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.5379, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 11 | Ep_r: -3\n",
            "The reward is:  -0.7165347275054856\n",
            "The training process is:  False\n",
            "The reward is:  -0.7219999724869196\n",
            "The training process is:  False\n",
            "The reward is:  -0.732361575105058\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.7466607660255977\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.3063, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.0548, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 12 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.7874662291826843\n",
            "The training process is:  False\n",
            "The reward is:  -0.8517393995286822\n",
            "The training process is:  False\n",
            "The reward is:  -0.7228437826793099\n",
            "The training process is:  False\n",
            "The reward is:  -0.7202613621187639\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.2623, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.6861, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 13 | Ep_r: -3\n",
            "The reward is:  -0.8530822508715209\n",
            "The training process is:  False\n",
            "The reward is:  -0.8565897231949601\n",
            "The training process is:  False\n",
            "The reward is:  -0.8222838363011423\n",
            "The training process is:  False\n",
            "The reward is:  -0.8177952353982173\n",
            "The training process is:  False\n",
            "The reward is:  -0.6491846342492091\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.0978, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.4288, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 14 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.7824124910729464\n",
            "The training process is:  False\n",
            "The reward is:  -0.7789303493492757\n",
            "The training process is:  False\n",
            "The reward is:  -0.7794769438114942\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.8261987\n",
            "*******$$The Critic loss $$********:  tensor(5.2131, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.5009, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.7613048072876538\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(0.8467, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.0199, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 15 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.48473212629295015\n",
            "The training process is:  False\n",
            "The reward is:  -0.7611117486936149\n",
            "The training process is:  False\n",
            "The reward is:  -0.8528823840932247\n",
            "The training process is:  False\n",
            "The reward is:  -0.848766208868873\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.4634, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.1401, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 16 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.6003265732855534\n",
            "The training process is:  False\n",
            "The reward is:  -0.4549033419670211\n",
            "The training process is:  False\n",
            "The reward is:  -0.2431404696997997\n",
            "The training process is:  False\n",
            "The reward is:  -0.23561692720489819\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(4.8445, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.7854, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 17 | Ep_r: -3\n",
            "The reward is:  -0.5598801648948714\n",
            "The training process is:  False\n",
            "The reward is:  -0.4667539903755554\n",
            "The training process is:  False\n",
            "The reward is:  -0.7254873553940804\n",
            "The training process is:  False\n",
            "The reward is:  -0.5823268661524361\n",
            "The training process is:  False\n",
            "The reward is:  -0.7449368612487366\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(3.7919, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.6627, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 18 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.6618570812392915\n",
            "The training process is:  False\n",
            "The reward is:  -0.833592002284132\n",
            "The training process is:  False\n",
            "The reward is:  -0.8358985747529075\n",
            "The training process is:  False\n",
            "The reward is:  -0.8349250009310925\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.1422, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.6990, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 19 | Ep_r: -3\n",
            "The reward is:  -0.48032619514371644\n",
            "The training process is:  False\n",
            "The reward is:  -0.4956760035147794\n",
            "The training process is:  False\n",
            "The reward is:  -0.8544172885649823\n",
            "The training process is:  False\n",
            "The reward is:  -0.7013652445249008\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.7485831\n",
            "*******$$The Critic loss $$********:  tensor(4.4449, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.0821, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.18650979365679451\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(0.5954, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(-0.0279, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 20 | Ep_r: -3\n",
            "The reward is:  -0.5436661012110535\n",
            "The training process is:  False\n",
            "The reward is:  -0.4863682550955307\n",
            "The training process is:  False\n",
            "The reward is:  -0.20538164702165213\n",
            "The training process is:  False\n",
            "The reward is:  -0.3248968918194339\n",
            "The training process is:  False\n",
            "The reward is:  -0.6693857637472193\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(5.4348, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.7553, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 21 | Ep_r: -3\n",
            "The reward is:  -0.7898288305858561\n",
            "The training process is:  False\n",
            "The reward is:  -0.48607826855524705\n",
            "The training process is:  False\n",
            "The reward is:  -0.782760460416266\n",
            "The training process is:  False\n",
            "The reward is:  -0.7781027422443847\n",
            "The training process is:  False\n",
            "The reward is:  -0.4979997553146558\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.9753, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.0791, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 22 | Ep_r: -3\n",
            "The reward is:  -0.8439544745287335\n",
            "The training process is:  False\n",
            "The reward is:  -0.6738753313281369\n",
            "The training process is:  False\n",
            "The reward is:  -0.848766208868873\n",
            "The training process is:  False\n",
            "The reward is:  -0.4978443322048425\n",
            "The training process is:  False\n",
            "The reward is:  -0.6981673917155937\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(3.2683, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.4946, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 23 | Ep_r: -3\n",
            "The reward is:  -0.6618570812392915\n",
            "The training process is:  False\n",
            "The reward is:  -0.5347692067236153\n",
            "The training process is:  False\n",
            "The reward is:  -0.35132736450210034\n",
            "The training process is:  False\n",
            "The reward is:  -0.21903447473387222\n",
            "The training process is:  False\n",
            "The reward is:  0.03510382481414034\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(6.0585, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.4675, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 24 | Ep_r: -3\n",
            "The reward is:  -0.5459246449339993\n",
            "The training process is:  False\n",
            "The reward is:  -0.40124099459790485\n",
            "The training process is:  False\n",
            "The reward is:  -0.3174727963113941\n",
            "The training process is:  False\n",
            "The reward is:  -0.40849650596386533\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.7605038\n",
            "*******$$The Critic loss $$********:  tensor(7.5107, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.8329, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.4395748691580579\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(0.6639, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(-1.1996, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 25 | Ep_r: -3\n",
            "The reward is:  -0.816847224328137\n",
            "The training process is:  False\n",
            "The reward is:  -0.6440000006999602\n",
            "The training process is:  False\n",
            "The reward is:  -0.41941294144801355\n",
            "The training process is:  False\n",
            "The reward is:  -0.13227793370408908\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.1187, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.1451, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 26 | Ep_r: -3\n",
            "The reward is:  -0.823089440242088\n",
            "The training process is:  False\n",
            "The reward is:  -0.6351615649017522\n",
            "The training process is:  False\n",
            "The reward is:  -0.8269660854844038\n",
            "The training process is:  False\n",
            "The reward is:  -0.8159420189165267\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.6477, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.4212, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 27 | Ep_r: -3\n",
            "The reward is:  -0.6175399461180732\n",
            "The training process is:  False\n",
            "The reward is:  -0.510117737416718\n",
            "The training process is:  False\n",
            "The reward is:  -0.5536752787055406\n",
            "The training process is:  False\n",
            "The reward is:  -0.5191124447649382\n",
            "The training process is:  False\n",
            "The reward is:  -0.3901106742947464\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(3.5156, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.6038, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 28 | Ep_r: -3\n",
            "The reward is:  -0.823089440242088\n",
            "The training process is:  False\n",
            "The reward is:  -0.5439631788834649\n",
            "The training process is:  False\n",
            "The reward is:  -0.50518139348721\n",
            "The training process is:  False\n",
            "The reward is:  -0.21290930897841384\n",
            "The training process is:  False\n",
            "The reward is:  -0.28820562990349885\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(6.0481, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.9343, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 29 | Ep_r: -3\n",
            "The reward is:  -0.6\n",
            "The training process is:  False\n",
            "The reward is:  -0.6114855776407535\n",
            "The training process is:  False\n",
            "The reward is:  -0.24851053333101433\n",
            "The training process is:  False\n",
            "The reward is:  -0.25635569994642077\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(4.1334, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(3.8262, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 30 | Ep_r: -3\n",
            "The reward is:  -0.6567346757821589\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.7460563\n",
            "*******$$The Critic loss $$********:  tensor(5.2196, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.1172, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.5120738285499261\n",
            "The training process is:  False\n",
            "The reward is:  -0.5341349042090194\n",
            "The training process is:  False\n",
            "The reward is:  -0.39761440100880047\n",
            "The training process is:  False\n",
            "The reward is:  -0.3874593315038596\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.2010, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.5884, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 31 | Ep_r: -3\n",
            "The reward is:  -0.5337525682060213\n",
            "The training process is:  False\n",
            "The reward is:  -0.7288267028118661\n",
            "The training process is:  False\n",
            "The reward is:  -0.12221831012861428\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(0.4207, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(-0.2883, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 32 | Ep_r: -3\n",
            "The reward is:  -0.24314232807516803\n",
            "The training process is:  False\n",
            "The reward is:  -0.2272939636200953\n",
            "The training process is:  False\n",
            "The reward is:  -0.7523940007829394\n",
            "The training process is:  False\n",
            "The reward is:  -0.596926646000962\n",
            "The training process is:  False\n",
            "The reward is:  -0.5218333001786576\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(3.9741, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.6504, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 33 | Ep_r: -3\n",
            "The reward is:  -0.8040091751551467\n",
            "The training process is:  False\n",
            "The reward is:  -0.7078033817764648\n",
            "The training process is:  False\n",
            "The reward is:  -0.8438979403416212\n",
            "The training process is:  False\n",
            "The reward is:  -0.8410925618441404\n",
            "The training process is:  False\n",
            "The reward is:  -0.8382570636827189\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.1325, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.3463, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 34 | Ep_r: -3\n",
            "The reward is:  -0.7352378026736786\n",
            "The training process is:  False\n",
            "The reward is:  -0.8151372055671853\n",
            "The training process is:  False\n",
            "The reward is:  -0.8172279005587472\n",
            "The training process is:  False\n",
            "The reward is:  -0.5273001676191119\n",
            "The training process is:  False\n",
            "The reward is:  -0.6591862083897395\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.6148, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.8818, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 35 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.5129622337659269\n",
            "The training process is:  False\n",
            "The reward is:  -0.3536320791854678\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  0.19096643\n",
            "*******$$The Critic loss $$********:  tensor(2.4608, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.5868, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.4037467219816703\n",
            "The training process is:  False\n",
            "The reward is:  -0.42527539329820324\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.9257, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.0214, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 36 | Ep_r: -3\n",
            "The reward is:  -0.6\n",
            "The training process is:  False\n",
            "The reward is:  -0.44527251561955844\n",
            "The training process is:  False\n",
            "The reward is:  -0.6885520115948068\n",
            "The training process is:  False\n",
            "The reward is:  -0.40355261776605794\n",
            "The training process is:  False\n",
            "The reward is:  -0.6334712408558605\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(3.6737, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.6139, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 37 | Ep_r: -3\n",
            "The reward is:  -0.8258654504428253\n",
            "The training process is:  False\n",
            "The reward is:  -0.8430255787280686\n",
            "The training process is:  False\n",
            "The reward is:  -0.8382367016169624\n",
            "The training process is:  False\n",
            "The reward is:  -0.8358354730195042\n",
            "The training process is:  False\n",
            "The reward is:  -0.4213708173865512\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.2623, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(-0.0479, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 38 | Ep_r: -3\n",
            "The reward is:  -0.6955423867095224\n",
            "The training process is:  False\n",
            "The reward is:  -0.6056548286934673\n",
            "The training process is:  False\n",
            "The reward is:  -0.31809525051790644\n",
            "The training process is:  False\n",
            "The reward is:  -0.1337721600018639\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(4.0949, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.3734, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 39 | Ep_r: -3\n",
            "The reward is:  -0.8225113083470316\n",
            "The training process is:  False\n",
            "The reward is:  -0.4375032235760895\n",
            "The training process is:  False\n",
            "The reward is:  -0.4296177366546597\n",
            "The training process is:  False\n",
            "The reward is:  -0.4423870633706857\n",
            "The training process is:  False\n",
            "The reward is:  -0.437455761473891\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.9257, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.3036, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 40 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.7694247228023015\n",
            "The training process is:  False\n",
            "The reward is:  -0.6098296870633979\n",
            "The training process is:  False\n",
            "The reward is:  -0.5300161995215337\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.7610996\n",
            "*******$$The Critic loss $$********:  tensor(5.0829, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.6690, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.6273357765657132\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(0.7032, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(-0.4215, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 41 | Ep_r: -3\n",
            "The reward is:  -0.8260580556913085\n",
            "The training process is:  False\n",
            "The reward is:  -0.6606514654038128\n",
            "The training process is:  False\n",
            "The reward is:  -0.5424242948546861\n",
            "The training process is:  False\n",
            "The reward is:  -0.6422510677290322\n",
            "The training process is:  False\n",
            "The reward is:  -0.6326007314976279\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(3.0660, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.7726, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 42 | Ep_r: -3\n",
            "The reward is:  -0.8293032628220434\n",
            "The training process is:  False\n",
            "The reward is:  -0.832675037208411\n",
            "The training process is:  False\n",
            "The reward is:  -0.8359826255153134\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.8181442558949641\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.3082, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.9177, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 43 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.6\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(3.8710, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(2.4453, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 44 | Ep_r: -3\n",
            "The reward is:  -0.25431604926320117\n",
            "The training process is:  False\n",
            "The reward is:  -0.0756809394836756\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(0.2893, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(-0.1967, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 45 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.7315809531572622\n",
            "The training process is:  False\n",
            "The reward is:  -0.7385625406833498\n",
            "The training process is:  False\n",
            "The reward is:  -0.7420460960490921\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.8634, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.6115, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 46 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.7500992\n",
            "*******$$The Critic loss $$********:  tensor(1.9598, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.3013, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(0.3823, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(-0.0746, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 47 | Ep_r: -3\n",
            "The reward is:  -0.687115848782408\n",
            "The training process is:  False\n",
            "The reward is:  -0.6747441126051021\n",
            "The training process is:  False\n",
            "The reward is:  -0.49950831887903\n",
            "The training process is:  False\n",
            "The reward is:  -0.40945444274320186\n",
            "The training process is:  False\n",
            "The reward is:  -0.29960917706333057\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(4.1843, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.6860, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 48 | Ep_r: -3\n",
            "The reward is:  -0.823089440242088\n",
            "The training process is:  False\n",
            "The reward is:  -0.6488018741614022\n",
            "The training process is:  False\n",
            "The reward is:  -0.31415312714147625\n",
            "The training process is:  False\n",
            "The reward is:  -0.298284880777009\n",
            "The training process is:  False\n",
            "The reward is:  -0.40498833234747933\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(6.0319, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.9310, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 49 | Ep_r: -3\n",
            "The reward is:  -0.8476283916679908\n",
            "The training process is:  False\n",
            "The reward is:  -0.5635533536831634\n",
            "The training process is:  False\n",
            "The reward is:  -0.43104898067150144\n",
            "The training process is:  False\n",
            "The reward is:  -0.491982698419824\n",
            "The training process is:  False\n",
            "The reward is:  -0.47939304799127447\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.8559, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.3598, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 50 | Ep_r: -3\n",
            "The reward is:  -0.8433301872981824\n",
            "The training process is:  False\n",
            "The reward is:  -0.6131374958414513\n",
            "The training process is:  False\n",
            "The reward is:  -0.6057368907013909\n",
            "The training process is:  False\n",
            "The reward is:  -0.7995572142318348\n",
            "The training process is:  False\n",
            "The reward is:  -0.7957320514039379\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.9717, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.6567, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 51 | Ep_r: -3\n",
            "The reward is:  -0.8032255407682116\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.5792542570190127\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  0.4381475\n",
            "*******$$The Critic loss $$********:  tensor(0.3878, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.0641, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.5071534150680727\n",
            "The training process is:  False\n",
            "The reward is:  -0.559695318556674\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.0158, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.4251, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 52 | Ep_r: -3\n",
            "The reward is:  -0.6882838860553734\n",
            "The training process is:  False\n",
            "The reward is:  -0.6\n",
            "The training process is:  False\n",
            "The reward is:  -0.25212936346943715\n",
            "The training process is:  False\n",
            "The reward is:  -0.2420044054103038\n",
            "The training process is:  False\n",
            "The reward is:  -0.39345370255777257\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(6.5265, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(2.6166, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 53 | Ep_r: -3\n",
            "The reward is:  -0.7736713194456154\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.7720322159706822\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.7712748831568659\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.2487, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.5095, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 54 | Ep_r: -3\n",
            "The reward is:  -0.7736221841857132\n",
            "The training process is:  False\n",
            "The reward is:  -0.5810795107197619\n",
            "The training process is:  False\n",
            "The reward is:  -0.5739913845346427\n",
            "The training process is:  False\n",
            "The reward is:  -0.7556681154834494\n",
            "The training process is:  False\n",
            "The reward is:  -0.5990108270848002\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.4130, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.2343, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 55 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.8549867213070007\n",
            "The training process is:  False\n",
            "The reward is:  -0.8518747964318708\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.1452, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.0727, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 56 | Ep_r: -3\n",
            "The reward is:  -0.70980757757965\n",
            "The training process is:  False\n",
            "The reward is:  -0.3466721363160987\n",
            "The training process is:  False\n",
            "The reward is:  -0.4157104713787114\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.7537894\n",
            "*******$$The Critic loss $$********:  tensor(7.7608, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.2058, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.2890315087827592\n",
            "The training process is:  False\n",
            "The reward is:  -0.46830112001721946\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(0.9182, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.0440, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 57 | Ep_r: -3\n",
            "The reward is:  -0.4309853761580789\n",
            "The training process is:  False\n",
            "The reward is:  -0.3314354140554804\n",
            "The training process is:  False\n",
            "The reward is:  -0.32018157074782616\n",
            "The training process is:  False\n",
            "The reward is:  -0.46543141415256867\n",
            "The training process is:  False\n",
            "The reward is:  -0.4607418263253355\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(5.1803, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.7903, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 58 | Ep_r: -3\n",
            "The reward is:  -0.7861108080650634\n",
            "The training process is:  False\n",
            "The reward is:  -0.7875882160559309\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.8548082326545338\n",
            "The training process is:  False\n",
            "The reward is:  -0.760788894518746\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.7689, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.2688, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 59 | Ep_r: -3\n",
            "The reward is:  -0.6677837758076945\n",
            "The training process is:  False\n",
            "The reward is:  -0.6609689245575334\n",
            "The training process is:  False\n",
            "The reward is:  -0.41816868940082275\n",
            "The training process is:  False\n",
            "The reward is:  -0.5350264057296823\n",
            "The training process is:  False\n",
            "The reward is:  -0.41858390610899354\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(3.5322, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.7286, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 60 | Ep_r: -3\n",
            "The reward is:  -0.5288510877537638\n",
            "The training process is:  False\n",
            "The reward is:  -0.6071619161035835\n",
            "The training process is:  False\n",
            "The reward is:  -0.5166956287439455\n",
            "The training process is:  False\n",
            "The reward is:  -0.7394742127391615\n",
            "The training process is:  False\n",
            "The reward is:  -0.5690214776207124\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.8278, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.2915, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 61 | Ep_r: -3\n",
            "The reward is:  -0.8518747964318706\n",
            "The training process is:  False\n",
            "The reward is:  -0.7719316889876603\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.7740425\n",
            "*******$$The Critic loss $$********:  tensor(3.8002, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.9453, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.7723329726535866\n",
            "The training process is:  False\n",
            "The reward is:  -0.7649170199156392\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(0.4363, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(-0.0495, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 62 | Ep_r: -3\n",
            "The reward is:  -0.7874662291826843\n",
            "The training process is:  False\n",
            "The reward is:  -0.3524043587240485\n",
            "The training process is:  False\n",
            "The reward is:  -0.6262630727763082\n",
            "The training process is:  False\n",
            "The reward is:  -0.6346569090448343\n",
            "The training process is:  False\n",
            "The reward is:  -0.1468412708146792\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.5045, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.5902, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 63 | Ep_r: -3\n",
            "The reward is:  -0.8218522320306769\n",
            "The training process is:  False\n",
            "The reward is:  -0.8206455821789842\n",
            "The training process is:  False\n",
            "The reward is:  -0.8183315040551221\n",
            "The training process is:  False\n",
            "The reward is:  -0.8172279005587473\n",
            "The training process is:  False\n",
            "The reward is:  -0.5864226131415237\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.9396, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.9967, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 64 | Ep_r: -3\n",
            "The reward is:  -0.5654023592091475\n",
            "The training process is:  False\n",
            "The reward is:  -0.5085854729481474\n",
            "The training process is:  False\n",
            "The reward is:  -0.49592908232275795\n",
            "The training process is:  False\n",
            "The reward is:  -0.3465466017463643\n",
            "The training process is:  False\n",
            "The reward is:  -0.33553847354041527\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(6.0223, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.8625, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 65 | Ep_r: -3\n",
            "The reward is:  -0.5817848299736708\n",
            "The training process is:  False\n",
            "The reward is:  -0.6195425810522738\n",
            "The training process is:  False\n",
            "The reward is:  -0.5823733620528547\n",
            "The training process is:  False\n",
            "The reward is:  -0.8332440327896027\n",
            "The training process is:  False\n",
            "The reward is:  -0.5740416948744265\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.2904, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.0062, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 66 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.33001376390778037\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  0.22852898\n",
            "*******$$The Critic loss $$********:  tensor(0.3690, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(-0.0306, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.37669682337483873\n",
            "The training process is:  False\n",
            "The reward is:  -0.3750175728885964\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.3666, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.4081, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 67 | Ep_r: -3\n",
            "The reward is:  -0.8500255001755994\n",
            "The training process is:  False\n",
            "The reward is:  -0.07626990837358823\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(0.2876, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(-0.2876, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 68 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.6970467352150866\n",
            "The training process is:  False\n",
            "The reward is:  -0.6942365287958919\n",
            "The training process is:  False\n",
            "The reward is:  -0.5055396339107974\n",
            "The training process is:  False\n",
            "The reward is:  -0.680687898362699\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(3.7591, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.1072, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 69 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.6\n",
            "The training process is:  False\n",
            "The reward is:  -0.4262700562764555\n",
            "The training process is:  False\n",
            "The reward is:  -0.39443756588083173\n",
            "The training process is:  False\n",
            "The reward is:  -0.605021615568021\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(3.2349, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(3.2573, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 70 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.6046652294898606\n",
            "The training process is:  False\n",
            "The reward is:  -0.2704437618812382\n",
            "The training process is:  False\n",
            "The reward is:  -0.42927204867378954\n",
            "The training process is:  False\n",
            "The reward is:  -0.4343445276269392\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(4.3575, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(2.9681, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 71 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.8037162926628586\n",
            "The training process is:  False\n",
            "The reward is:  -0.672883754229121\n",
            "The training process is:  False\n",
            "The reward is:  -0.8124371256569203\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.9950, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.3013, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 72 | Ep_r: -3\n",
            "The reward is:  -0.8491357411851255\n",
            "The training process is:  False\n",
            "The reward is:  -0.6277767303175571\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.7535444\n",
            "*******$$The Critic loss $$********:  tensor(3.0426, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.8623, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.8433301872981824\n",
            "The training process is:  False\n",
            "The reward is:  -0.6565591879883208\n",
            "The training process is:  False\n",
            "The reward is:  -0.3631398453824283\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.8093, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.4612, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 73 | Ep_r: -3\n",
            "The reward is:  -0.43504884323482945\n",
            "The training process is:  False\n",
            "The reward is:  -0.574342574660426\n",
            "The training process is:  False\n",
            "The reward is:  -0.6534492177079405\n",
            "The training process is:  False\n",
            "The reward is:  -0.6225556964935441\n",
            "The training process is:  False\n",
            "The reward is:  -0.8486072662310932\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.4130, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.3777, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 74 | Ep_r: -3\n",
            "The reward is:  -0.7024110289333513\n",
            "The training process is:  False\n",
            "The reward is:  -0.3820024424717693\n",
            "The training process is:  False\n",
            "The reward is:  -0.6874927847677792\n",
            "The training process is:  False\n",
            "The reward is:  -0.6813572944934662\n",
            "The training process is:  False\n",
            "The reward is:  -0.6727413666689432\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(4.0088, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.2817, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 75 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.6770782839556582\n",
            "The training process is:  False\n",
            "The reward is:  -0.8528823840932247\n",
            "The training process is:  False\n",
            "The reward is:  -0.8499561038590313\n",
            "The training process is:  False\n",
            "The reward is:  -0.6664400835878105\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.2308, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.2645, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 76 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.6403292710631991\n",
            "The training process is:  False\n",
            "The reward is:  -0.8222585178868194\n",
            "The training process is:  False\n",
            "The reward is:  -0.627737155884598\n",
            "The training process is:  False\n",
            "The reward is:  -0.5875031389673768\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(3.3918, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.0959, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 77 | Ep_r: -3\n",
            "The reward is:  -0.8288880306270034\n",
            "The training process is:  False\n",
            "The reward is:  -0.7529173529418726\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.786101\n",
            "*******$$The Critic loss $$********:  tensor(1.2370, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.7973, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.5771040812584225\n",
            "The training process is:  False\n",
            "The reward is:  -0.2679618972405079\n",
            "The training process is:  False\n",
            "The reward is:  -0.4627814219551464\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.3041, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.4301, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 78 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.6964653929423641\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.49136344368343166\n",
            "The training process is:  False\n",
            "The reward is:  -0.31770020490052764\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(4.9580, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.2118, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 79 | Ep_r: -3\n",
            "The reward is:  -0.6322336475539447\n",
            "The training process is:  False\n",
            "The reward is:  -0.625729235734893\n",
            "The training process is:  False\n",
            "The reward is:  -0.46110555734232206\n",
            "The training process is:  False\n",
            "The reward is:  -0.5973532195493052\n",
            "The training process is:  False\n",
            "The reward is:  -0.4549114164660823\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.8495, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.8197, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 80 | Ep_r: -3\n",
            "The reward is:  -0.825478715692844\n",
            "The training process is:  False\n",
            "The reward is:  -0.8242814922993645\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.8584681887364347\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.1155, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.2219, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 81 | Ep_r: -3\n",
            "The reward is:  -0.8360875538579939\n",
            "The training process is:  False\n",
            "The reward is:  -0.38666896828042374\n",
            "The training process is:  False\n",
            "The reward is:  -0.4613583305254555\n",
            "The training process is:  False\n",
            "The reward is:  -0.4564250643957692\n",
            "The training process is:  False\n",
            "The reward is:  -0.4321037891507161\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.4286, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.6234, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 82 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.8448973\n",
            "*******$$The Critic loss $$********:  tensor(1.1687, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.5239, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.8262981031213584\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(0.3455, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(-0.4945, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 83 | Ep_r: -3\n",
            "The reward is:  -0.723572888526277\n",
            "The training process is:  False\n",
            "The reward is:  -0.576678030046492\n",
            "The training process is:  False\n",
            "The reward is:  -0.5665386614339761\n",
            "The training process is:  False\n",
            "The reward is:  -0.5523715447735732\n",
            "The training process is:  False\n",
            "The reward is:  -0.5210378163509635\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(3.3811, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.5700, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 84 | Ep_r: -3\n",
            "The reward is:  -0.5897853171974494\n",
            "The training process is:  False\n",
            "The reward is:  -0.7452351718243162\n",
            "The training process is:  False\n",
            "The reward is:  -0.5629821027600849\n",
            "The training process is:  False\n",
            "The reward is:  -0.6200611151369624\n",
            "The training process is:  False\n",
            "The reward is:  -0.6137898028400476\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(3.9302, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.9427, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 85 | Ep_r: -3\n",
            "The reward is:  -0.8057423229041423\n",
            "The training process is:  False\n",
            "The reward is:  -0.8048808688866671\n",
            "The training process is:  False\n",
            "The reward is:  -0.574706044098108\n",
            "The training process is:  False\n",
            "The reward is:  -0.6267566624889849\n",
            "The training process is:  False\n",
            "The reward is:  -0.6985208559055416\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.9062, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.2236, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 86 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.5753280567033044\n",
            "The training process is:  False\n",
            "The reward is:  -0.5492857595712809\n",
            "The training process is:  False\n",
            "The reward is:  -0.7384780810547049\n",
            "The training process is:  False\n",
            "The reward is:  -0.5385026311487454\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.9314, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.4823, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 87 | Ep_r: -3\n",
            "The reward is:  -0.8040741015225219\n",
            "The training process is:  False\n",
            "The reward is:  -0.7982690855743779\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.761128\n",
            "*******$$The Critic loss $$********:  tensor(3.4254, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.3070, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.7952944504892825\n",
            "The training process is:  False\n",
            "The reward is:  -0.790651720711212\n",
            "The training process is:  False\n",
            "The reward is:  -0.5078235545596588\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.2601, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(-0.0968, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 88 | Ep_r: -3\n",
            "The reward is:  -0.6770841808201372\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.8299673416257672\n",
            "The training process is:  False\n",
            "The reward is:  -0.8278395461377093\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.5355, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.4941, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 89 | Ep_r: -3\n",
            "The reward is:  -0.47539722664941475\n",
            "The training process is:  False\n",
            "The reward is:  -0.39132907876874845\n",
            "The training process is:  False\n",
            "The reward is:  -0.47886940613430296\n",
            "The training process is:  False\n",
            "The reward is:  -0.4549387838523161\n",
            "The training process is:  False\n",
            "The reward is:  -0.6188302672614048\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(4.9086, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.8635, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 90 | Ep_r: -3\n",
            "The reward is:  -0.5178012755509741\n",
            "The training process is:  False\n",
            "The reward is:  -0.3309589625233361\n",
            "The training process is:  False\n",
            "The reward is:  -0.5248492652327148\n",
            "The training process is:  False\n",
            "The reward is:  -0.5118556637650539\n",
            "The training process is:  False\n",
            "The reward is:  -0.4095840310591493\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(4.3472, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.6054, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 91 | Ep_r: -3\n",
            "The reward is:  -0.6200180756779988\n",
            "The training process is:  False\n",
            "The reward is:  -0.41885704652720523\n",
            "The training process is:  False\n",
            "The reward is:  -0.535915299661472\n",
            "The training process is:  False\n",
            "The reward is:  -0.5232850947438761\n",
            "The training process is:  False\n",
            "The reward is:  -0.20992960946405725\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(5.3468, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.9551, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 92 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.7316681004067931\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.7475843\n",
            "*******$$The Critic loss $$********:  tensor(1.1490, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.1952, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.46399207581683266\n",
            "The training process is:  False\n",
            "The reward is:  -0.7381601200700108\n",
            "The training process is:  False\n",
            "The reward is:  -0.3462198183913123\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(0.4439, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.1996, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 93 | Ep_r: -3\n",
            "The reward is:  -0.8281907092063842\n",
            "The training process is:  False\n",
            "The reward is:  -0.656725800191482\n",
            "The training process is:  False\n",
            "The reward is:  -0.6238075679245516\n",
            "The training process is:  False\n",
            "The reward is:  -0.46015482539521424\n",
            "The training process is:  False\n",
            "The reward is:  -0.5656106813382745\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(3.9300, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.6590, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 94 | Ep_r: -3\n",
            "The reward is:  -0.48368734838075617\n",
            "The training process is:  False\n",
            "The reward is:  0.003731550053331212\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(0.2875, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(-0.3765, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 95 | Ep_r: -3\n",
            "The reward is:  -0.16714354125989953\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(0.5731, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.4612, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 96 | Ep_r: -3\n",
            "The reward is:  -0.41264915966916094\n",
            "The training process is:  False\n",
            "The reward is:  -0.7591623504031835\n",
            "The training process is:  False\n",
            "The reward is:  -0.40820128996937555\n",
            "The training process is:  False\n",
            "The reward is:  -0.39942222363573177\n",
            "The training process is:  False\n",
            "The reward is:  -0.39263704354454115\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(3.5002, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.5205, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 97 | Ep_r: -3\n",
            "The reward is:  -0.8056471039181201\n",
            "The training process is:  False\n",
            "The reward is:  -0.7555753511789847\n",
            "The training process is:  False\n",
            "The reward is:  -0.4103832956422363\n",
            "The training process is:  False\n",
            "The reward is:  -0.5121723513188949\n",
            "The training process is:  False\n",
            "The reward is:  -0.47155630826867023\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(4.7361, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.6655, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 98 | Ep_r: -3\n",
            "The reward is:  -0.508522601184006\n",
            "The training process is:  False\n",
            "The reward is:  -0.1643552834591336\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(0.3431, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(-0.1379, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 99 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.850836024005104\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.7643661\n",
            "*******$$The Critic loss $$********:  tensor(4.2017, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.8441, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.8455384328057919\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(0.7547, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(-0.1080, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 100 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.245492997707551\n",
            "The training process is:  False\n",
            "The reward is:  -0.6\n",
            "The training process is:  False\n",
            "The reward is:  -0.4854350638023102\n",
            "The training process is:  False\n",
            "The reward is:  -0.1368230427451058\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(3.4852, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.5736, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 101 | Ep_r: -3\n",
            "The reward is:  -0.45355671180739776\n",
            "The training process is:  False\n",
            "The reward is:  -0.27306231427553296\n",
            "The training process is:  False\n",
            "The reward is:  -0.48342392341924095\n",
            "The training process is:  False\n",
            "The reward is:  -0.7325381509553917\n",
            "The training process is:  False\n",
            "The reward is:  -0.5262886561959166\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(3.6046, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.2602, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 102 | Ep_r: -3\n",
            "The reward is:  -0.6265764763532711\n",
            "The training process is:  False\n",
            "The reward is:  -0.6353314994415948\n",
            "The training process is:  False\n",
            "The reward is:  -0.7817357633321123\n",
            "The training process is:  False\n",
            "The reward is:  -0.8096037335650038\n",
            "The training process is:  False\n",
            "The reward is:  -0.7762146009998092\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.3072, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(-0.1324, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 103 | Ep_r: -3\n",
            "The reward is:  -0.8079912545150826\n",
            "The training process is:  False\n",
            "The reward is:  -0.8020007895843179\n",
            "The training process is:  False\n",
            "The reward is:  -0.579357875882489\n",
            "The training process is:  False\n",
            "The reward is:  -0.3626849991764333\n",
            "The training process is:  False\n",
            "The reward is:  -0.5634288454012506\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.7132, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.3605, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 104 | Ep_r: -3\n",
            "The reward is:  -0.5092586412463274\n",
            "The training process is:  False\n",
            "The reward is:  -0.21372795613788398\n",
            "The training process is:  False\n",
            "The reward is:  -0.8228637572326178\n",
            "The training process is:  False\n",
            "The reward is:  0.011126996428610213\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.9439, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.3073, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 105 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.8352523\n",
            "*******$$The Critic loss $$********:  tensor(4.8971, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.1293, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.8172550162385811\n",
            "The training process is:  False\n",
            "The reward is:  -0.7830414957839779\n",
            "The training process is:  False\n",
            "The reward is:  -0.5102411695511428\n",
            "The training process is:  False\n",
            "The reward is:  -0.49490900701508844\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(3.3115, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.7044, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 106 | Ep_r: -3\n",
            "The reward is:  -0.521187577798919\n",
            "The training process is:  False\n",
            "The reward is:  -0.7011687565026044\n",
            "The training process is:  False\n",
            "The reward is:  -0.4432218730822058\n",
            "The training process is:  False\n",
            "The reward is:  -0.6124743214360981\n",
            "The training process is:  False\n",
            "The reward is:  -0.6938327916326011\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(3.0718, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.2348, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 107 | Ep_r: -3\n",
            "The reward is:  -0.5654299721795086\n",
            "The training process is:  False\n",
            "The reward is:  -0.33771109116448905\n",
            "The training process is:  False\n",
            "The reward is:  -0.4495313564897014\n",
            "The training process is:  False\n",
            "The reward is:  -0.569130017595106\n",
            "The training process is:  False\n",
            "The reward is:  -0.45040876196860025\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(3.0203, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.3605, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 108 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.6612641725880433\n",
            "The training process is:  False\n",
            "The reward is:  -0.4476598178728312\n",
            "The training process is:  False\n",
            "The reward is:  -0.5893169811648173\n",
            "The training process is:  False\n",
            "The reward is:  -0.4209475802141375\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(3.1013, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.7446, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 109 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.38984313035090906\n",
            "The training process is:  False\n",
            "The reward is:  -0.6919667208134056\n",
            "The training process is:  False\n",
            "The reward is:  -0.526670262722619\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.9997, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.3702, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 110 | Ep_r: -3\n",
            "The reward is:  -0.4010601612204436\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  0.1888889\n",
            "*******$$The Critic loss $$********:  tensor(0.8055, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.5237, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.40488086888666724\n",
            "The training process is:  False\n",
            "The reward is:  -0.8078064554582685\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(0.7620, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.1264, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 111 | Ep_r: -3\n",
            "The reward is:  -0.6564553610378583\n",
            "The training process is:  False\n",
            "The reward is:  -0.45252146523068265\n",
            "The training process is:  False\n",
            "The reward is:  -0.453084407841402\n",
            "The training process is:  False\n",
            "The reward is:  -0.4535557421531191\n",
            "The training process is:  False\n",
            "The reward is:  -0.6277254652919618\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(3.7798, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.5316, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 112 | Ep_r: -3\n",
            "The reward is:  -0.5210898629413339\n",
            "The training process is:  False\n",
            "The reward is:  -0.26841719882502196\n",
            "The training process is:  False\n",
            "The reward is:  -0.29121456671800744\n",
            "The training process is:  False\n",
            "The reward is:  0.1227184666733891\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(3.1747, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.4166, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 113 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.8293032628220434\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.2418, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.3806, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 114 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.6889161574355661\n",
            "The training process is:  False\n",
            "The reward is:  -0.6872990155083655\n",
            "The training process is:  False\n",
            "The reward is:  -0.6846879286664718\n",
            "The training process is:  False\n",
            "The reward is:  -0.7712748831568659\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.7520, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.8963, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 115 | Ep_r: -3\n",
            "The reward is:  -0.5934160744654987\n",
            "The training process is:  False\n",
            "The reward is:  -0.23742081689739725\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.8142986\n",
            "*******$$The Critic loss $$********:  tensor(6.2850, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.0031, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.3145714844365227\n",
            "The training process is:  False\n",
            "The reward is:  -0.1646024726540037\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(0.0587, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.0914, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 116 | Ep_r: -3\n",
            "The reward is:  -0.5805101706978136\n",
            "The training process is:  False\n",
            "The reward is:  -0.5882996256417921\n",
            "The training process is:  False\n",
            "The reward is:  -0.5795398759907078\n",
            "The training process is:  False\n",
            "The reward is:  -0.5838905701680619\n",
            "The training process is:  False\n",
            "The reward is:  -0.6078676885060263\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.8200, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.4120, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 117 | Ep_r: -3\n",
            "The reward is:  -0.5452504480566287\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.7529173529418726\n",
            "The training process is:  False\n",
            "The reward is:  -0.5066065849145728\n",
            "The training process is:  False\n",
            "The reward is:  -0.7557935807045519\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(3.7248, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.0146, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 118 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.6078076488049537\n",
            "The training process is:  False\n",
            "The reward is:  -0.5979077380367099\n",
            "The training process is:  False\n",
            "The reward is:  -0.5937727778461791\n",
            "The training process is:  False\n",
            "The reward is:  -0.5837212050632379\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.9175, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.4796, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 119 | Ep_r: -3\n",
            "The reward is:  -0.2868714876253279\n",
            "The training process is:  False\n",
            "The reward is:  -0.14803892347203712\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.0052, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.4579, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 120 | Ep_r: -3\n",
            "The reward is:  -0.645492997707551\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.8563514951715646\n",
            "The training process is:  False\n",
            "The reward is:  -0.5225263806085039\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.8373, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.4948, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 121 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.4227668554679299\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.7730646\n",
            "*******$$The Critic loss $$********:  tensor(1.2809, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.6399, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.42747921262690686\n",
            "The training process is:  False\n",
            "The reward is:  -0.620417469537718\n",
            "The training process is:  False\n",
            "The reward is:  -0.6234284896395316\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.0101, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(-0.0757, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 122 | Ep_r: -3\n",
            "The reward is:  -0.7642498334486071\n",
            "The training process is:  False\n",
            "The reward is:  -0.43286384163279557\n",
            "The training process is:  False\n",
            "The reward is:  -0.2498675500918123\n",
            "The training process is:  False\n",
            "The reward is:  -0.2538110660787231\n",
            "The training process is:  False\n",
            "The reward is:  -0.2653822960672775\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(3.3079, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.4906, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 123 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.8400271520404499\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.5908050280827648\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.3021, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.3651, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 124 | Ep_r: -3\n",
            "The reward is:  -0.693448273869187\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.6115090776667608\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.4107796252618837\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.3896, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.3525, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 125 | Ep_r: -3\n",
            "The reward is:  -0.26552359587243896\n",
            "The training process is:  False\n",
            "The reward is:  -0.15874747956777038\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(0.9386, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.1940, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 126 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.8197077225321177\n",
            "The training process is:  False\n",
            "The reward is:  -0.8189963718736643\n",
            "The training process is:  False\n",
            "The reward is:  -0.7959886350792341\n",
            "The training process is:  False\n",
            "The reward is:  -0.7947470548299733\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.7102, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.2019, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 127 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.7708952\n",
            "*******$$The Critic loss $$********:  tensor(5.0022, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.3776, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.7813143212324964\n",
            "The training process is:  False\n",
            "The reward is:  -0.7787472421669748\n",
            "The training process is:  False\n",
            "The reward is:  -0.6011134986973914\n",
            "The training process is:  False\n",
            "The reward is:  -0.34378423723339\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.4459, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.6252, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 128 | Ep_r: -3\n",
            "The reward is:  -0.8073113688715736\n",
            "The training process is:  False\n",
            "The reward is:  -0.7226416054270244\n",
            "The training process is:  False\n",
            "The reward is:  -0.7385625406833498\n",
            "The training process is:  False\n",
            "The reward is:  -0.732630748890334\n",
            "The training process is:  False\n",
            "The reward is:  -0.7471560316084308\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.4661, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.5907, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 129 | Ep_r: -3\n",
            "The reward is:  -0.8067503718592292\n",
            "The training process is:  False\n",
            "The reward is:  -0.4024334422060102\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.20660797005725912\n",
            "The training process is:  False\n",
            "The reward is:  -0.6\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(6.4170, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(4.9916, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 130 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.7158899799483267\n",
            "The training process is:  False\n",
            "The reward is:  -0.6547953132949055\n",
            "The training process is:  False\n",
            "The reward is:  -0.6422801467280053\n",
            "The training process is:  False\n",
            "The reward is:  -0.6578526478136484\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(4.2918, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.7053, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 131 | Ep_r: -3\n",
            "The reward is:  -0.823114473527283\n",
            "The training process is:  False\n",
            "The reward is:  -0.5894670194658216\n",
            "The training process is:  False\n",
            "The reward is:  -0.7642498334486071\n",
            "The training process is:  False\n",
            "The reward is:  -0.7549107826635555\n",
            "The training process is:  False\n",
            "The reward is:  -0.7489668496956072\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.9185, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.6412, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 132 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.7569163\n",
            "*******$$The Critic loss $$********:  tensor(4.9843, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.3653, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.5390326392551238\n",
            "The training process is:  False\n",
            "The reward is:  -0.6776061751043455\n",
            "The training process is:  False\n",
            "The reward is:  -0.8258413392758447\n",
            "The training process is:  False\n",
            "The reward is:  -0.8206714633880537\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(0.7642, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.2084, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 133 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.6765321001682653\n",
            "The training process is:  False\n",
            "The reward is:  -0.6593320186437606\n",
            "The training process is:  False\n",
            "The reward is:  -0.39711682231284046\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(3.4785, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.7398, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 134 | Ep_r: -3\n",
            "The reward is:  -0.8491006278576408\n",
            "The training process is:  False\n",
            "The reward is:  -0.3924214387880879\n",
            "The training process is:  False\n",
            "The reward is:  -0.3996196878160383\n",
            "The training process is:  False\n",
            "The reward is:  -0.6574394144517319\n",
            "The training process is:  False\n",
            "The reward is:  -0.21092691800099242\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.4681, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.5421, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 135 | Ep_r: -3\n",
            "The reward is:  -0.8324990696607134\n",
            "The training process is:  False\n",
            "The reward is:  -0.7294895820243628\n",
            "The training process is:  False\n",
            "The reward is:  -0.5447093757968836\n",
            "The training process is:  False\n",
            "The reward is:  -0.5733926863973968\n",
            "The training process is:  False\n",
            "The reward is:  -0.6548953860177652\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(3.4898, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.3284, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 136 | Ep_r: -3\n",
            "The reward is:  -0.8189963718736643\n",
            "The training process is:  False\n",
            "The reward is:  -0.8186247888760667\n",
            "The training process is:  False\n",
            "The reward is:  -0.6730487828537132\n",
            "The training process is:  False\n",
            "The reward is:  -0.6653990624212714\n",
            "The training process is:  False\n",
            "The reward is:  -0.5907999343845524\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.5227, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.0390, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 137 | Ep_r: -3\n",
            "The reward is:  -0.732361575105058\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.7946815\n",
            "*******$$The Critic loss $$********:  tensor(5.1217, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.4085, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.5379607993172548\n",
            "The training process is:  False\n",
            "The reward is:  -0.5616292098398207\n",
            "The training process is:  False\n",
            "The reward is:  -0.5568952075502441\n",
            "The training process is:  False\n",
            "The reward is:  -0.8506471281502398\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.7935, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.3236, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 138 | Ep_r: -3\n",
            "The reward is:  -0.8560965294444033\n",
            "The training process is:  False\n",
            "The reward is:  -0.6937555998402753\n",
            "The training process is:  False\n",
            "The reward is:  -0.7064454096045674\n",
            "The training process is:  False\n",
            "The reward is:  -0.5215923024363215\n",
            "The training process is:  False\n",
            "The reward is:  -0.6415146022235951\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.3706, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.7638, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 139 | Ep_r: -3\n",
            "The reward is:  -0.8085123372745862\n",
            "The training process is:  False\n",
            "The reward is:  -0.47405820055497194\n",
            "The training process is:  False\n",
            "The reward is:  -0.26363257758797387\n",
            "The training process is:  False\n",
            "The reward is:  -0.2531818854103517\n",
            "The training process is:  False\n",
            "The reward is:  -0.5455082598911813\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(5.2340, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.1081, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 140 | Ep_r: -3\n",
            "The reward is:  -0.7009691982638997\n",
            "The training process is:  False\n",
            "The reward is:  -0.7032282612380529\n",
            "The training process is:  False\n",
            "The reward is:  -0.7128528460098783\n",
            "The training process is:  False\n",
            "The reward is:  -0.7170460169117109\n",
            "The training process is:  False\n",
            "The reward is:  -0.721129145548238\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.8784, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.5107, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 141 | Ep_r: -3\n",
            "The reward is:  -0.5459051210544711\n",
            "The training process is:  False\n",
            "The reward is:  -0.40920013014237977\n",
            "The training process is:  False\n",
            "The reward is:  -0.6864951873643514\n",
            "The training process is:  False\n",
            "The reward is:  -0.5049724509151796\n",
            "The training process is:  False\n",
            "The reward is:  -0.6217939215898161\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(4.2758, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.7146, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 142 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.8226002\n",
            "*******$$The Critic loss $$********:  tensor(5.1861, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.3322, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.806499655815076\n",
            "The training process is:  False\n",
            "The reward is:  -0.8052649872669086\n",
            "The training process is:  False\n",
            "The reward is:  -0.6593763847301255\n",
            "The training process is:  False\n",
            "The reward is:  -0.655098687204102\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.8313, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.7475, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 143 | Ep_r: -3\n",
            "The reward is:  -0.7774991634603113\n",
            "The training process is:  False\n",
            "The reward is:  -0.48743266628296816\n",
            "The training process is:  False\n",
            "The reward is:  -0.48478027337817364\n",
            "The training process is:  False\n",
            "The reward is:  -0.24970954783111918\n",
            "The training process is:  False\n",
            "The reward is:  -0.4128705400508319\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(4.1152, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.8756, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 144 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.8279567873986153\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.6543292761170412\n",
            "The training process is:  False\n",
            "The reward is:  -0.6459838020326734\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.3720, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.5769, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 145 | Ep_r: -3\n",
            "The reward is:  -0.8438979403416212\n",
            "The training process is:  False\n",
            "The reward is:  -0.7352376736003858\n",
            "The training process is:  False\n",
            "The reward is:  -0.5790146679820426\n",
            "The training process is:  False\n",
            "The reward is:  -0.7247473257723721\n",
            "The training process is:  False\n",
            "The reward is:  -0.4968879495162886\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.8223, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.2960, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 146 | Ep_r: -3\n",
            "The reward is:  -0.6578239627794903\n",
            "The training process is:  False\n",
            "The reward is:  -0.8413467540721612\n",
            "The training process is:  False\n",
            "The reward is:  -0.46951481533354134\n",
            "The training process is:  False\n",
            "The reward is:  -0.3400151130362303\n",
            "The training process is:  False\n",
            "The reward is:  -0.3342568525348678\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(4.9789, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.6992, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 147 | Ep_r: -3\n",
            "The reward is:  -0.7921558713447828\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  0.19037926\n",
            "*******$$The Critic loss $$********:  tensor(0.7257, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.5118, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.7874255218114797\n",
            "The training process is:  False\n",
            "The reward is:  -0.4216932824437367\n",
            "The training process is:  False\n",
            "The reward is:  -0.549065430839078\n",
            "The training process is:  False\n",
            "The reward is:  -0.5330793578855941\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(0.6631, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.5161, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 148 | Ep_r: -3\n",
            "The reward is:  -0.4016738275322565\n",
            "The training process is:  False\n",
            "The reward is:  -0.3975312012966241\n",
            "The training process is:  False\n",
            "The reward is:  -0.3878519172947269\n",
            "The training process is:  False\n",
            "The reward is:  -0.7975987158314755\n",
            "The training process is:  False\n",
            "The reward is:  -0.1712829810412381\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.0728, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.3996, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 149 | Ep_r: -3\n",
            "The reward is:  -0.6\n",
            "The training process is:  False\n",
            "The reward is:  -0.6236400077888369\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.7991419168520468\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.3504, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.7335, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 150 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.7933298528512825\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.7178082946230524\n",
            "The training process is:  False\n",
            "The reward is:  -0.7221984418958572\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.3200, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.8456, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 151 | Ep_r: -3\n",
            "The reward is:  -0.816847224328137\n",
            "The training process is:  False\n",
            "The reward is:  -0.6054130313599775\n",
            "The training process is:  False\n",
            "The reward is:  -0.6842358106316142\n",
            "The training process is:  False\n",
            "The reward is:  -0.6264910398002723\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.7013, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.1062, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 152 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.7714216\n",
            "*******$$The Critic loss $$********:  tensor(5.0132, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.3687, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.722692278090437\n",
            "The training process is:  False\n",
            "The reward is:  -0.5585723544541048\n",
            "The training process is:  False\n",
            "The reward is:  -0.7787930618158627\n",
            "The training process is:  False\n",
            "The reward is:  -0.7098123697154934\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.8891, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.3431, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 153 | Ep_r: -3\n",
            "The reward is:  -0.8117389744281862\n",
            "The training process is:  False\n",
            "The reward is:  -0.810471252434143\n",
            "The training process is:  False\n",
            "The reward is:  -0.8080527508788744\n",
            "The training process is:  False\n",
            "The reward is:  -0.7931568282090409\n",
            "The training process is:  False\n",
            "The reward is:  -0.790458524938638\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.6913, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.0493, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 154 | Ep_r: -3\n",
            "The reward is:  -0.5930482701593005\n",
            "The training process is:  False\n",
            "The reward is:  -0.7523194940353279\n",
            "The training process is:  False\n",
            "The reward is:  -0.7623831414633603\n",
            "The training process is:  False\n",
            "The reward is:  -0.5581880676778918\n",
            "The training process is:  False\n",
            "The reward is:  -0.48317493659470756\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.8364, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.3072, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 155 | Ep_r: -3\n",
            "The reward is:  -0.8246745754754062\n",
            "The training process is:  False\n",
            "The reward is:  -0.6695097641572131\n",
            "The training process is:  False\n",
            "The reward is:  -0.6611009678112476\n",
            "The training process is:  False\n",
            "The reward is:  -0.6548433912906427\n",
            "The training process is:  False\n",
            "The reward is:  -0.8367763410399046\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.7987, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.2661, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 156 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.5333777880712282\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.2353, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.2263, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 157 | Ep_r: -3\n",
            "The reward is:  -0.7510021627817116\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.780195\n",
            "*******$$The Critic loss $$********:  tensor(5.1945, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.3195, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.45337660638543414\n",
            "The training process is:  False\n",
            "The reward is:  -0.44938126278904883\n",
            "The training process is:  False\n",
            "The reward is:  -0.6156173454803536\n",
            "The training process is:  False\n",
            "The reward is:  -0.6026696191072987\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.0116, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.5413, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 158 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.732361575105058\n",
            "The training process is:  False\n",
            "The reward is:  -0.47924100400972636\n",
            "The training process is:  False\n",
            "The reward is:  -0.7491729418654756\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.5220, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.3079, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 159 | Ep_r: -3\n",
            "The reward is:  -0.751536179309055\n",
            "The training process is:  False\n",
            "The reward is:  -0.3692741964099926\n",
            "The training process is:  False\n",
            "The reward is:  -0.5616851483353795\n",
            "The training process is:  False\n",
            "The reward is:  -0.7168635712261454\n",
            "The training process is:  False\n",
            "The reward is:  -0.4871757007086138\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(3.2337, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.6236, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 160 | Ep_r: -3\n",
            "The reward is:  -0.8078064554582685\n",
            "The training process is:  False\n",
            "The reward is:  -0.7083068059235886\n",
            "The training process is:  False\n",
            "The reward is:  -0.8421234031407183\n",
            "The training process is:  False\n",
            "The reward is:  -0.84034444578239\n",
            "The training process is:  False\n",
            "The reward is:  -0.8367763410399046\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.8445, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.3890, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 161 | Ep_r: -3\n",
            "The reward is:  -0.6428513084845067\n",
            "The training process is:  False\n",
            "The reward is:  -0.6536240288645072\n",
            "The training process is:  False\n",
            "The reward is:  -0.5409288181042958\n",
            "The training process is:  False\n",
            "The reward is:  -0.645984402131659\n",
            "The training process is:  False\n",
            "The reward is:  -0.6221166027699574\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(3.5770, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.5275, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 162 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.7909715\n",
            "*******$$The Critic loss $$********:  tensor(4.9982, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.3904, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.6348902339973078\n",
            "The training process is:  False\n",
            "The reward is:  -0.6463010559870641\n",
            "The training process is:  False\n",
            "The reward is:  -0.6590980970946673\n",
            "The training process is:  False\n",
            "The reward is:  -0.5788084511147186\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(0.7712, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.4305, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 163 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.2303, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.5473, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 164 | Ep_r: -3\n",
            "The reward is:  -0.6839436916281525\n",
            "The training process is:  False\n",
            "The reward is:  -0.3717550555367953\n",
            "The training process is:  False\n",
            "The reward is:  -0.4538901562437962\n",
            "The training process is:  False\n",
            "The reward is:  0.11651180531457998\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(4.1986, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(2.6367, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 165 | Ep_r: -3\n",
            "The reward is:  -0.6916667842727927\n",
            "The training process is:  False\n",
            "The reward is:  -0.3912878164173223\n",
            "The training process is:  False\n",
            "The reward is:  -0.7069408358044249\n",
            "The training process is:  False\n",
            "The reward is:  -0.7139192564095552\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.4577, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.1296, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 166 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.5579259176412853\n",
            "The training process is:  False\n",
            "The reward is:  -0.555734420242771\n",
            "The training process is:  False\n",
            "The reward is:  -0.2879771221046005\n",
            "The training process is:  False\n",
            "The reward is:  -0.39876495757504077\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(5.4266, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.8971, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 167 | Ep_r: -3\n",
            "The reward is:  -0.4261507056203834\n",
            "The training process is:  False\n",
            "The reward is:  -0.7012322702262273\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.7549404\n",
            "*******$$The Critic loss $$********:  tensor(8.2573, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.1764, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.3665135641332924\n",
            "The training process is:  False\n",
            "The reward is:  -0.7035227333811764\n",
            "The training process is:  False\n",
            "The reward is:  -0.36348271651427055\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.4734, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.9292, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 168 | Ep_r: -3\n",
            "The reward is:  -0.7342354945596822\n",
            "The training process is:  False\n",
            "The reward is:  -0.27556663778496715\n",
            "The training process is:  False\n",
            "The reward is:  -0.28683710891546016\n",
            "The training process is:  False\n",
            "The reward is:  -0.2810801058187352\n",
            "The training process is:  False\n",
            "The reward is:  -0.5125013765385178\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(4.1241, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.2410, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 169 | Ep_r: -3\n",
            "The reward is:  -0.5324796103632099\n",
            "The training process is:  False\n",
            "The reward is:  -0.5761090250817629\n",
            "The training process is:  False\n",
            "The reward is:  -0.3678058135763825\n",
            "The training process is:  False\n",
            "The reward is:  -0.3678655712208495\n",
            "The training process is:  False\n",
            "The reward is:  -0.6208252433373016\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(3.3051, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.2381, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 170 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.7280073154969372\n",
            "The training process is:  False\n",
            "The reward is:  -0.5808708539227047\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(4.3853, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.5577, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 171 | Ep_r: -3\n",
            "The reward is:  -0.8256723381084768\n",
            "The training process is:  False\n",
            "The reward is:  -0.8202562638473025\n",
            "The training process is:  False\n",
            "The reward is:  -0.8173363033757581\n",
            "The training process is:  False\n",
            "The reward is:  -0.8413467540721612\n",
            "The training process is:  False\n",
            "The reward is:  -0.8391273318799485\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.5366, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.0372, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 172 | Ep_r: -3\n",
            "The reward is:  -0.36285646485656675\n",
            "The training process is:  False\n",
            "The reward is:  -0.7928776351526509\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.8038015\n",
            "*******$$The Critic loss $$********:  tensor(3.9340, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(2.1676, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.5764681391299277\n",
            "The training process is:  False\n",
            "The reward is:  -0.7866065918159049\n",
            "The training process is:  False\n",
            "The reward is:  -0.5731948938803809\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(0.4296, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.4804, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 173 | Ep_r: -3\n",
            "The reward is:  -0.15119903625603737\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(0.5762, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.4645, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 174 | Ep_r: -3\n",
            "The reward is:  -0.48118475435702057\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.310392613546077\n",
            "The training process is:  False\n",
            "The reward is:  -0.3054983298938204\n",
            "The training process is:  False\n",
            "The reward is:  -0.35949550383456014\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(4.1940, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.7119, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 175 | Ep_r: -3\n",
            "The reward is:  -0.7963475500656695\n",
            "The training process is:  False\n",
            "The reward is:  -0.4711653101606358\n",
            "The training process is:  False\n",
            "The reward is:  -0.4590824155850572\n",
            "The training process is:  False\n",
            "The reward is:  -0.6454308476505632\n",
            "The training process is:  False\n",
            "The reward is:  -0.3841917447741108\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(3.6591, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.6736, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 176 | Ep_r: -3\n",
            "The reward is:  -0.6081919828396979\n",
            "The training process is:  False\n",
            "The reward is:  -0.6325845795545741\n",
            "The training process is:  False\n",
            "The reward is:  -0.7062449768911057\n",
            "The training process is:  False\n",
            "The reward is:  -0.7022126797403098\n",
            "The training process is:  False\n",
            "The reward is:  -0.5246090601781142\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.5282, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.3528, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 177 | Ep_r: -3\n",
            "The reward is:  -0.415979197355993\n",
            "The training process is:  False\n",
            "The reward is:  -0.654753153995434\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.5248378833660279\n",
            "The training process is:  False\n",
            "The reward is:  -0.25769142748985596\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(4.2933, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.8962, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 178 | Ep_r: -3\n",
            "The reward is:  -0.5192149278784406\n",
            "The training process is:  False\n",
            "The reward is:  -0.349714578112499\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  0.7093655\n",
            "*******$$The Critic loss $$********:  tensor(0.1933, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.0438, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.3051716534747004\n",
            "The training process is:  False\n",
            "The reward is:  -0.2401476410450783\n",
            "The training process is:  False\n",
            "The reward is:  -0.24422002518577637\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.6398, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.4621, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 179 | Ep_r: -3\n",
            "The reward is:  -0.35178191388217667\n",
            "The training process is:  False\n",
            "The reward is:  -0.2172605152259802\n",
            "The training process is:  False\n",
            "The reward is:  -0.23076063742745156\n",
            "The training process is:  False\n",
            "The reward is:  -0.3390720867783053\n",
            "The training process is:  False\n",
            "The reward is:  -0.5340003421750689\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(5.1712, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.8317, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 180 | Ep_r: -3\n",
            "The reward is:  -0.48834731800281456\n",
            "The training process is:  False\n",
            "The reward is:  -0.33454002760762835\n",
            "The training process is:  False\n",
            "The reward is:  -0.5074714129678005\n",
            "The training process is:  False\n",
            "The reward is:  -0.7147136050865406\n",
            "The training process is:  False\n",
            "The reward is:  -0.11943210781315972\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(3.2152, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.5890, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 181 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.7594014195806569\n",
            "The training process is:  False\n",
            "The reward is:  -0.6262527003800226\n",
            "The training process is:  False\n",
            "The reward is:  -0.7505995941295207\n",
            "The training process is:  False\n",
            "The reward is:  -0.7414387683284357\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.4563, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.1696, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 182 | Ep_r: -3\n",
            "The reward is:  -0.8011952776072157\n",
            "The training process is:  False\n",
            "The reward is:  -0.7967430786131451\n",
            "The training process is:  False\n",
            "The reward is:  -0.5586606336968486\n",
            "The training process is:  False\n",
            "The reward is:  -0.5510020430240801\n",
            "The training process is:  False\n",
            "The reward is:  -0.5463448193611293\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(3.8045, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.9389, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 183 | Ep_r: -3\n",
            "The reward is:  -0.5725547782610257\n",
            "The training process is:  False\n",
            "The reward is:  -0.36183013585327684\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.7742174\n",
            "*******$$The Critic loss $$********:  tensor(3.4490, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.4317, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.836900883031829\n",
            "The training process is:  False\n",
            "The reward is:  -0.4720352910436912\n",
            "The training process is:  False\n",
            "The reward is:  -0.47039028792805065\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(0.7741, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.4919, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 184 | Ep_r: -3\n",
            "The reward is:  -0.6431134845139835\n",
            "The training process is:  False\n",
            "The reward is:  -0.6429839297220286\n",
            "The training process is:  False\n",
            "The reward is:  -0.6680017157380912\n",
            "The training process is:  False\n",
            "The reward is:  -0.6710946860429481\n",
            "The training process is:  False\n",
            "The reward is:  -0.6404887948184913\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.7545, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.1535, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 185 | Ep_r: -3\n",
            "The reward is:  -0.8035857462335063\n",
            "The training process is:  False\n",
            "The reward is:  -0.7116812228216023\n",
            "The training process is:  False\n",
            "The reward is:  -0.46811407023716606\n",
            "The training process is:  False\n",
            "The reward is:  -0.47539714124499516\n",
            "The training process is:  False\n",
            "The reward is:  -0.7169617121112133\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(3.6322, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.8013, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 186 | Ep_r: -3\n",
            "The reward is:  -0.6248967884724239\n",
            "The training process is:  False\n",
            "The reward is:  -0.4509946493304735\n",
            "The training process is:  False\n",
            "The reward is:  -0.6158342590006981\n",
            "The training process is:  False\n",
            "The reward is:  -0.4166132250216591\n",
            "The training process is:  False\n",
            "The reward is:  -0.3761792969355177\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(4.6928, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.4990, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 187 | Ep_r: -3\n",
            "The reward is:  -0.5666274057331876\n",
            "The training process is:  False\n",
            "The reward is:  -0.4449211083046675\n",
            "The training process is:  False\n",
            "The reward is:  -0.793878524409584\n",
            "The training process is:  False\n",
            "The reward is:  -0.6655623568123428\n",
            "The training process is:  False\n",
            "The reward is:  -0.6560773984006459\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.5261, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.8921, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 188 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.7570552\n",
            "*******$$The Critic loss $$********:  tensor(1.0929, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.4171, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(0.4174, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 189 | Ep_r: -3\n",
            "The reward is:  -0.8404630778645741\n",
            "The training process is:  False\n",
            "The reward is:  -0.2634070405523664\n",
            "The training process is:  False\n",
            "The reward is:  -0.2607868033535562\n",
            "The training process is:  False\n",
            "The reward is:  -0.06154884607133728\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(3.3358, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(2.1122, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 190 | Ep_r: -3\n",
            "The reward is:  -0.8402256215405632\n",
            "The training process is:  False\n",
            "The reward is:  -0.6737814507248024\n",
            "The training process is:  False\n",
            "The reward is:  -0.7678069990372967\n",
            "The training process is:  False\n",
            "The reward is:  -0.8379919132692815\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.9451, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.0359, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 191 | Ep_r: -3\n",
            "The reward is:  -0.8491357411851255\n",
            "The training process is:  False\n",
            "The reward is:  -0.8459428853849775\n",
            "The training process is:  False\n",
            "The reward is:  -0.7583927873796641\n",
            "The training process is:  False\n",
            "The reward is:  -0.3724770233325934\n",
            "The training process is:  False\n",
            "The reward is:  -0.4350261019679321\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(4.1112, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.8809, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 192 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.678715915185113\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.42676780302370326\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.2989, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.8347, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 193 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.8472691727452013\n",
            "The training process is:  False\n",
            "The reward is:  -0.586383890942889\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  0.5341552\n",
            "*******$$The Critic loss $$********:  tensor(1.7667, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.4088, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.5982808496345802\n",
            "The training process is:  False\n",
            "The reward is:  -0.5848444629308275\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.0720, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.0460, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 194 | Ep_r: -3\n",
            "The reward is:  -0.72463502478808\n",
            "The training process is:  False\n",
            "The reward is:  -0.3178082946230524\n",
            "The training process is:  False\n",
            "The reward is:  -0.333998509194609\n",
            "The training process is:  False\n",
            "The reward is:  -0.19120957387521376\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.3242, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.0010, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 195 | Ep_r: -3\n",
            "The reward is:  -0.4065020193652461\n",
            "The training process is:  False\n",
            "The reward is:  -0.3864209132233515\n",
            "The training process is:  False\n",
            "The reward is:  -0.7040792497047765\n",
            "The training process is:  False\n",
            "The reward is:  -0.6951875107285975\n",
            "The training process is:  False\n",
            "The reward is:  -0.6906072391811227\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.5579, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.0985, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 196 | Ep_r: -3\n",
            "The reward is:  -0.47964134174073303\n",
            "The training process is:  False\n",
            "The reward is:  -0.48005910342542946\n",
            "The training process is:  False\n",
            "The reward is:  -0.48054350331686047\n",
            "The training process is:  False\n",
            "The reward is:  -0.4810932132439622\n",
            "The training process is:  False\n",
            "The reward is:  -0.2250313747295222\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(3.8033, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(2.0908, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 197 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.8520268201472858\n",
            "The training process is:  False\n",
            "The reward is:  -0.5366659770771841\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.4908, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.5372, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 198 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.7440594700619411\n",
            "The training process is:  False\n",
            "The reward is:  -0.7404410059473342\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.8174682\n",
            "*******$$The Critic loss $$********:  tensor(3.1330, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.8074, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(0.8853, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.1975, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 199 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.6\n",
            "The training process is:  False\n",
            "The reward is:  -0.7572212105626401\n",
            "The training process is:  False\n",
            "The reward is:  -0.6176353975863484\n",
            "The training process is:  False\n",
            "The reward is:  -0.39770212418415224\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(3.7464, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.2645, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 200 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.7040792497047765\n",
            "The training process is:  False\n",
            "The reward is:  -0.6959549532726165\n",
            "The training process is:  False\n",
            "The reward is:  -0.5473254486346648\n",
            "The training process is:  False\n",
            "The reward is:  -0.5005984621536106\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(3.1264, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.2202, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 201 | Ep_r: -3\n",
            "The reward is:  -0.718454778152615\n",
            "The training process is:  False\n",
            "The reward is:  -0.5692823399648766\n",
            "The training process is:  False\n",
            "The reward is:  -0.6985966265234809\n",
            "The training process is:  False\n",
            "The reward is:  -0.5681299099724383\n",
            "The training process is:  False\n",
            "The reward is:  -0.5657031656196085\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(4.0182, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.5609, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 202 | Ep_r: -3\n",
            "The reward is:  -0.3700098650858198\n",
            "The training process is:  False\n",
            "The reward is:  -0.4884515137291937\n",
            "The training process is:  False\n",
            "The reward is:  -0.48521850025969615\n",
            "The training process is:  False\n",
            "The reward is:  -0.4471978503732591\n",
            "The training process is:  False\n",
            "The reward is:  -0.19597901496524556\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(4.6890, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.7922, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 203 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.689009512264181\n",
            "The training process is:  False\n",
            "The reward is:  -0.8307157740542639\n",
            "The training process is:  False\n",
            "The reward is:  -0.7196372857804614\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.8213753\n",
            "*******$$The Critic loss $$********:  tensor(4.0814, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(2.5503, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(0.8927, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(-0.7207, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 204 | Ep_r: -3\n",
            "The reward is:  -0.7758013134187985\n",
            "The training process is:  False\n",
            "The reward is:  -0.43487592878580517\n",
            "The training process is:  False\n",
            "The reward is:  -0.43324135648275225\n",
            "The training process is:  False\n",
            "The reward is:  -0.5947624592619624\n",
            "The training process is:  False\n",
            "The reward is:  -0.6619478200521959\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(3.0986, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.1076, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 205 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.7227906475271881\n",
            "The training process is:  False\n",
            "The reward is:  -0.7187491622304736\n",
            "The training process is:  False\n",
            "The reward is:  -0.7131469002254264\n",
            "The training process is:  False\n",
            "The reward is:  -0.39550435359749264\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(3.0434, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.8187, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 206 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.8114754445719864\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.1500, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.2364, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 207 | Ep_r: -3\n",
            "The reward is:  -0.8221064243473059\n",
            "The training process is:  False\n",
            "The reward is:  -0.8041271137143461\n",
            "The training process is:  False\n",
            "The reward is:  -0.8223597385851003\n",
            "The training process is:  False\n",
            "The reward is:  -0.821673771710824\n",
            "The training process is:  False\n",
            "The reward is:  -0.8236878884062484\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.3707, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.5589, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 208 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.8177952353982173\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.7555779\n",
            "*******$$The Critic loss $$********:  tensor(4.0139, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(2.6200, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.8080220091325347\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(0.7316, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(-1.4633, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 209 | Ep_r: -3\n",
            "The reward is:  -0.561475160953371\n",
            "The training process is:  False\n",
            "The reward is:  -0.5751911408891367\n",
            "The training process is:  False\n",
            "The reward is:  -0.5747491113123875\n",
            "The training process is:  False\n",
            "The reward is:  -0.5596345746825989\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(3.8664, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.3971, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 210 | Ep_r: -3\n",
            "The reward is:  -0.675975831759023\n",
            "The training process is:  False\n",
            "The reward is:  -0.6703691589303284\n",
            "The training process is:  False\n",
            "The reward is:  -0.6590980970946673\n",
            "The training process is:  False\n",
            "The reward is:  -0.6468898840990361\n",
            "The training process is:  False\n",
            "The reward is:  -0.38238498456214143\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(3.6632, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.1375, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 211 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.8070314068682762\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.7995572142318348\n",
            "The training process is:  False\n",
            "The reward is:  -0.7601836742563198\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.7946, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.7752, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 212 | Ep_r: -3\n",
            "The reward is:  -0.35916235040318345\n",
            "The training process is:  False\n",
            "The reward is:  -0.1025948398724283\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(0.3413, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.2860, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 213 | Ep_r: -3\n",
            "The reward is:  -0.6274169116736894\n",
            "The training process is:  False\n",
            "The reward is:  -0.48625220984143736\n",
            "The training process is:  False\n",
            "The reward is:  -0.513895616717458\n",
            "The training process is:  False\n",
            "The reward is:  -0.6545597438668536\n",
            "The training process is:  False\n",
            "The reward is:  -0.850836024005104\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.7790, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.2827, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 214 | Ep_r: -3\n",
            "The reward is:  -0.5635929715632904\n",
            "The training process is:  False\n",
            "The reward is:  -0.556464267331141\n",
            "The training process is:  False\n",
            "The reward is:  -0.5280399800154271\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.7899626\n",
            "*******$$The Critic loss $$********:  tensor(6.1667, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.7140, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.4039325579309615\n",
            "The training process is:  False\n",
            "The reward is:  -0.545937658794292\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(0.2870, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.2171, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 215 | Ep_r: -3\n",
            "The reward is:  -0.6041999826690697\n",
            "The training process is:  False\n",
            "The reward is:  -0.6939871322660653\n",
            "The training process is:  False\n",
            "The reward is:  -0.5684049246350282\n",
            "The training process is:  False\n",
            "The reward is:  -0.4144696675197105\n",
            "The training process is:  False\n",
            "The reward is:  -0.5631437665810817\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(3.4566, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.3752, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 216 | Ep_r: -3\n",
            "The reward is:  -0.7781027422443847\n",
            "The training process is:  False\n",
            "The reward is:  -0.643313712087368\n",
            "The training process is:  False\n",
            "The reward is:  -0.7702013034015247\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.7624976370393091\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.3450, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.6051, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 217 | Ep_r: -3\n",
            "The reward is:  -0.8256723381084766\n",
            "The training process is:  False\n",
            "The reward is:  -0.5432010651131929\n",
            "The training process is:  False\n",
            "The reward is:  -0.5300095033694017\n",
            "The training process is:  False\n",
            "The reward is:  -0.42241993144695583\n",
            "The training process is:  False\n",
            "The reward is:  -0.7503620828339068\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.8208, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.4743, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 218 | Ep_r: -3\n",
            "The reward is:  -0.8340246548860348\n",
            "The training process is:  False\n",
            "The reward is:  -0.8353286972335796\n",
            "The training process is:  False\n",
            "The reward is:  -0.8345619056646646\n",
            "The training process is:  False\n",
            "The reward is:  -0.4353075054510168\n",
            "The training process is:  False\n",
            "The reward is:  -0.4367555633120186\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.3915, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.7186, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 219 | Ep_r: -3\n",
            "The reward is:  -0.5999288994217647\n",
            "The training process is:  False\n",
            "The reward is:  -0.4319371847915283\n",
            "The training process is:  False\n",
            "The reward is:  -0.18397346902221146\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.6855, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(-0.3591, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 220 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.7502036\n",
            "*******$$The Critic loss $$********:  tensor(5.0361, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.0999, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.6966060150136035\n",
            "The training process is:  False\n",
            "The reward is:  -0.7898288305858561\n",
            "The training process is:  False\n",
            "The reward is:  -0.31297170813682074\n",
            "The training process is:  False\n",
            "The reward is:  -0.7824996383041057\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(3.3187, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.0108, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 221 | Ep_r: -3\n",
            "The reward is:  -0.8204122392720716\n",
            "The training process is:  False\n",
            "The reward is:  -0.6868537011770273\n",
            "The training process is:  False\n",
            "The reward is:  -0.6815300492813048\n",
            "The training process is:  False\n",
            "The reward is:  -0.47183429584144054\n",
            "The training process is:  False\n",
            "The reward is:  -0.6593320186437606\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(4.3945, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.6552, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 222 | Ep_r: -3\n",
            "The reward is:  -0.8565897231949601\n",
            "The training process is:  False\n",
            "The reward is:  -0.5285088003023761\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.40564710391812014\n",
            "The training process is:  False\n",
            "The reward is:  -0.40200078958431795\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(4.3607, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(3.4901, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 223 | Ep_r: -3\n",
            "The reward is:  -0.7941145853288554\n",
            "The training process is:  False\n",
            "The reward is:  -0.6147823501169075\n",
            "The training process is:  False\n",
            "The reward is:  -0.4771074354395899\n",
            "The training process is:  False\n",
            "The reward is:  -0.46726123463599994\n",
            "The training process is:  False\n",
            "The reward is:  -0.5251755793178756\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(4.2421, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.8492, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 224 | Ep_r: -3\n",
            "The reward is:  -0.7861108080650634\n",
            "The training process is:  False\n",
            "The reward is:  -0.5874764065154622\n",
            "The training process is:  False\n",
            "The reward is:  -0.5745375053243844\n",
            "The training process is:  False\n",
            "The reward is:  -0.5672526024187791\n",
            "The training process is:  False\n",
            "The reward is:  -0.5603396581163375\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.9367, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.3173, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 225 | Ep_r: -3\n",
            "The reward is:  -0.7873847917841317\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.8260858\n",
            "*******$$The Critic loss $$********:  tensor(4.9281, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.4216, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.7700715056071905\n",
            "The training process is:  False\n",
            "The reward is:  -0.8032255407682116\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.8172550162385811\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(0.7001, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.1007, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 226 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.678715915185113\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.8406406670645185\n",
            "The training process is:  False\n",
            "The reward is:  -0.443234748223159\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.2049, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.7892, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 227 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.728098811959513\n",
            "The training process is:  False\n",
            "The reward is:  -0.724250570966681\n",
            "The training process is:  False\n",
            "The reward is:  -0.7079247786324286\n",
            "The training process is:  False\n",
            "The reward is:  -0.7083906568381069\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.6008, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.6041, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 228 | Ep_r: -3\n",
            "The reward is:  -0.5504434108475322\n",
            "The training process is:  False\n",
            "The reward is:  -0.5446319523633925\n",
            "The training process is:  False\n",
            "The reward is:  -0.439918066217877\n",
            "The training process is:  False\n",
            "The reward is:  -0.6336915098643284\n",
            "The training process is:  False\n",
            "The reward is:  -0.6287537726792048\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.8799, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.2020, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 229 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.8172550162385811\n",
            "The training process is:  False\n",
            "The reward is:  -0.47638737514937085\n",
            "The training process is:  False\n",
            "The reward is:  -0.20618526270104218\n",
            "The training process is:  False\n",
            "The reward is:  -0.19178003315625708\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(5.1295, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.8689, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 230 | Ep_r: -3\n",
            "The reward is:  -0.5083719635768504\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.7530539\n",
            "*******$$The Critic loss $$********:  tensor(5.2539, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.4003, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.3280384629275389\n",
            "The training process is:  False\n",
            "The reward is:  -0.32744306427454534\n",
            "The training process is:  False\n",
            "The reward is:  -0.29948269774229236\n",
            "The training process is:  False\n",
            "The reward is:  -0.7420460960490921\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.7084, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.5052, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 231 | Ep_r: -3\n",
            "The reward is:  -0.2910632057130916\n",
            "The training process is:  False\n",
            "The reward is:  -0.7038250574536057\n",
            "The training process is:  False\n",
            "The reward is:  -0.4950806946183244\n",
            "The training process is:  False\n",
            "The reward is:  -0.09944149190119811\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(3.3122, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.6204, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 232 | Ep_r: -3\n",
            "The reward is:  -0.8563514951715646\n",
            "The training process is:  False\n",
            "The reward is:  -0.6672761654289171\n",
            "The training process is:  False\n",
            "The reward is:  -0.8422199086182249\n",
            "The training process is:  False\n",
            "The reward is:  -0.8247725178809591\n",
            "The training process is:  False\n",
            "The reward is:  -0.6651724508561572\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.2718, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.3901, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 233 | Ep_r: -3\n",
            "The reward is:  -0.8109455268307878\n",
            "The training process is:  False\n",
            "The reward is:  -0.8074974182654937\n",
            "The training process is:  False\n",
            "The reward is:  -0.6772957129254822\n",
            "The training process is:  False\n",
            "The reward is:  -0.12865666957517644\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.7345, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.3118, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 234 | Ep_r: -3\n",
            "The reward is:  -0.8077756102909472\n",
            "The training process is:  False\n",
            "The reward is:  -0.6324394234875378\n",
            "The training process is:  False\n",
            "The reward is:  -0.628126393663865\n",
            "The training process is:  False\n",
            "The reward is:  -0.6231581500747988\n",
            "The training process is:  False\n",
            "The reward is:  -0.4405868724967096\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.6032, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.4323, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 235 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.778056489070422\n",
            "The training process is:  False\n",
            "The reward is:  -0.7746956278170412\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.7610394\n",
            "*******$$The Critic loss $$********:  tensor(3.6268, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.6185, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.6382771404375183\n",
            "The training process is:  False\n",
            "The reward is:  -0.5646999092806989\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.1259, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.0524, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 236 | Ep_r: -3\n",
            "The reward is:  -0.7798842325124786\n",
            "The training process is:  False\n",
            "The reward is:  -0.05143528861134365\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(0.2964, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.0501, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 237 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.2203, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.5015, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 238 | Ep_r: -3\n",
            "The reward is:  -0.8453723300293452\n",
            "The training process is:  False\n",
            "The reward is:  -0.8430446536925562\n",
            "The training process is:  False\n",
            "The reward is:  -0.7037230064306309\n",
            "The training process is:  False\n",
            "The reward is:  -0.8019005831818149\n",
            "The training process is:  False\n",
            "The reward is:  -0.7863688829149658\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(3.0382, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.4420, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 239 | Ep_r: -3\n",
            "The reward is:  -0.6814434341251279\n",
            "The training process is:  False\n",
            "The reward is:  -0.44721900811331344\n",
            "The training process is:  False\n",
            "The reward is:  -0.48088947259920367\n",
            "The training process is:  False\n",
            "The reward is:  -0.5719093940856765\n",
            "The training process is:  False\n",
            "The reward is:  -0.6278132878663287\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(3.3007, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.3093, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 240 | Ep_r: -3\n",
            "The reward is:  -0.7491729418654756\n",
            "The training process is:  False\n",
            "The reward is:  -0.7431714542926894\n",
            "The training process is:  False\n",
            "The reward is:  -0.6420437446074713\n",
            "The training process is:  False\n",
            "The reward is:  -0.6271648710368077\n",
            "The training process is:  False\n",
            "The reward is:  -0.7202181541565673\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.9064, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.2976, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 241 | Ep_r: -3\n",
            "The reward is:  -0.6570138771756223\n",
            "The training process is:  False\n",
            "The reward is:  -0.6524267327174579\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  0.43497366\n",
            "*******$$The Critic loss $$********:  tensor(1.4679, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.4173, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.6451481135485028\n",
            "The training process is:  False\n",
            "The reward is:  -0.8212642240981104\n",
            "The training process is:  False\n",
            "The reward is:  -0.6476578082774035\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.6450, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.4020, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 242 | Ep_r: -3\n",
            "The reward is:  -0.5881585107162384\n",
            "The training process is:  False\n",
            "The reward is:  -0.5681029670223745\n",
            "The training process is:  False\n",
            "The reward is:  -0.5740885707702686\n",
            "The training process is:  False\n",
            "The reward is:  -0.6181012726790902\n",
            "The training process is:  False\n",
            "The reward is:  -0.6168780466861638\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.0919, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.0202, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 243 | Ep_r: -3\n",
            "The reward is:  -0.24261677364423395\n",
            "The training process is:  False\n",
            "The reward is:  -0.6\n",
            "The training process is:  False\n",
            "The reward is:  -0.6\n",
            "The training process is:  False\n",
            "The reward is:  -0.7823688785324483\n",
            "The training process is:  False\n",
            "The reward is:  -0.3323685292925753\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(3.4857, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.3987, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 244 | Ep_r: -3\n",
            "The reward is:  -0.5687859805723771\n",
            "The training process is:  False\n",
            "The reward is:  -0.6219045532644184\n",
            "The training process is:  False\n",
            "The reward is:  -0.5466717440360878\n",
            "The training process is:  False\n",
            "The reward is:  -0.522301258821258\n",
            "The training process is:  False\n",
            "The reward is:  -0.6399913169748009\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(3.8012, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.5538, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 245 | Ep_r: -3\n",
            "The reward is:  -0.26446645469347524\n",
            "The training process is:  False\n",
            "The reward is:  -0.8026984268471964\n",
            "The training process is:  False\n",
            "The reward is:  -0.560028363314912\n",
            "The training process is:  False\n",
            "The reward is:  -0.796058547078649\n",
            "The training process is:  False\n",
            "The reward is:  -0.7927262740676319\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.3268, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.3906, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 246 | Ep_r: -3\n",
            "The reward is:  -0.702194182466658\n",
            "The training process is:  False\n",
            "The reward is:  -0.6146336265620138\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.7798375\n",
            "*******$$The Critic loss $$********:  tensor(1.2904, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.2039, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.5974411813024243\n",
            "The training process is:  False\n",
            "The reward is:  -0.8002783732361806\n",
            "The training process is:  False\n",
            "The reward is:  -0.8090903754432628\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(0.4082, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(-0.1060, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 247 | Ep_r: -3\n",
            "The reward is:  -0.6145937745415581\n",
            "The training process is:  False\n",
            "The reward is:  -0.8152765981527266\n",
            "The training process is:  False\n",
            "The reward is:  -0.5164923014894123\n",
            "The training process is:  False\n",
            "The reward is:  -0.3301717459876877\n",
            "The training process is:  False\n",
            "The reward is:  -0.43752666611061936\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(3.6932, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.4943, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 248 | Ep_r: -3\n",
            "The reward is:  -0.7494468335222465\n",
            "The training process is:  False\n",
            "The reward is:  -0.7554795142172964\n",
            "The training process is:  False\n",
            "The reward is:  -0.22738408926524004\n",
            "The training process is:  False\n",
            "The reward is:  -0.2644066779442091\n",
            "The training process is:  False\n",
            "The reward is:  -0.4713259913893869\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(5.5037, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.8443, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 249 | Ep_r: -3\n",
            "The reward is:  -0.8530156890540734\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.8537610477892222\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.0592, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.1715, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 250 | Ep_r: -3\n",
            "The reward is:  -0.5433383826134459\n",
            "The training process is:  False\n",
            "The reward is:  -0.823089440242088\n",
            "The training process is:  False\n",
            "The reward is:  -0.41118034523314534\n",
            "The training process is:  False\n",
            "The reward is:  -0.5351759978982353\n",
            "The training process is:  False\n",
            "The reward is:  -0.5685783622551366\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(3.8773, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.8171, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 251 | Ep_r: -3\n",
            "The reward is:  -0.6924143379606001\n",
            "The training process is:  False\n",
            "The reward is:  -0.6916667842727927\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.816226\n",
            "*******$$The Critic loss $$********:  tensor(1.2730, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.5333, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.6590980970946673\n",
            "The training process is:  False\n",
            "The reward is:  -0.2416749144972068\n",
            "The training process is:  False\n",
            "The reward is:  -0.3824229976922417\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(0.3189, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.5908, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 252 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.4318949708829498\n",
            "The training process is:  False\n",
            "The reward is:  -0.7305270274378096\n",
            "The training process is:  False\n",
            "The reward is:  -0.8039766902912959\n",
            "The training process is:  False\n",
            "The reward is:  -0.6015210124115488\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(3.2225, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.5808, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 253 | Ep_r: -3\n",
            "The reward is:  -0.7724828897478657\n",
            "The training process is:  False\n",
            "The reward is:  -0.7715281974212285\n",
            "The training process is:  False\n",
            "The reward is:  -0.813728510493996\n",
            "The training process is:  False\n",
            "The reward is:  -0.7692162381936499\n",
            "The training process is:  False\n",
            "The reward is:  -0.63296228398042\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.9162, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.5771, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 254 | Ep_r: -3\n",
            "The reward is:  -0.6355809393049642\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.4400286733728718\n",
            "The training process is:  False\n",
            "The reward is:  -0.47765129938273015\n",
            "The training process is:  False\n",
            "The reward is:  -0.35776830675462257\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(4.4854, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.5932, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 255 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.7607611452889029\n",
            "The training process is:  False\n",
            "The reward is:  -0.6033177386900831\n",
            "The training process is:  False\n",
            "The reward is:  -0.5654496263947724\n",
            "The training process is:  False\n",
            "The reward is:  -0.7365532532485963\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.4770, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.1655, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 256 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.09920122794339785\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(0.2889, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(-0.3654, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 257 | Ep_r: -3\n",
            "The reward is:  -0.4650537652772341\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  -0.45676\n",
            "*******$$The Critic loss $$********:  tensor(0.0948, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.1735, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.4712248093445487\n",
            "The training process is:  False\n",
            "The reward is:  -0.5095007373170679\n",
            "The training process is:  False\n",
            "The reward is:  -0.5015066379973925\n",
            "The training process is:  False\n",
            "The reward is:  -0.3144472145698627\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(3.6378, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.4546, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 258 | Ep_r: -3\n",
            "The reward is:  -0.5821409931383917\n",
            "The training process is:  False\n",
            "The reward is:  -0.8406603725326462\n",
            "The training process is:  False\n",
            "The reward is:  -0.8382977711131938\n",
            "The training process is:  False\n",
            "The reward is:  -0.835940612026288\n",
            "The training process is:  False\n",
            "The reward is:  -0.8308960678816257\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.2059, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(2.0107, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 259 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.7264885068423801\n",
            "The training process is:  False\n",
            "The reward is:  -0.4517767712772221\n",
            "The training process is:  False\n",
            "The reward is:  -0.7389832749053031\n",
            "The training process is:  False\n",
            "The reward is:  -0.4537660499652265\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.1176, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.3922, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 260 | Ep_r: -3\n",
            "The reward is:  -0.6885631387375444\n",
            "The training process is:  False\n",
            "The reward is:  -0.6893336342521916\n",
            "The training process is:  False\n",
            "The reward is:  -0.21866627432628372\n",
            "The training process is:  False\n",
            "The reward is:  -0.20083704670795344\n",
            "The training process is:  False\n",
            "The reward is:  -0.1893622925857234\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(4.7993, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.6012, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 261 | Ep_r: -3\n",
            "The reward is:  -0.8227632302741525\n",
            "The training process is:  False\n",
            "The reward is:  -0.542892285065404\n",
            "The training process is:  False\n",
            "The reward is:  -0.33349624121706384\n",
            "The training process is:  False\n",
            "The reward is:  -0.3309052528190749\n",
            "The training process is:  False\n",
            "The reward is:  -0.3297210680313875\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(5.5003, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.8875, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 262 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.7830013\n",
            "*******$$The Critic loss $$********:  tensor(4.9774, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.1002, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.6714038832486173\n",
            "The training process is:  False\n",
            "The reward is:  -0.8296246034247264\n",
            "The training process is:  False\n",
            "The reward is:  -0.8356036353457533\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.6674, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.2068, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 263 | Ep_r: -3\n",
            "The reward is:  -0.736634690689493\n",
            "The training process is:  False\n",
            "The reward is:  -0.736634690689493\n",
            "The training process is:  False\n",
            "The reward is:  -0.7319289225122431\n",
            "The training process is:  False\n",
            "The reward is:  -0.732361575105058\n",
            "The training process is:  False\n",
            "The reward is:  -0.7329630322710963\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.9927, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.3329, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 264 | Ep_r: -3\n",
            "The reward is:  -0.4723219260683037\n",
            "The training process is:  False\n",
            "The reward is:  -0.6448919285158203\n",
            "The training process is:  False\n",
            "The reward is:  -0.44464588456739185\n",
            "The training process is:  False\n",
            "The reward is:  -0.6391771004246835\n",
            "The training process is:  False\n",
            "The reward is:  -0.6340482209605467\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(4.2545, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.7113, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 265 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.8102329601418086\n",
            "The training process is:  False\n",
            "The reward is:  -0.3994990018790471\n",
            "The training process is:  False\n",
            "The reward is:  -0.5213450266193967\n",
            "The training process is:  False\n",
            "The reward is:  -0.308260870408393\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.8218, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(2.7205, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 266 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.7569749150817697\n",
            "The training process is:  False\n",
            "The reward is:  -0.2738415149808167\n",
            "The training process is:  False\n",
            "The reward is:  -0.1841591517462667\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.8509, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.5257, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 267 | Ep_r: -3\n",
            "The reward is:  -0.7388789787311711\n",
            "The training process is:  False\n",
            "The reward is:  -0.7350716997588769\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.7715861\n",
            "*******$$The Critic loss $$********:  tensor(1.2499, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.3281, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.7352378026736786\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(0.4041, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.0009, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 268 | Ep_r: -3\n",
            "The reward is:  -0.7099067057495698\n",
            "The training process is:  False\n",
            "The reward is:  -0.7094852863778509\n",
            "The training process is:  False\n",
            "The reward is:  -0.6516793855027423\n",
            "The training process is:  False\n",
            "The reward is:  -0.43667602228621777\n",
            "The training process is:  False\n",
            "The reward is:  -0.5920358951299656\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(4.0147, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.6529, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 269 | Ep_r: -3\n",
            "The reward is:  -0.5496009588653422\n",
            "The training process is:  False\n",
            "The reward is:  -0.38822074496925535\n",
            "The training process is:  False\n",
            "The reward is:  -0.3957080012217947\n",
            "The training process is:  False\n",
            "The reward is:  -0.4354463277880791\n",
            "The training process is:  False\n",
            "The reward is:  -0.4887318626937033\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(3.4817, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.4014, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 270 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.8102329601418086\n",
            "The training process is:  False\n",
            "The reward is:  -0.629749434092549\n",
            "The training process is:  False\n",
            "The reward is:  -0.5868876224782125\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(4.2875, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.7368, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 271 | Ep_r: -3\n",
            "The reward is:  -0.10904310698603159\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(0.5700, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.4637, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 272 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.7259081093100852\n",
            "The training process is:  False\n",
            "The reward is:  -0.8324550117004748\n",
            "The training process is:  False\n",
            "The reward is:  -0.6897140024213516\n",
            "The training process is:  False\n",
            "The reward is:  -0.5181699923111589\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.1579, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.3030, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 273 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.8210901\n",
            "*******$$The Critic loss $$********:  tensor(1.1351, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.0908, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.8509388532408433\n",
            "The training process is:  False\n",
            "The reward is:  -0.8477537036770559\n",
            "The training process is:  False\n",
            "The reward is:  -0.40492627205959186\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(0.2378, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.4620, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 274 | Ep_r: -3\n",
            "The reward is:  -0.7692162381936499\n",
            "The training process is:  False\n",
            "The reward is:  -0.5357659153079437\n",
            "The training process is:  False\n",
            "The reward is:  -0.37696960657453044\n",
            "The training process is:  False\n",
            "The reward is:  -0.07674863763239644\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.4902, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.8692, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 275 | Ep_r: -3\n",
            "The reward is:  -0.7773591677043233\n",
            "The training process is:  False\n",
            "The reward is:  -0.77440442527542\n",
            "The training process is:  False\n",
            "The reward is:  -0.7715281974212285\n",
            "The training process is:  False\n",
            "The reward is:  -0.7649170199156392\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.6549, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.1332, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 276 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.5905907271796739\n",
            "The training process is:  False\n",
            "The reward is:  -0.6620462497562728\n",
            "The training process is:  False\n",
            "The reward is:  -0.6956821271365207\n",
            "The training process is:  False\n",
            "The reward is:  -0.6216164375203879\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(3.1468, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.8577, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 277 | Ep_r: -3\n",
            "The reward is:  -0.727271204913896\n",
            "The training process is:  False\n",
            "The reward is:  -0.4694560136944741\n",
            "The training process is:  False\n",
            "The reward is:  -0.5145865559259747\n",
            "The training process is:  False\n",
            "The reward is:  -0.40045142069616535\n",
            "The training process is:  False\n",
            "The reward is:  -0.5194270762586788\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(5.0433, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.6903, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 278 | Ep_r: -3\n",
            "The reward is:  -0.723572888526277\n",
            "The training process is:  False\n",
            "The reward is:  -0.4407841635817283\n",
            "The training process is:  False\n",
            "The reward is:  -0.7079211537637804\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  0.79479814\n",
            "*******$$The Critic loss $$********:  tensor(1.5306, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.6367, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.5428195434305576\n",
            "The training process is:  False\n",
            "The reward is:  -0.5573715565240722\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(0.3405, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.0087, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 279 | Ep_r: -3\n",
            "The reward is:  -0.8087867128453132\n",
            "The training process is:  False\n",
            "The reward is:  -0.19473944838253318\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(0.2699, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.1620, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 280 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.8385415422755866\n",
            "The training process is:  False\n",
            "The reward is:  -0.8360875538579939\n",
            "The training process is:  False\n",
            "The reward is:  -0.8308960678816257\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.7973, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.4356, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 281 | Ep_r: -3\n",
            "The reward is:  -0.5637028939014879\n",
            "The training process is:  False\n",
            "The reward is:  -0.5619275504822748\n",
            "The training process is:  False\n",
            "The reward is:  -0.21675788975842608\n",
            "The training process is:  False\n",
            "The reward is:  -0.4592362856790787\n",
            "The training process is:  False\n",
            "The reward is:  -0.40024842171456304\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(5.5297, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.7507, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 282 | Ep_r: -3\n",
            "The reward is:  -0.8362551276321873\n",
            "The training process is:  False\n",
            "The reward is:  -0.8358354730195042\n",
            "The training process is:  False\n",
            "The reward is:  -0.833592002284132\n",
            "The training process is:  False\n",
            "The reward is:  -0.6740941725083902\n",
            "The training process is:  False\n",
            "The reward is:  -0.6755217837946644\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.8080, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.4015, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 283 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.1784, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.2244, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 284 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.8144925648958654\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.7952647\n",
            "*******$$The Critic loss $$********:  tensor(1.1707, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.0745, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.8143798727059022\n",
            "The training process is:  False\n",
            "The reward is:  -0.811504772514548\n",
            "The training process is:  False\n",
            "The reward is:  -0.8086344086538932\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(0.3919, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.0981, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 285 | Ep_r: -3\n",
            "The reward is:  -0.746304945786023\n",
            "The training process is:  False\n",
            "The reward is:  -0.49002907499765797\n",
            "The training process is:  False\n",
            "The reward is:  -0.32472749256233835\n",
            "The training process is:  False\n",
            "The reward is:  -0.5573599004309527\n",
            "The training process is:  False\n",
            "The reward is:  -0.5497292560120559\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(3.2662, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.6793, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 286 | Ep_r: -3\n",
            "The reward is:  -0.7966354185189408\n",
            "The training process is:  False\n",
            "The reward is:  -0.7825205839143614\n",
            "The training process is:  False\n",
            "The reward is:  -0.8563833037013759\n",
            "The training process is:  False\n",
            "The reward is:  -0.8542701455874362\n",
            "The training process is:  False\n",
            "The reward is:  -0.3375833433872676\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.5517, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.2973, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 287 | Ep_r: -3\n",
            "The reward is:  -0.6007343386562715\n",
            "The training process is:  False\n",
            "The reward is:  -0.5949978234226877\n",
            "The training process is:  False\n",
            "The reward is:  -0.4605853461326065\n",
            "The training process is:  False\n",
            "The reward is:  -0.5926538163220888\n",
            "The training process is:  False\n",
            "The reward is:  -0.4504329653042576\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(3.2176, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.8351, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 288 | Ep_r: -3\n",
            "The reward is:  -0.5662281738285524\n",
            "The training process is:  False\n",
            "The reward is:  -0.52813757933453\n",
            "The training process is:  False\n",
            "The reward is:  -0.5298324708387382\n",
            "The training process is:  False\n",
            "The reward is:  -0.4388216806526334\n",
            "The training process is:  False\n",
            "The reward is:  -0.4089546055493131\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(3.0772, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.7017, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 289 | Ep_r: -3\n",
            "The reward is:  -0.43428797621618226\n",
            "The training process is:  False\n",
            "The reward is:  -0.4493302889229641\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.7618302\n",
            "*******$$The Critic loss $$********:  tensor(3.9274, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.5874, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.5833190603550058\n",
            "The training process is:  False\n",
            "The reward is:  -0.6008334438243562\n",
            "The training process is:  False\n",
            "The reward is:  -0.19042503168316052\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.3857, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.5101, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 290 | Ep_r: -3\n",
            "The reward is:  -0.29893402609166236\n",
            "The training process is:  False\n",
            "The reward is:  -0.4532499913267011\n",
            "The training process is:  False\n",
            "The reward is:  -0.341464178206467\n",
            "The training process is:  False\n",
            "The reward is:  -0.5726485879330663\n",
            "The training process is:  False\n",
            "The reward is:  -0.5626990139871253\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(4.2863, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.6439, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 291 | Ep_r: -3\n",
            "The reward is:  -0.823089440242088\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.8491883801336872\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.7001706307914144\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.2262, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.5895, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 292 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.6289977974643194\n",
            "The training process is:  False\n",
            "The reward is:  -0.7951113432236939\n",
            "The training process is:  False\n",
            "The reward is:  -0.6318171249218978\n",
            "The training process is:  False\n",
            "The reward is:  -0.6170711238330157\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.3003, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.0212, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 293 | Ep_r: -3\n",
            "The reward is:  -0.6248013507753767\n",
            "The training process is:  False\n",
            "The reward is:  -0.5897927920040906\n",
            "The training process is:  False\n",
            "The reward is:  -0.5778568386580771\n",
            "The training process is:  False\n",
            "The reward is:  -0.4321050887128178\n",
            "The training process is:  False\n",
            "The reward is:  -0.4242718571266157\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(4.2376, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.5108, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 294 | Ep_r: -3\n",
            "The reward is:  -0.7087133655083708\n",
            "The training process is:  False\n",
            "The reward is:  -0.8407194575816828\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  0.5782524\n",
            "*******$$The Critic loss $$********:  tensor(0.9621, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(-0.3872, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.5938097502454615\n",
            "The training process is:  False\n",
            "The reward is:  -0.42729601885074986\n",
            "The training process is:  False\n",
            "The reward is:  -0.4580830059816371\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.0552, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.4047, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 295 | Ep_r: -3\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.6\n",
            "The training process is:  False\n",
            "The reward is:  -0.6026696191072987\n",
            "The training process is:  False\n",
            "The reward is:  -0.39431110304573636\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(3.0339, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(1.5408, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 296 | Ep_r: -3\n",
            "The reward is:  -0.6833555886401362\n",
            "The training process is:  False\n",
            "The reward is:  -0.4630408071199078\n",
            "The training process is:  False\n",
            "The reward is:  -0.68384125753505\n",
            "The training process is:  False\n",
            "The reward is:  -0.643202773472417\n",
            "The training process is:  False\n",
            "The reward is:  -0.636399983375427\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(3.9156, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.6101, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 297 | Ep_r: -3\n",
            "The reward is:  -0.34166710604937595\n",
            "The training process is:  False\n",
            "The reward is:  -0.5715803558387164\n",
            "The training process is:  False\n",
            "The reward is:  -0.6585866141177594\n",
            "The training process is:  False\n",
            "The reward is:  -0.639501945387845\n",
            "The training process is:  False\n",
            "The reward is:  -0.3396431756125467\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(2.9821, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.4239, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 298 | Ep_r: -3\n",
            "The reward is:  -0.8310534620830051\n",
            "The training process is:  False\n",
            "The reward is:  -0.5915471746826925\n",
            "The training process is:  False\n",
            "The reward is:  -0.7230163760803828\n",
            "The training process is:  False\n",
            "The reward is:  -0.6005048948943564\n",
            "The training process is:  False\n",
            "The reward is:  -0.5872022899345921\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(4.0085, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.6151, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 299 | Ep_r: -3\n",
            "The reward is:  -0.49834854713489507\n",
            "The training process is:  False\n",
            "The reward is:  -0.8157432440427395\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  0.42589155\n",
            "*******$$The Critic loss $$********:  tensor(1.1990, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.4158, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.8445548107416372\n",
            "The training process is:  False\n",
            "The reward is:  -0.5130374118161123\n",
            "The training process is:  False\n",
            "The reward is:  -0.43397206532487226\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "*******$$The Critic loss $$********:  tensor(1.8023, grad_fn=<MeanBackward0>)\n",
            "*******$$The Actor loss $$********:  tensor(0.2497, grad_fn=<MeanBackward0>)\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 300 | Ep_r: -3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A_L = [0.8977,3.7794,0.9608,0.9451,1.4748,3.8474,2.3654,1.0685,3.9120,2.7400,0.6217,2.6272,2.5003,2.5161,0.1223,3.4081,2.9380,-0.9958,-0.9958,\n",
        "       2.3878,4.1981,1.7905,2.4218,\n",
        "       0.3281,0.0009,0.6529,0.4014,0.7368,0.4637,0.3030,1.0908,0.4620,0.8692,0.1332,0.8577,0.6903,0.6367,0.0087,0.1620,0.4356,0.7507,0.4015,0.2244,\n",
        "       0.0745,0.0981,0.6793,0.2973,0.8351,0.7017,0.5874,0.5101,0.6439,1.5895,1.0212,0.5108,0.3872,0.4047,1.5408,0.6101,0.4239,0.6151,0.4158,0.2497]\n",
        "C_L = [2.6844,29.6985,3.6111,2.9235,6.4320,28.0981,13.5384,3.4340,29.6314,22.4366,1.1842,21.3181,14.9656,13.2376,0.0176,25.0289,26.5604,2.0560,2.0560,\n",
        "       17.0670,21.9507,4.7557,11.1665,\n",
        "       1.2499,0.4041,4.0147,3.4817,4.2875,0.5700,2.1579,1.1351,0.2378,1.4902,2.6549,3.1468,5.0433,1.5306,0.3405,0.2699,2.7973,5.5297,1.8080,1.1784,\n",
        "       1.1707,0.3919,3.2662,2.5517,3.2176,3.0772,3.9274,2.3857,4.2863,1.2262,2.3003,4.2376,0.9621,1.0552,3.0339,3.9156,2.9821,4.0085,1.1990,1.8023]\n",
        "plt.scatter(np.arange(len(C_L)),C_L, label = \"Critic Loss\")\n",
        "plt.scatter(np.arange(len(A_L)),A_L, label = \"Actor Loss\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"The chosen episode for demonstration\")\n",
        "plt.ylabel(\"The calculated loss\")\n",
        "plt.title(\"The A3C model on the mobile environment\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "AOGIBJySjqpQ",
        "outputId": "0cd507ad-fd93-4a05-b3dc-af66bd0450d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'The A3C model on the mobile environment')"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    env = gym.make(\"mobile-small-central-v0\")\n",
        "    N_S = 7\n",
        "    N_A = 4\n",
        "    gnet = ACNetwork(N_S, N_A)        # global network\n",
        "    gnet.share_memory()\n",
        "    print(\"share the global parameters in multiprocessing\")\n",
        "    opt = SharedAdam(gnet.parameters(), lr=1e-4, betas=(0.95, 0.999))  # global optimizer\n",
        "    global_ep, global_ep_r, res_queue = mp.Value('i', 0), mp.Value('d', 0.), mp.Queue()\n",
        "\n",
        "    # parallel training\n",
        "    print(\"Start parallel training\")\n",
        "    workers = [Worker(gnet, opt, global_ep, global_ep_r, res_queue, i) for i in range(mp.cpu_count())]\n",
        "    [w.start() for w in workers]\n",
        "    res = []                    # record episode reward to plot\n",
        "    while True:\n",
        "        r = res_queue.get()\n",
        "        print(\"The delivered reward\", r)\n",
        "        if r is not None:\n",
        "            res.append(r)\n",
        "        else:\n",
        "            break\n",
        "    [w.join() for w in workers]\n",
        "\n",
        "    import matplotlib.pyplot as plt\n",
        "    plt.plot(res)\n",
        "    plt.ylabel('Moving average ep reward')\n",
        "    plt.xlabel('Step')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "PyPjf9a3fP0V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a63d464e-9caa-468d-9135-69d699784e34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "v_s_ is:  -0.263003\n",
            "The reward is: ****** sync is finished ********** -1.0\n",
            "The training process is:  \n",
            "False\n",
            "The reward is:  -0.1695797758529064\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 27 | Ep_r: -7\n",
            "The reward is:  -0.816847224328137\n",
            "The training process is:  False\n",
            "The reward is:  -0.6716828709273067\n",
            "The training process is:  The delivered reward -6.659061282433375\n",
            "False\n",
            "The reward is:  -0.4145915784793795\n",
            "The training process is:  False\n",
            "The reward is: The reward is:  -1.0 \n",
            "The training process is:  -0.43981751676994885False\n",
            "\n",
            "The training process is:  False\n",
            "The reward is:  -0.5422751607459451\n",
            "The training process is:  False\n",
            "The reward is:  -0.6418819425341571\n",
            "The training process is:  False\n",
            "The reward is:  -0.30970206124204874\n",
            "The training process is:  False\n",
            "The reward is:  -0.5413025965845618\n",
            "The training process is:  False\n",
            "The reward is:  -0.37244598151620495\n",
            "The training process is:  False\n",
            "The reward is:  -0.47697438678029674\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1The reward is:  Ep: -0.8019005831818149\n",
            "The training process is:   False\n",
            "28 | Ep_r: -7\n",
            "The reward is:  -0.8037488929778469\n",
            "The training process is:  False\n",
            "The reward is:  The delivered reward -6.64474588280812\n",
            "-0.7902223837902436\n",
            "The training process is:  False\n",
            "The reward is:  -0.833592002284132\n",
            "The training process is:  False\n",
            "The reward is:  -0.7928519153323361\n",
            "The training process is:  False\n",
            "The reward is:  -0.8221064243473059\n",
            "The training process is:  False\n",
            "The reward is:  -0.7950556416551506\n",
            "The training process is:  The reward is: False\n",
            " The reward is:  -0.8223597385851003-0.76195307195146\n",
            "\n",
            "The training process is:  False\n",
            "The training process is:  The reward is:  False-0.6433202103945554\n",
            "\n",
            "The training process is:  False\n",
            "The reward is:  -0.44075139617736614\n",
            "The training process is:  False\n",
            "The reward is:  -0.5869768570239127\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 29 | Ep_r: -7\n",
            "The reward is:  -0.5920453297692577\n",
            "The training process is:  False\n",
            "The reward is:  -0.4598009910224123\n",
            "The training process is:  The delivered reward -6.6516082786057185\n",
            "False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.5933903\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.3463750390114672\n",
            "The training process is:  False\n",
            "The reward is:  -0.4048141927212642\n",
            "The reward is: The training process is:   -0.27800127805058505False\n",
            "\n",
            "The training process is:  The reward is: False \n",
            "-0.5820848404684729\n",
            "The training process is:  False\n",
            "The reward is:  -0.3352778825522752\n",
            "The training process is:  False\n",
            "The reward is:  -0.060279711967189085\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 30 | Ep_r: -7\n",
            "The reward is:  -0.6440310994597015\n",
            "The training process is:  False\n",
            "The reward is:  -0.6430288829313235\n",
            "The training process is:  False\n",
            "The delivered reward -6.612898975694785\n",
            "The reward is:  -0.7787472421669748\n",
            "The training process is:  False\n",
            "The reward is:  -0.6307069574900652\n",
            "The training process is:  False\n",
            "The reward is: The reward is:  -0.2751669733430627 \n",
            "-0.6197960261535775The training process is: \n",
            "The training process is:   FalseFalse\n",
            "\n",
            "The reward is:  -0.7681648307992479\n",
            "The training process is:  False\n",
            "The reward is:  -0.6082909838638193\n",
            "The training process is:  False\n",
            "The reward is:  -0.8414247899950531\n",
            "The training process is:  False\n",
            "The reward is:  -0.5854189287487104\n",
            "The training process is:  False\n",
            "The reward is:  -0.5799813641615399\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 31 | Ep_r: -7\n",
            "The reward is:  -0.4428154239738493\n",
            "The training process is:  False\n",
            "The delivered reward -6.613765896995537\n",
            "The reward is: The reward is:   -0.4634920155928766-0.8395286157540756\n",
            "\n",
            "The training process is: The training process is:   False\n",
            "False\n",
            "The reward is:  -0.6767134482543398\n",
            "The training process is:  False\n",
            "The reward is:  -0.41953178625292437\n",
            "The training process is:  False\n",
            "The reward is:  -0.4333747149267075\n",
            "The training process is:  False\n",
            "The reward is:  -0.14060675124191777\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 32 | Ep_r: -7\n",
            "The reward is:  -0.6555533741064717\n",
            "The training process is:  False\n",
            "The delivered reward -6.57715394542962\n",
            "The reward is:  -0.6409790405772776\n",
            "The reward is: The training process is:   False-0.2221079806256287\n",
            "\n",
            "******** sync has started ********\n",
            "The training process is: v_s_ is:  1.5434117 \n",
            "False\n",
            "****** sync is finished **********\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "The reward is: w_0  -0.37330024524417493Ep: \n",
            "33 The training process is: | Ep_r: -7 False\n",
            "\n",
            "The reward is:  -0.3698224127063821\n",
            "The training process is:  False\n",
            "The reward is:  -0.5841350690398588\n",
            "The training process is:  False\n",
            "The reward is:  -0.5801742802939676\n",
            "The training process is:  False\n",
            "The delivered reward -6.579408625002778\n",
            "The reward is:  -0.33088929282301033\n",
            "The training process is:  False\n",
            "The reward is:  -0.33968270045998217\n",
            "The training process is:  False\n",
            "The reward is:  -0.4551075221658859\n",
            "The training process is:  False\n",
            "The reward is:  -0.449597482180336\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: The reward is: 34  -0.7928776351526509\n",
            "The training process is: | Ep_r: -7\n",
            " FalseThe reward is: \n",
            " ******** sync has started ********-0.37729437570699753\n",
            "v_s_ is: \n",
            " 1.5037241The training process is: \n",
            " ****** sync is finished **********\n",
            "False\n",
            "The reward is:  -0.6\n",
            "The training process is:  False\n",
            "The delivered reward -6.561406952948724\n",
            "The reward is:  -0.6\n",
            "The training process is:  False\n",
            "The reward is:  -0.7016378428489034\n",
            "The training process is:  False\n",
            "The reward is:  -0.7608306551497357\n",
            "The training process is:  False\n",
            "The reward is:  -0.2667350563268941\n",
            "The training process is:  False\n",
            "The reward is:  -0.41937205919277487\n",
            "The training process is:  False\n",
            "The reward is:  -0.5798572100469374\n",
            "The training process is:  False\n",
            "The reward is:  -0.28192814778921016\n",
            "The training process is:  False\n",
            "The reward is:  -0.1029381113497521\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 35The reward is:   | Ep_r: -7-0.7047264805160619\n",
            "The training process is: \n",
            " False\n",
            "The reward is:  -0.35313449564697114\n",
            "The training process is:  False\n",
            "The reward is:  -0.25000089965863215\n",
            "The training process is:  The delivered reward -6.542698818003349\n",
            "False\n",
            "The reward is:  -0.27353925359001346\n",
            "The training process is:  False\n",
            "The reward is:  0.09339263813772733\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 36 | Ep_r: -6\n",
            "The reward is:  -0.8499561038590313\n",
            "The training process is:  False\n",
            "******** sync has started ********The delivered reward -6.485104649930895\n",
            "\n",
            "v_s_ is:  1.6332903\n",
            "****** sync is finished **********\n",
            "The reward is: The reward is:   -0.7032552951288313\n",
            "-0.8466725871831262The training process is: \n",
            "The training process is:  False \n",
            "False\n",
            "The reward is:  -0.8438979403416212\n",
            "The training process is:  False\n",
            "The reward is:  -0.5863838880835098\n",
            "The training process is:  False\n",
            "The reward is:  -0.4760707781538799\n",
            "The training process is:  False\n",
            "The reward is:  -0.6772217051961906\n",
            "The training process is:  False\n",
            "The reward is:  -0.77440442527542\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.6462031295397253\n",
            "The training process is:  False\n",
            "The reward is:  -0.4369385986258171\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********The reward is: \n",
            " w_1-0.702315941227831 \n",
            "Ep:The training process is:   37False \n",
            "| Ep_r: -6\n",
            "The reward is:  -0.45976670117583696\n",
            "The training process is:  False\n",
            "The reward is:  -0.4518699324141\n",
            "The training process is:  False\n",
            "The delivered reward -6.491631094994169\n",
            "The reward is:  -0.4407378726636543\n",
            "The training process is:  False\n",
            "The reward is:  -0.5273001676191119\n",
            "The training process is:  False\n",
            "The reward is:  -0.46018703075966716\n",
            "The training process is:  False\n",
            "The reward is:  -0.15436977100386762\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: The reward is: 38 -0.7005335712677369 | Ep_r: -6\n",
            "\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.6\n",
            "The training process is:  The delivered reward -6.45165709880059\n",
            "False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.6189324511925359\n",
            "The training process is:  False\n",
            "The reward is:  -0.6124143315736219\n",
            "The training process is:  False\n",
            "The reward is:  -0.6088092697586254\n",
            "The training process is:  False\n",
            "The reward is:  -0.6328591083240738\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.5914489\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.6297979938058657\n",
            "The training process is:  False\n",
            "The reward is:  The reward is: -0.6971553126099145 \n",
            "-0.7463514351947012The training process is:  \n",
            "FalseThe training process is: \n",
            " False\n",
            "The reward is:  -0.7448206567206991\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 39 | Ep_r: -6\n",
            "The reward is:  -0.8397683359683565\n",
            "The training process is:  False\n",
            "The reward is:  -0.6350195087113104\n",
            "The training process is:  False\n",
            "The reward is:  -0.6496719758510064The delivered reward -6.4590803802782855\n",
            "\n",
            "The training process is:  False\n",
            "The reward is:  -0.6327702320058763\n",
            "The training process is:  False\n",
            "The reward is:  -0.7695964665799102\n",
            "The training process is:  False\n",
            "The reward is:  -0.5972102003764033\n",
            "The training process is:  False\n",
            "The reward is:  -0.3911175252320408\n",
            "The training process is:  False\n",
            "The reward is:  -0.4541670849660873\n",
            "The training process is:  False\n",
            "The reward is: The reward is:   -0.5107017484007896-0.6646411114122941\n",
            "\n",
            "The training process is: The training process is:  False\n",
            " The reward is: False -0.6289383764992923\n",
            "\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 40 | Ep_r: -6\n",
            "The reward is:  -0.8453908042454714\n",
            "The training process is:  False\n",
            "The reward is:  -0.7253380022081707\n",
            "The training process is:  False\n",
            "The reward is: The delivered reward -6.455579191021414\n",
            " -0.71867293655134\n",
            "The training process is:  False\n",
            "The reward is:  -0.3188891504368836\n",
            "The training process is:  False\n",
            "The reward is:  -0.8334399686213017\n",
            "The training process is:  False\n",
            "The reward is:  -0.556586816417869\n",
            "The training process is:  False\n",
            "The reward is:  -0.6969174104235882\n",
            "The training process is:  False\n",
            "The reward is:  -0.6967055629981708\n",
            "The training process is:  False\n",
            "The reward is:  -0.6959587974625131\n",
            "The training process is:  False\n",
            "******** sync has started ********The reward is:  \n",
            "-0.6613000150872477v_s_ is:  \n",
            "0.65591663The training process is:  \n",
            "False\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.6937145478221272\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 41 | Ep_r: -6\n",
            "The reward is:  -0.674064431442017\n",
            "The training process is:  False\n",
            "The reward is:  -0.6900768715363149\n",
            "The delivered reward -6.458839539083074\n",
            "The training process is:  False\n",
            "The reward is:  -0.6997680622338379\n",
            "The training process is:  False\n",
            "The reward is:  -0.46481319248114483\n",
            "The training process is:  False\n",
            "The reward is:  -0.4650926240424016\n",
            "The training process is:  False\n",
            "The reward is:  -0.19620499378639328\n",
            "The training process is:  The reward is: True \n",
            "-0.6580975152383625\n",
            "******** sync has started ********The training process is: \n",
            " False****** sync is finished **********\n",
            "\n",
            "w_1 Ep: 42 | Ep_r: -6\n",
            "The reward is:  -0.657253362270206\n",
            "The training process is:  False\n",
            "The reward is: The delivered reward -6.426151345447464\n",
            " -0.38346660606585486\n",
            "The training process is:  False\n",
            "The reward is:  -0.45896578874050925\n",
            "The training process is:  False\n",
            "The reward is:  -0.45693610656918227\n",
            "The training process is:  False\n",
            "The reward is:  -0.3043182143349986\n",
            "The training process is:  False\n",
            "The reward is:  -0.2846926350662204\n",
            "The training process is:  False\n",
            "The reward is:  -0.43317186109790573\n",
            "The training process is:  FalseThe reward is:  -0.8293032628220433\n",
            "\n",
            "The training process is: The reward is:   False-0.6066372537716097\n",
            "\n",
            "******** sync has started ********The training process is: \n",
            " ****** sync is finished **********False\n",
            "\n",
            "The reward is:  w_0-0.6073934138708112\n",
            "The training process is:   FalseEp: \n",
            "43 | Ep_r: -6The reward is: \n",
            " -0.48616547103457197\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 44 | Ep_r: -6\n",
            "The delivered reward -6.43303189339762\n",
            "The delivered reward -6.415491581591862\n",
            "The reward is:  -0.8315013070410803\n",
            "The training process is:  False\n",
            "The reward is:  -0.6603386157984227\n",
            "The training process is:  False\n",
            "The reward is:  -0.323726190078103\n",
            "The training process is:  False\n",
            "The reward is:  -0.4925717437338505\n",
            "The training process is:  False\n",
            "The reward is:  -0.8418912709677414\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.6088209\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.644259721410677\n",
            "The training process is:  False\n",
            "The reward is:  -0.47643675268649144\n",
            "The training process is:  False\n",
            "The reward is:  -0.4539116384522046\n",
            "The training process is:  False\n",
            "The reward is:  -0.6225149397052391\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 45 | Ep_r: -6\n",
            "The reward is:  The reward is: -0.5122627588304176 \n",
            "-1.0The training process is: \n",
            " The training process is: False \n",
            "False\n",
            "The delivered reward -6.414808187574682\n",
            "The reward is:  -0.7588624137395096\n",
            "The training process is:  False\n",
            "The reward is:  -0.4894995749313442\n",
            "The training process is:  False\n",
            "The reward is:  -0.4741482947077419\n",
            "The training process is:  False\n",
            "The reward is:  -0.46046797002946693\n",
            "The training process is:  False\n",
            "The reward is:  -0.35182767556745487\n",
            "The training process is:  False\n",
            "The reward is:  -0.5470613930548909\n",
            "The training process is:  False\n",
            "The reward is:  -0.4324350337373858\n",
            "The training process is:  False\n",
            "The reward is:  -0.30920955632486086\n",
            "The training process is:  False\n",
            "The reward is:  -0.4760550614259717The reward is:  -0.40645197670895905\n",
            "The training process is: \n",
            "False \n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 46 | Ep_r: -6\n",
            "The reward is:  -0.8358354730195042\n",
            "The training process is:  False\n",
            "The reward is:  -0.7097706357413478\n",
            "The training process is:  False\n",
            "The delivered reward -6.403655775434122\n",
            "The reward is:  -0.5634810528431109\n",
            "The training process is:  False\n",
            "The reward is:  -0.5305236497251795\n",
            "The training process is:  False\n",
            "The reward is:  -0.5600283891860843\n",
            "The training process is: The reward is:  False \n",
            "-0.3513390804496339The reward is: \n",
            " The training process is:  -0.5267524408721502False\n",
            "\n",
            "The training process is:  False\n",
            "The reward is:  -0.7265276304924771\n",
            "The training process is:  False\n",
            "The reward is:  -0.533929712096561\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  -0.7809575\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.732361575105058\n",
            "The training process is:  False\n",
            "The reward is:  -0.4050936154391581\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 47 | Ep_r: -6\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The reward is: The training process is:   -0.5133640363445849False\n",
            "The training process is:  The delivered reward -6.400862259424987\n",
            "\n",
            "FalseThe reward is: \n",
            " -0.5884557714486105\n",
            "The training process is:  False\n",
            "The reward is:  -0.7798842325124786\n",
            "The training process is:  False\n",
            "The reward is:  -0.7567896490893853\n",
            "The training process is:  False\n",
            "The reward is:  -0.38903514569610537\n",
            "The training process is:  False\n",
            "The reward is:  -0.766179072321449\n",
            "The training process is:  False\n",
            "The reward is:  -0.7715281974212285\n",
            "The training process is:  False\n",
            "The reward is:  -0.5277713404262914\n",
            "The training process is:  False\n",
            "The reward is:  -0.3550192506568809\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 48 | Ep_r: -6\n",
            "The reward is:  -0.4236118389391487\n",
            "The training process is:  The reward is:  False-0.23675114264864416\n",
            "\n",
            "The training process is:  The delivered reward -6.406200263426461\n",
            "The reward is: False\n",
            " -0.39511134322369396\n",
            "The training process is:  False\n",
            "The reward is:  -0.6132166583414366\n",
            "The training process is:  False\n",
            "The reward is:  -0.6109017481771207\n",
            "The training process is:  False\n",
            "The reward is:  -0.5582370934427112\n",
            "The training process is:  False\n",
            "The reward is:  -0.5682748012467072\n",
            "The training process is:  False\n",
            "The reward is:  -0.46639088572853193\n",
            "The training process is:  False\n",
            "The reward is:  -0.5551000928424947\n",
            "The training process is:  False\n",
            "The reward is: The reward is:  -0.3939727708216464 \n",
            "-0.7596991642141329The training process is: \n",
            " The training process is: False \n",
            "False\n",
            "The reward is:  -0.2504479777532752\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 49 | Ep_r: -6\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.6550016\n",
            "****** sync is finished **********\n",
            "The delivered reward -6.394148176831289\n",
            "The reward is:  -0.6828976296757796\n",
            "The training process is:  False\n",
            "The reward is:  -0.8408178271541189\n",
            "The training process is:  False\n",
            "The reward is:  -0.6019995878417378\n",
            "The training process is:  False\n",
            "The reward is:  -0.832300600361761\n",
            "The training process is:  FalseThe reward is: \n",
            " -0.5822046983053075\n",
            "The training process is: The reward is:   -0.8286795294792973False\n",
            "\n",
            "The training process is:  False\n",
            "The reward is:  -0.6907595432464515\n",
            "The training process is:  False\n",
            "The reward is:  -0.569965430400602\n",
            "The training process is:  False\n",
            "The reward is:  -0.5644750103328668\n",
            "The training process is:  False\n",
            "The reward is:  -0.8132433228030422\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 50 | Ep_r: -6\n",
            "The reward is:  -0.8087867128453132\n",
            "The training process is:  False\n",
            "The delivered reward -6.4044580798759325\n",
            "The reward is:  -0.3686493685597816\n",
            "The training process is:  False\n",
            "The reward is:  -0.47526289304294683\n",
            "The training process is:  False\n",
            "The reward is:  -0.668844932306451\n",
            "The training process is:  False\n",
            "The reward is:  -0.6736763779843911\n",
            "The training process is:  False\n",
            "The reward is:  -0.6679851386993988\n",
            "The training process is: The reward is:   False-0.477002704602299\n",
            "\n",
            "The training process is:  False\n",
            "The reward is:  -0.4266849108767562\n",
            "The training process is:  False\n",
            "The reward is:  -0.42632736863979914\n",
            "The training process is:  False\n",
            "The reward is:  -0.4825720373355786\n",
            "The training process is:  False\n",
            "The reward is:  -0.42887571039366357\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 51 | Ep_r: -6\n",
            "The reward is:  -0.845298385510698\n",
            "The training process is:  False\n",
            "The reward is:  -0.823089440242088\n",
            "The training process is:  FalseThe delivered reward -6.392780329243043\n",
            "\n",
            "The reward is:  The reward is: 0.09253352402040065 \n",
            "-0.6664885903596969The training process is: \n",
            " TrueThe training process is:  \n",
            "False******** sync has started ********\n",
            "\n",
            "****** sync is finished ****************** sync has started ********\n",
            "\n",
            "v_s_ is: w_0  Ep:0.5281025 \n",
            "****** sync is finished **********52\n",
            " | Ep_r: -6\n",
            "The reward is:  -0.8183241565251818\n",
            "The training process is:  False\n",
            "The reward is:  The delivered reward -6.364570506738494\n",
            "-0.7171647720531467\n",
            "The training process is:  False\n",
            "The reward is:  -0.7514516949085105\n",
            "The training process is:  False\n",
            "The reward is:  -0.7475590491831585\n",
            "The training process is:  False\n",
            "The reward is:  -0.8488191136391912\n",
            "The training process is:  False\n",
            "The reward is:  -0.6556903182442593\n",
            "The training process is:  False\n",
            "The reward is:  -0.6533264511553754The reward is: \n",
            "The training process is:  -0.49650410052121197 \n",
            "FalseThe training process is: \n",
            " ******** sync has started ********\n",
            "False****** sync is finished **********\n",
            "\n",
            "w_1 Ep: 53 | Ep_r: -6\n",
            "The reward is:  -0.6179502284040802\n",
            "The training process is:  False\n",
            "The reward is:  -0.7948301682038205The delivered reward -6.376196921389322\n",
            "\n",
            "The training process is:  False\n",
            "The reward is:  -0.6825706939636653\n",
            "The training process is:  False\n",
            "The reward is:  -0.581753589208722\n",
            "The training process is:  False\n",
            "The reward is:  The reward is: -0.7011063747545407 \n",
            "-0.2623343416744362The training process is: \n",
            " The training process is: False \n",
            "FalseThe reward is: \n",
            " -0.5083942526918377\n",
            "The training process is:  False\n",
            "The reward is:  -0.8307834361783183\n",
            "The training process is:  False\n",
            "The reward is:  -0.4235796043281098\n",
            "The training process is:  False\n",
            "The reward is:  -0.4272351335578216\n",
            "The training process is:  False\n",
            "The reward is:  -0.14900089786588208\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 54 | Ep_r: -6\n",
            "The reward is:  -0.2266891471925226\n",
            "The training process is:  False\n",
            "The reward is:  -0.23285053108798498\n",
            "The training process is:  The delivered reward -6.369606995966997\n",
            "False\n",
            "The reward is:  -0.6\n",
            "The training process is:  False\n",
            "The reward is:  The reward is: -0.11562929014101649 \n",
            "The training process is: -0.4372732445767896 \n",
            "TrueThe training process is:  \n",
            "******** sync has started ********False\n",
            "\n",
            "****** sync is finished **********\n",
            "The reward is: w_0 -0.40357091294242586 Ep:\n",
            " The training process is: 55  False| Ep_r: -6\n",
            "\n",
            "******** sync has started ********\n",
            "v_s_ is:  0.08216996\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.64722189457034\n",
            "The training process is:  False\n",
            "The delivered reward -6.314655603330693\n",
            "The reward is:  -0.22266396400405147\n",
            "The training process is:  False\n",
            "The reward is:  -0.23680722359965403\n",
            "The training process is:  False\n",
            "The reward is:  -0.5589569992404412\n",
            "The training process is:  False\n",
            "The reward is:  -0.6056483294302096\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 56 | Ep_r: -6\n",
            "The reward is:  -0.7004325516904185\n",
            "The reward is:  The training process is:  False-0.7506014464132129\n",
            "\n",
            "The training process is:  FalseThe reward is:  \n",
            "-0.8430446536925562\n",
            "The training process is: The delivered reward -6.29322586976383\n",
            " False\n",
            "The reward is:  -0.573437773869607\n",
            "The training process is:  False\n",
            "The reward is:  -0.4457826238040192\n",
            "The training process is:  False\n",
            "The reward is:  -0.5775085760356806\n",
            "The training process is:  False\n",
            "The reward is:  -0.543732415553525\n",
            "The training process is:  False\n",
            "The reward is:  -0.5329494768733116\n",
            "The training process is:  False\n",
            "The reward is:  -0.6829750406915183\n",
            "The training process is:  False\n",
            "The reward is:  -0.5886431513433983\n",
            "The reward is: The training process is:   False-0.7081124520842854\n",
            "\n",
            "The reward is: The training process is:   -0.4999117455894625False\n",
            "\n",
            "The training process is: ******** sync has started ******** \n",
            "Falsev_s_ is: \n",
            " ******** sync has started ********1.464905\n",
            "\n",
            "****** sync is finished **************** sync is finished **********\n",
            "\n",
            "w_1 Ep: 57 | Ep_r: -6\n",
            "The reward is:  -0.8435009750407085\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is: The delivered reward -6.290177791157627\n",
            " False\n",
            "The reward is:  -0.7977757239274295\n",
            "The training process is:  False\n",
            "The reward is:  -0.8484834053503351\n",
            "The training process is:  False\n",
            "The reward is:  -0.8444987376025402\n",
            "The training process is:  False\n",
            "The reward is:  -0.6085005700227664\n",
            "The training process is:  False\n",
            "The reward is:  The reward is: -0.7106520260819925\n",
            " The training process is: -0.5360712267943908\n",
            " The training process is: False False\n",
            "\n",
            "******** sync has started ********\n",
            "v_s_ is:  0.9207001\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.5374510362063608\n",
            "The training process is:  False\n",
            "The reward is:  -0.41179534962104886\n",
            "The training process is:  False\n",
            "The reward is:  -0.27186386231686416\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 58 | Ep_r: -6\n",
            "The reward is: The reward is:   -1.0\n",
            "The training process is:  -0.8424894500190028False\n",
            "\n",
            "The training process is:  The reward is:  False-0.7532425614773264\n",
            "\n",
            "The delivered reward -6.294275422114875\n",
            "The training process is:  False\n",
            "The reward is:  -0.19135134504071205\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 59 | Ep_r: -6\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The delivered reward -6.250778606958907\n",
            "The reward is:  -0.7865654043590634\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The reward is: The training process is:   False-1.0\n",
            "\n",
            "The reward is: The training process is:   False-1.0\n",
            "\n",
            "The training process is:  False\n",
            "The reward is:  -0.8022673393281077\n",
            "The training process is:  False\n",
            "The reward is:  -0.7781027422443847\n",
            "The training process is:  False\n",
            "The reward is:  -0.7748407966222848\n",
            "The training process is:  False\n",
            "The reward is:  -0.6348576550978303\n",
            "The training process is:  False\n",
            "The reward is:  -0.7719316889876603\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "The reward is:  ****** sync is finished **********-1.0\n",
            "w_1 \n",
            "Ep: 60 The training process is:  | Ep_r: -6False\n",
            "\n",
            "The reward is:  -0.7828905244521167\n",
            "The training process is:  False\n",
            "The reward is:  -0.15763485986939368\n",
            "The delivered reward -6.273756477155711\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 61 | Ep_r: -6\n",
            "The reward is:  -0.6894165553759145\n",
            "The training process is:  False\n",
            "The reward is: The delivered reward -6.220424166227369\n",
            " -0.5126422562481415\n",
            "The training process is:  False\n",
            "The reward is:  -0.76038376264322\n",
            "The reward is: The training process is:   -0.8314789797766495\n",
            "FalseThe training process is:  \n",
            "FalseThe reward is: \n",
            " -0.4935058561989563\n",
            "The training process is:  False\n",
            "The reward is:  -0.5589581294544318\n",
            "The training process is:  False\n",
            "The reward is:  -0.537156629441145\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  0.43083447\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.5361271612309297\n",
            "The training process is:  False\n",
            "The reward is:  -0.4341936425227936\n",
            "The training process is:  False\n",
            "The reward is:  -0.4523062381219895\n",
            "The training process is:  False\n",
            "The reward is:  -0.46886983963365003\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: The reward is: 62 | Ep_r: -6 \n",
            "-0.2722054671323108\n",
            "The training process is:  FalseThe reward is: \n",
            " -0.21702804835217657\n",
            "The training process is:  False\n",
            "The reward is: The delivered reward -6.212655525273807\n",
            " -0.09090070123000893\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 63 | Ep_r: -6\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.7040183342689544\n",
            "The training process is:  False\n",
            "The reward is: The delivered reward -6.153608257516891\n",
            " -0.6133887428427691\n",
            "The training process is:  False\n",
            "The reward is:  -0.6076925568014033\n",
            "The training process is:  False\n",
            "The reward is:  -0.7602523042051272\n",
            "The training process is:  False\n",
            "The reward is: The reward is:  -0.6142387701977355\n",
            "The training process is:  False \n",
            "-0.23967227216860612\n",
            "The training process is:  False\n",
            "The reward is:  -0.22300126442483093\n",
            "The training process is:  False\n",
            "The reward is:  -0.5323263809993366\n",
            "The training process is:  False\n",
            "The reward is:  -0.1892554064921041\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 64 | Ep_r: -6\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.7557935807045519\n",
            "The training process is:  The delivered reward -6.140768247563753\n",
            "False\n",
            "The reward is:  -0.5366136212476716\n",
            "The training process is:  False\n",
            "The reward is:  -0.4360675514006568\n",
            "The training process is:  FalseThe reward is: \n",
            " The reward is: -0.7274212913278761 \n",
            "-0.5556930124118123The training process is: \n",
            "The training process is:  False\n",
            " FalseThe reward is: \n",
            " ******** sync has started ********\n",
            "-0.6273152715633546****** sync is finished **********\n",
            "\n",
            "The training process is: w_0  FalseEp:\n",
            " 65The reward is:   | Ep_r: -6\n",
            "-0.6183258159348928\n",
            "The training process is:  False\n",
            "The reward is:  -0.5880966359090585\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  The delivered reward -6.153932563918446\n",
            "1.592419\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.44803170713033913\n",
            "The training process is:  False\n",
            "The reward is:  -0.842681374647379\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 66 | Ep_r: -6\n",
            "The reward is:  -0.7746956278170412\n",
            "The training process is:  False\n",
            "The reward is:  -0.7701387118342644\n",
            "The training process is:  The delivered reward -6.156479423988759\n",
            "False\n",
            "The reward is: The reward is:  -1.0\n",
            " The training process is: -0.5422748176014651\n",
            " The training process is:  FalseFalse\n",
            "\n",
            "The reward is:  -0.844629508694411\n",
            "The training process is:  False\n",
            "The reward is:  -0.6236216104204433\n",
            "The training process is:  False\n",
            "The reward is:  -0.6311323158099873\n",
            "The training process is:  False\n",
            "The reward is:  -0.21430923849698136\n",
            "The training process is:  False\n",
            "The reward is:  -0.5210465695809855\n",
            "The training process is:  False\n",
            "The reward is:  -0.5521369740392299\n",
            "The training process is:  False\n",
            "The reward is:  -0.7355070400950261\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 67 | Ep_r: -6\n",
            "The reward is:  -0.5991828512470901\n",
            "The training process is:  False\n",
            "The reward is:  -0.8520774244977829\n",
            "The training process is:  FalseThe delivered reward -6.157009553892769\n",
            "\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.43219010678304315\n",
            "The training process is:  False\n",
            "The reward is:  -0.06709928551821287\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 68 | Ep_r: -6\n",
            "The reward is:  -0.5374973150528084\n",
            "The training process is:  False\n",
            "The reward is:  -0.7767494120903369\n",
            "The training process is:  False\n",
            "The delivered reward -6.124944955034303\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.7420460960490921\n",
            "The training process is:  The reward is:  False\n",
            "-0.7696326164077292The reward is:  -0.719862838829066\n",
            "The training process is:  False\n",
            "\n",
            "******** sync has started ********The training process is: \n",
            " Falsev_s_ is: \n",
            " -0.7923968\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.7326199467154881\n",
            "The training process is:  False\n",
            "The reward is:  -0.566587901050063\n",
            "The training process is:  False\n",
            "The reward is:  -0.5723920021654683\n",
            "The training process is:  False\n",
            "The reward is:  -0.33712721134944923\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 69 | Ep_r: -6\n",
            "The reward is:  -0.7598772324832843\n",
            "The training process is:  False\n",
            "The reward is:  -0.6507228998326904\n",
            "The delivered reward -6.133544332716978\n",
            "The training process is:  False\n",
            "The reward is:  -0.770663334856866\n",
            "The training process is:  False\n",
            "The reward is:  The reward is: -0.6071103561763701 -0.39664284657582405\n",
            "\n",
            "The training process is: The training process is:   FalseFalse\n",
            "\n",
            "The reward is:  -0.15071038446920473\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 70 | Ep_r: -6\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  The delivered reward -6.099495056371986\n",
            "-0.823114473527283\n",
            "The training process is:  False\n",
            "The reward is:  -0.8206455821789842\n",
            "The training process is:  False\n",
            "The reward is:  -0.8169289643473295\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.8513146652557708\n",
            "The training process is:  The reward is: False \n",
            "-0.6796918948021349\n",
            "The reward is: The training process is:   -0.7966354185189408False\n",
            "\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 71 | Ep_r: -6\n",
            "The reward is:  -0.8357512533865815\n",
            "The training process is:  False\n",
            "The reward is:  The delivered reward -6.129586496846549\n",
            "-0.8332658292648182\n",
            "The training process is:  False\n",
            "The reward is:  -0.4622287930307227\n",
            "The training process is:  False\n",
            "The reward is:  -0.3416327940429052\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  -0.31938827\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.40700450990238446\n",
            "The training process is:  False\n",
            "The reward is:  -0.8236630503988284\n",
            "The training process is:  False\n",
            "The reward is: The reward is:   -0.5111762997870427-0.6385449042111638\n",
            "\n",
            "The training process is: The training process is:   False\n",
            "False\n",
            "The reward is:  -0.3775026989105379\n",
            "The training process is:  False\n",
            "The reward is:  -0.29368882096209326\n",
            "The training process is:  False\n",
            "The reward is:  -0.48922051202633965\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 72 | Ep_r: -6\n",
            "The reward is:  -0.7586818611260789\n",
            "The training process is:  False\n",
            "The reward is:  -0.5758015384116916\n",
            "The training process is:  False\n",
            "The delivered reward -6.123315663539448\n",
            "The reward is:  -0.5693723249292311\n",
            "The training process is:  False\n",
            "The reward is:  -0.4729916558051621\n",
            "The training process is:  False\n",
            "The reward is:  -0.5923838068178207\n",
            "The training process is:  FalseThe reward is: \n",
            " The reward is: -0.6661893361055305 \n",
            "-0.729501629462744The training process is: \n",
            " The training process is:  FalseFalse\n",
            "\n",
            "The reward is:  -0.5991566759670642\n",
            "The training process is:  False\n",
            "The reward is:  -0.5887158773477894\n",
            "The training process is:  False\n",
            "The reward is:  -0.5827239373932195\n",
            "The training process is:  False\n",
            "The reward is:  -0.507085818738009\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 73 | Ep_r: -6\n",
            "The reward is:  -0.5378776487372747\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The delivered reward -6.121846658164041\n",
            "The reward is:  -0.6269223231865201\n",
            "The training process is:  False\n",
            "The reward is:  -0.6213956662975024\n",
            "The training process is:  False\n",
            "The reward is:  -0.5961311933480234\n",
            "The training process is:  False\n",
            "The reward is: The reward is:   -0.6415959605927245-0.6638798761900926\n",
            "\n",
            "The training process is:  FalseThe training process is:  \n",
            "False\n",
            "******** sync has started ********\n",
            "v_s_ is:  0.104055\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.834754356514727\n",
            "The training process is:  False\n",
            "The reward is:  -0.4248768490178462\n",
            "The training process is:  False\n",
            "The reward is:  -0.20623555344264854\n",
            "The training process is:  False\n",
            "The reward is:  -0.4555320348331766\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 74 | Ep_r: -6\n",
            "The reward is:  -0.7795676480951288\n",
            "The training process is:  False\n",
            "The delivered reward -6.120081407442106\n",
            "The reward is:  -0.5731068021792762\n",
            "The training process is:  False\n",
            "The reward is: The reward is:   -0.3304680999416561-0.6482767718693717\n",
            "\n",
            "The training process is: The training process is:   False\n",
            "False\n",
            "The reward is:  -0.46941336070516326\n",
            "The training process is:  False\n",
            "The reward is:  -0.6040616673731478\n",
            "The training process is:  False\n",
            "The reward is:  -0.7068553842493562\n",
            "The training process is:  False\n",
            "The reward is:  -0.8051371712592346\n",
            "The training process is:  False\n",
            "The reward is:  -0.8009247954605424\n",
            "The training process is:  False\n",
            "The reward is:  -0.6279686464806665\n",
            "The training process is:  False\n",
            "The reward is:  -0.4972774855844067\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 75 | Ep_r: -6\n",
            "The reward is:  -0.30535271154720345The reward is: \n",
            "The training process is:  False \n",
            "-0.5507289851735659The reward is: \n",
            " The training process is: -0.16056894884151018 \n",
            "The training process is: False\n",
            " The delivered reward -6.120828403980971\n",
            "True\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 76 | Ep_r: -6\n",
            "The reward is:  -0.8307157740542639\n",
            "The training process is:  False\n",
            "The reward is:  -0.8481461535461966\n",
            "The training process is:  FalseThe delivered reward -6.064279336545048\n",
            "\n",
            "The reward is:  -0.6430587933517138\n",
            "The training process is:  False\n",
            "The reward is:  -0.8223597385851003\n",
            "The training process is:  False\n",
            "The reward is:  -0.6806710456193873\n",
            "The training process is:  False\n",
            "The reward is:  -0.28021854096424403\n",
            "The training process is: The reward is:   False-0.6903761500575994\n",
            "\n",
            "The training process is:  FalseThe reward is: \n",
            " ******** sync has started ********-0.2819115844919565\n",
            "\n",
            "****** sync is finished **********The training process is:  False\n",
            "\n",
            "******** sync has started ********w_0\n",
            " v_s_ is: Ep:  1.586717277 \n",
            "****** sync is finished **********\n",
            "| Ep_r: -6\n",
            "The reward is:  -0.2734912429492624\n",
            "The training process is:  False\n",
            "The delivered reward -6.071507166045292\n",
            "The reward is:  -0.5268882424904886\n",
            "The training process is:  False\n",
            "The reward is:  -0.5382932275311093\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 78 | Ep_r: -6\n",
            "The reward is:  -0.2849981461390455\n",
            "The training process is:  False\n",
            "The reward is: The delivered reward -6.0680496378206765\n",
            " -0.2799943088258936\n",
            "The training process is:  False\n",
            "The reward is:  -0.46410935501690986\n",
            "The training process is:  False\n",
            "The reward is:  -0.4703838161363202\n",
            "The training process is:  False\n",
            "The reward is:  -0.6896469944960419\n",
            "The reward is: The training process is:   False\n",
            "-1.0\n",
            "The training process is: The reward is:   -0.5771011198243612False\n",
            "\n",
            "The training process is:  False\n",
            "The reward is:  -0.5739677035867559\n",
            "The training process is:  False\n",
            "The reward is:  -0.5676262753486104\n",
            "The training process is:  False\n",
            "The reward is:  -0.3134587182377777\n",
            "The training process is:  False\n",
            "The reward is:  -0.4010987187901615\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 79 | Ep_r: -6\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The delivered reward -6.053592993006489\n",
            "The reward is: The reward is:   -0.4062234767116796\n",
            "The training process is:  -0.7596397119486499False\n",
            "\n",
            "The training process is:  False\n",
            "The reward is:  -0.5976579363619754\n",
            "The training process is:  False\n",
            "The reward is:  -0.6450265156768835\n",
            "The training process is:  False\n",
            "The reward is:  -0.6430943497584645\n",
            "The training process is:  False\n",
            "The reward is:  -0.26863282018505913\n",
            "The training process is:  False\n",
            "The reward is:  -0.42466226175877075\n",
            "The training process is:  False\n",
            "The reward is:  -0.6139157883896098\n",
            "The training process is:  False\n",
            "The reward is:  -0.45505610056567214\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.6180317\n",
            "****** sync is finished **********\n",
            "The reward is: The reward is:  -0.31522872947711456\n",
            "The training process is:   -0.6963112778164152False\n",
            "\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 80 | Ep_r: -6\n",
            "The reward is: The delivered reward -6.054097030701039\n",
            " -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.6353233369608206\n",
            "The training process is:  False\n",
            "The reward is:  -0.8494160450532995\n",
            "The training process is:  False\n",
            "The reward is:  -0.5790258075368606\n",
            "The training process is:  False\n",
            "The reward is:  -0.5720141400848264\n",
            "The training process is:  False\n",
            "The reward is:  -0.5651293389487144\n",
            "The training process is:  False\n",
            "The reward is:  -0.3521597385144602\n",
            "The training process is:  False\n",
            "The reward is:  -0.35904152493876246\n",
            "The training process is:  FalseThe reward is: \n",
            " -0.3180420844336657The reward is: \n",
            " The training process is:  -0.8491357411851255False\n",
            "\n",
            "******** sync has started ********\n",
            "The training process is: v_s_ is:   False\n",
            "1.5578245\n",
            "The reward is: ****** sync is finished ********** \n",
            "-0.6731460690221052\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 81 | Ep_r: -6\n",
            "The reward is:  -0.3295693331883297The delivered reward -6.057899977816478\n",
            "\n",
            "The training process is:  False\n",
            "The reward is:  -0.328098811959513\n",
            "The training process is:  False\n",
            "The reward is:  -0.558547038641666\n",
            "The training process is:  False\n",
            "The reward is:  The reward is: -0.32051598920584345\n",
            " The training process is: 0.014089075748035506\n",
            " The training process is:  FalseTrue\n",
            "\n",
            "The reward is: ******** sync has started ******** \n",
            "-0.5745451657098054****** sync is finished **********\n",
            "The training process is:  \n",
            "False\n",
            "w_0 The reward is: Ep:  -0.62929226035046482\n",
            " The training process is: | Ep_r: -6 \n",
            "False\n",
            "The reward is:  -0.5887789149076557\n",
            "The delivered reward -6.017575030187058\n",
            "The training process is:  False\n",
            "The reward is:  -0.4008900186838057\n",
            "The training process is:  False\n",
            "The reward is:  -0.7549107826635555\n",
            "The training process is:  False\n",
            "The reward is:  -0.6588365535824986\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 83 | Ep_r: -6\n",
            "The reward is:  The delivered reward -6.008839128574119\n",
            "-0.6142007542010856\n",
            "The training process is:  False\n",
            "The reward is:  -0.7809594050778895\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  -0.19151914\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.7859447990812534\n",
            "The training process is:  False\n",
            "The reward is:  -0.8395086035362815\n",
            "The training process is:  False\n",
            "The reward is:  -0.8422199086182249\n",
            "The training process is:  False\n",
            "The reward is:  The reward is: -1.0 \n",
            "The training process is:  False\n",
            "-0.8429874134854861\n",
            "The training process is:  False\n",
            "The reward is:  -0.8043655612910197\n",
            "The training process is:  False\n",
            "The reward is:  -0.810530704801294\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.8207490522997327\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 84 | Ep_r: -6\n",
            "The reward is:  -0.43419625992774796\n",
            "The training process is:  False\n",
            "The reward is:  -0.6249132432574955\n",
            "The training process is:  False\n",
            "The delivered reward -6.030165399312301\n",
            "The reward is:  -0.4741796219040227\n",
            "The training process is:  False\n",
            "The reward is:  -0.4699961756183718\n",
            "The training process is:  False\n",
            "The reward is:  -0.12052887156988996\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 85 | Ep_r: -6\n",
            "The reward is: The delivered reward -5.991101887041953\n",
            " -0.4148446142918435\n",
            "The training process is:  False\n",
            "The reward is:  -0.7710206908075612\n",
            "The training process is:  False\n",
            "The reward is:  -0.7698399222945462\n",
            "The training process is:  FalseThe reward is: \n",
            " -0.5132518974672499\n",
            "The reward is:  The training process is: -0.7677400104411259 \n",
            "FalseThe training process is: \n",
            " False\n",
            "The reward is:  -0.8385415422755866\n",
            "The training process is:  False\n",
            "The reward is:  -0.8413467540721612\n",
            "The training process is:  False\n",
            "The reward is:  -0.7213203773751582\n",
            "The training process is:  False\n",
            "The reward is:  -0.500390421568031\n",
            "The training process is:  False\n",
            "The reward is:  -0.4853385959979041\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.640871\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.540998222156418\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 86 | Ep_r: -6\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.8146050842350986\n",
            "The training process is:  The delivered reward -5.997704679684337\n",
            "False\n",
            "The reward is:  The reward is: -1.0\n",
            "The training process is:  False -1.0\n",
            "\n",
            "The training process is:  False\n",
            "The reward is:  -0.7182279489709756\n",
            "The training process is:  False\n",
            "The reward is:  -0.5641633051228981\n",
            "The training process is:  False\n",
            "The reward is:  -0.356840217669492\n",
            "The training process is:  False\n",
            "The reward is:  -0.6543569986902488\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.8530156890540734\n",
            "The training process is:  False\n",
            "The reward is:  -0.5133041360457735\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 87 | Ep_r: -6\n",
            "The reward is:  -0.8273923119238249\n",
            "The training process is:  False\n",
            "The reward is:  -0.6165085115786216\n",
            "The training process is: The delivered reward -6.012472766685379\n",
            " The reward is: False \n",
            "-0.6680535933580887\n",
            "The reward is: The training process is:   False-0.823114473527283\n",
            "The training process is: \n",
            " False\n",
            "The reward is:  -0.6149679997033044\n",
            "The training process is:  False\n",
            "The reward is:  -0.6143240006809564\n",
            "The training process is:  False\n",
            "The reward is:  -0.6117559611050537\n",
            "The training process is:  False\n",
            "The reward is:  -0.7324480706658874\n",
            "The training process is:  False\n",
            "The reward is:  -0.7339041502771301\n",
            "The training process is:  False\n",
            "The reward is:  -0.7469010387271834\n",
            "The training process is:  False\n",
            "The reward is:  -0.7070260323095908\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 88 | Ep_r: -6\n",
            "The reward is:  -0.6288265330109882The reward is: \n",
            "The training process is:   -1.0False\n",
            "The training process is: \n",
            " False\n",
            "The reward is:  -0.4981418466669621The delivered reward -6.0226314645235135\n",
            "\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  0.276176\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.4541377310656527\n",
            "The training process is:  False\n",
            "The reward is:  -0.41737084216626413\n",
            "The training process is:  False\n",
            "The reward is:  -0.6045285400742808\n",
            "The training process is:  False\n",
            "The reward is:  -0.8258413392758446\n",
            "The training process is:  False\n",
            "The reward is:  -0.19498464779367183\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 89 | Ep_r: -6\n",
            "The reward is:  -0.38483352271546767\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is: The delivered reward -5.998643464678815\n",
            " -0.657673923989079\n",
            "The training process is:  False\n",
            "The reward is:  -0.7274555113830943\n",
            "The training process is:  False\n",
            "The reward is:  -0.31133113504597454\n",
            "The training process is:  False\n",
            "The reward is:  -0.7431714542926894\n",
            "The training process is: The reward is:   -0.8095134016518223False\n",
            "The reward is: \n",
            "The training process is:  -1.0 \n",
            "FalseThe training process is: \n",
            " False\n",
            "The reward is:  -0.7924226115318074\n",
            "The training process is:  False\n",
            "The reward is:  -0.5685232991380097\n",
            "The training process is:  False\n",
            "The reward is:  -0.5746790666893196\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 90 | Ep_r: -6\n",
            "The reward is:  -0.7771252459057877\n",
            "The training process is:  False\n",
            "The reward is:  -0.634253566519331\n",
            "The training process is: The delivered reward -6.006257935279881\n",
            " False\n",
            "The reward is:  -0.5408245470054046\n",
            "The training process is:  False\n",
            "The reward is:  -0.566998001642221\n",
            "The training process is:  False\n",
            "The reward is:  The reward is: -0.7831931130694298\n",
            " The training process is: -0.8037488929778469 False\n",
            "\n",
            "The training process is: The reward is:   -0.5392064408730841\n",
            "FalseThe training process is: \n",
            " False\n",
            "The reward is:  -0.3018364181300069\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  -0.02282539\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.31671861463980705\n",
            "The training process is:  False\n",
            "The reward is:  -0.5281962013849297\n",
            "The training process is:  False\n",
            "The reward is:  -0.5368039649118382\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 91 | Ep_r: -6\n",
            "The reward is:  -0.7547202210768674\n",
            "The training process is:  False\n",
            "The reward is:  -0.4362455046076996\n",
            "The delivered reward -6.0014469170679\n",
            "The training process is:  False\n",
            "The reward is:  -0.46035557184653425\n",
            "The training process is:  False\n",
            "The reward is:  -0.3402248428338094\n",
            "The training process is:  False\n",
            "The reward is:  -0.6407600264777653\n",
            "The training process is:  False\n",
            "The reward is:  -0.5765955053934614\n",
            "The training process is:  False\n",
            "The reward is:  -0.8404037857594104The reward is: \n",
            " The training process is: -0.42451329589006104 \n",
            "The training process is:  False\n",
            "False\n",
            "The reward is:  -0.5522172127037168\n",
            "The training process is:  False\n",
            "The reward is:  -0.34887339639630816\n",
            "The training process is:  False\n",
            "The reward is:  -0.23460949734687797\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 92 | Ep_r: -6\n",
            "The reward is:  -0.7572212105626401\n",
            "The training process is:  False\n",
            "The reward is: The delivered reward -5.9932825035416455\n",
            " -0.5983832228789262\n",
            "The training process is:  False\n",
            "The reward is:  -0.20540482552301667\n",
            "The training process is:  False\n",
            "The reward is:  -0.46550358751106763\n",
            "The training process is:  False\n",
            "The reward is:  -0.4410347448402532\n",
            "The training process is:  False\n",
            "The reward is:  -0.43594261875586604\n",
            "The training process is:  False\n",
            "The reward is:  -0.5804993536447085\n",
            "The training process is:  False\n",
            "The reward is:  -0.6508609735385446\n",
            "The training process is:  False\n",
            "The reward is:  -0.3940594562211782\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.5846778\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.4034567447651546\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 93 | Ep_r: -6\n",
            "The reward is:  -0.7469441843654572\n",
            "The training process is:  FalseThe delivered reward -5.982673345888642\n",
            "\n",
            "The reward is:  -0.42703166652092917\n",
            "The training process is:  False\n",
            "The reward is:  The reward is: -0.6831991359248268 -0.2102637547952751\n",
            "The training process is: \n",
            " The training process is: False False\n",
            "\n",
            "The reward is:  -0.8526652451919008\n",
            "The training process is:  False\n",
            "The reward is:  -0.4720066454415961\n",
            "The training process is:  False\n",
            "The reward is:  -0.6228278672053523\n",
            "The training process is:  False\n",
            "The reward is:  -0.6216636397436591\n",
            "The training process is:  False\n",
            "The reward is:  -0.6587945819427323\n",
            "The training process is:  False\n",
            "The reward is:  -0.5224535397270587\n",
            "The training process is:  False\n",
            "The reward is:  -0.4143250074799897\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 94 | Ep_r: -6\n",
            "The reward is:  The delivered reward -5.983065727565191\n",
            "-0.8530988816575261\n",
            "The training process is:  False\n",
            "The reward is:  -0.6781402901336656\n",
            "The training process is:  False\n",
            "The reward is:  -0.2157621669174631\n",
            "The training process is:  False\n",
            "The reward is:  -0.20481804762562977\n",
            "The training process is:  False\n",
            "The reward is:  -0.41715620926485536\n",
            "The training process is:  False\n",
            "The reward is:  -0.5551785613900473\n",
            "The training process is:  False\n",
            "The reward is:  -0.5458802586627405\n",
            "The training process is:  FalseThe reward is: \n",
            " -0.42127756559631424The reward is:  \n",
            "The training process is: -0.6762261803963698\n",
            " False\n",
            "The training process is: ******** sync has started ******** \n",
            "False****** sync is finished **********\n",
            "\n",
            "The reward is: w_0  -0.6251052559587311Ep:\n",
            " The training process is: 95  False| Ep_r: -6\n",
            "\n",
            "The reward is:  -0.6260646347485455\n",
            "The training process is: The delivered reward -5.991741294306905\n",
            " False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 96 | Ep_r: -6\n",
            "The reward is:  -0.7469441843654572\n",
            "The training process is:  The delivered reward -5.985798186231391\n",
            "False\n",
            "The reward is:  -0.747437545995399\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.6248634\n",
            "****** sync is finished **********\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.828864893087214\n",
            "The training process is:  False\n",
            "The reward is:  -0.6830734340176776\n",
            "The training process is:  False\n",
            "The reward is:  -0.8483415935617995\n",
            "The training process is:  False\n",
            "The reward is:  -0.8471971172285857\n",
            "\n",
            "FalseThe training process is:  The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.458568689022102\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep:The reward is:  97  | Ep_r: -6-1.0\n",
            "\n",
            "The training process is:  FalseThe reward is: \n",
            " -0.33250700235197483\n",
            "The training process is:  False\n",
            "The delivered reward -6.00754447894186\n",
            "The reward is:  -0.3495722474123276\n",
            "The training process is:  False\n",
            "The reward is:  -0.27022815123356636\n",
            "The training process is:  False\n",
            "The reward is:  -0.2597609920473357\n",
            "The training process is:  False\n",
            "The reward is:  -0.2817528085379019\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.34791848958278704\n",
            "The training process is:  False\n",
            "The reward is:  -0.12248268926870383\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 98 | Ep_r: -6\n",
            "The reward is:  -0.6815300492813048\n",
            "The training process is:  False\n",
            "The reward is:  -0.675975831759023The delivered reward -5.977111257956786\n",
            "\n",
            "The training process is:  False\n",
            "The reward is:  -0.6703691589303284\n",
            "The training process is:  False\n",
            "The reward is: The reward is:  -0.6711684514245524 -1.0\n",
            "The training process is:  \n",
            "The training process is:  FalseFalse\n",
            "\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.635316\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.8295787836266871\n",
            "The training process is:  False\n",
            "The reward is:  -0.8247725178809591\n",
            "The training process is:  False\n",
            "The reward is:  -0.4814384429910663\n",
            "The training process is:  False\n",
            "The reward is:  -0.4802321275922414\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 99 The reward is:  | Ep_r: -6-1.0\n",
            "\n",
            "The training process is:  FalseThe reward is: \n",
            " -0.7584404307983282\n",
            "The training process is:  False\n",
            "The reward is: The delivered reward -5.99049079901208\n",
            " -0.7579551723985605\n",
            "The training process is:  False\n",
            "The reward is:  -0.6376869534220998\n",
            "The training process is:  False\n",
            "The reward is:  -0.6348445188710491\n",
            "The training process is:  False\n",
            "The reward is:  -0.608381566968169\n",
            "The training process is:  False\n",
            "The reward is:  -0.6582673645005178\n",
            "The training process is:  False\n",
            "The reward is:  -0.6022314549012144\n",
            "The training process is:  False\n",
            "The reward is:  -0.49667426453507774\n",
            "The training process is: The reward is:  False \n",
            "-0.8324550117004748\n",
            "The training process is:  FalseThe reward is: \n",
            " -0.3689027697735357\n",
            "The training process is:  False\n",
            "The reward is:  -0.3429517457552217\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 100 | Ep_r: -6\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.6365324646351513\n",
            "The delivered reward -5.989249253441197\n",
            "The training process is:  False\n",
            "The reward is:  -0.62824021933398\n",
            "The training process is:  False\n",
            "The reward is:  -0.5166255465838959\n",
            "The training process is:  False\n",
            "The reward is:  -0.49522998679698516\n",
            "The training process is:  False\n",
            "The reward is:  -0.48426723097857505\n",
            "The training process is:  False\n",
            "The reward is:  -0.5882115545091653\n",
            "The reward is: The training process is:   -0.8560166709198034\n",
            "False\n",
            "The training process is:  FalseThe reward is: \n",
            " -0.5952739439030944\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.5898843\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.5881060406981043\n",
            "The training process is:  False\n",
            "The reward is:  -0.5801362992373453\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 101 | Ep_r: -6\n",
            "The reward is:  -0.8406603725326462\n",
            "The training process is:  False\n",
            "The reward is:  -0.5509430721421305\n",
            "The training process is: The delivered reward -5.990482993773548\n",
            " False\n",
            "The reward is:  -0.43740939275107865\n",
            "The training process is:  False\n",
            "The reward is:  -0.8211614788630577\n",
            "The training process is:  False\n",
            "The reward is:  -0.4397461867722365\n",
            "The training process is:  False\n",
            "The reward is:  -0.3398154936133917\n",
            "The training process is:  False\n",
            "The reward is:  -0.4100815702993438\n",
            "The training process is:  False\n",
            "The reward is:  -0.38025096990844787\n",
            "The training process is:  False\n",
            "The reward is:  -0.21740814416859902\n",
            "The training process is:  False\n",
            "The reward is:  -0.6275310637147297\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 102 | Ep_r: -6\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is: The delivered reward -5.9812282412834685\n",
            " -0.605952719549374\n",
            "The training process is:  False\n",
            "The reward is:  -0.6063362303890564\n",
            "The training process is:  False\n",
            "The reward is:  -0.6054532646179387\n",
            "The training process is:  False\n",
            "The reward is:  -0.5805286201625179\n",
            "The training process is:  False\n",
            "The reward is:  -0.7132576562764479\n",
            "The training process is:  False\n",
            "The reward is:  -0.5939362295940086\n",
            "The training process is:  False\n",
            "The reward is:  -0.468730463373367\n",
            "The training process is:  False\n",
            "The reward is:  -0.8530156890540734\n",
            "The training process is:  FalseThe reward is: \n",
            " The reward is: -0.8516716070053771\n",
            "The training process is:  False -0.2646102351073994\n",
            "\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 103 | Ep_r: -6\n",
            "The reward is:  -0.6500649651103366\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  -0.15497154\n",
            "The delivered reward -5.984334169951876\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.4046693180589722\n",
            "The training process is:  False\n",
            "The reward is:  -0.40122978788432917\n",
            "The training process is:  False\n",
            "The reward is:  -0.3925791187057603\n",
            "The training process is:  False\n",
            "The reward is: The reward is:   -0.6537143684634802-0.3768591887643369\n",
            "\n",
            "The training process is: The training process is:   FalseFalse\n",
            "\n",
            "The reward is:  -0.34098362912032365\n",
            "The training process is:  False\n",
            "The reward is:  -0.22893034995420464\n",
            "The training process is:  False\n",
            "The reward is:  -0.18130057710579264\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 104 | Ep_r: -6\n",
            "The delivered reward -5.954256997599398\n",
            "The reward is:  -0.8431018495227711\n",
            "The training process is:  False\n",
            "The reward is:  -0.6651415082376796\n",
            "The training process is:  False\n",
            "The reward is:  -0.3499810271837408\n",
            "The training process is:  False\n",
            "The reward is:  -0.32459164977319477\n",
            "The training process is:  False\n",
            "The reward is:  -0.42877375977196514\n",
            "The training process is:  False\n",
            "The reward is:  -0.5063195502622985\n",
            "The training process is:  False\n",
            "The reward is:  -0.6301542563968878\n",
            "The training process is:  False\n",
            "The reward is:  -0.2831253030027628\n",
            "The training process is:  False\n",
            "The reward is:  -0.3090237553980622\n",
            "The training process is:  False\n",
            "The reward is:  -0.36363065287403507\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.596583177692886\n",
            "The training process is:  False\n",
            "w_1 Ep: 105 | Ep_r: -6\n",
            "The reward is:  -0.6532477400885041\n",
            "The training process is:  False\n",
            "The reward is: The delivered reward -5.941752860747638\n",
            " -0.34983673236405755\n",
            "The training process is:  False\n",
            "The reward is:  -0.33209992120621845\n",
            "The training process is:  False\n",
            "The reward is:  -0.19451248360820766\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 106 | Ep_r: -6\n",
            "The reward is:  -0.8315013070410803\n",
            "The delivered reward -5.897632300912831\n",
            "The training process is:  False\n",
            "The reward is:  -0.8083765687986324\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.5660208\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.5788847676942903\n",
            "The training process is:  False\n",
            "The reward is:  -0.5622815089326678\n",
            "The training process is:  False\n",
            "The reward is:  -0.548434492320905\n",
            "The training process is:  False\n",
            "The reward is:  -0.32093966956893916\n",
            "The training process is:  False\n",
            "The reward is:  -0.32688667390515747\n",
            "The training process is:  False\n",
            "The reward is:  -0.4403897173930463\n",
            "The training process is:  FalseThe reward is: \n",
            " -0.7252279425501906\n",
            "The reward is: The training process is:   -0.5709298196070035False\n",
            "\n",
            "The training process is:  False\n",
            "The reward is:  -0.4130507184875977\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 107 | Ep_r: -6\n",
            "The delivered reward -5.8926727303411965\n",
            "The reward is:  -0.8315013070410803\n",
            "The training process is:  False\n",
            "The reward is:  -0.7100470074751513\n",
            "The training process is:  False\n",
            "The reward is:  -0.2950455041769409\n",
            "The training process is:  False\n",
            "The reward is:  -0.47082790531337243\n",
            "The training process is:  False\n",
            "The reward is:  -0.46588630108012125\n",
            "The training process is:  False\n",
            "The reward is:  -0.4424304927989782\n",
            "The training process is:  False\n",
            "The reward is:  -0.4449930573236718\n",
            "The training process is:  False\n",
            "The reward is:  -0.45298871530209855\n",
            "The training process is:  False\n",
            "The reward is:  -0.5885141036848465\n",
            "The training process is:  False\n",
            "The reward is:  -0.6515480021831761\n",
            "The reward is:  The training process is: False \n",
            "-0.7171155045272871******** sync has started ********\n",
            "\n",
            "The training process is: ****** sync is finished ********** \n",
            "w_1False \n",
            "Ep: 108******** sync has started ******** \n",
            "| Ep_r: -6\n",
            "****** sync is finished **********\n",
            "The reward is: w_0 Ep:  -1.0109\n",
            " The training process is: | Ep_r: -6 \n",
            "False\n",
            "The reward is:  -0.8047523811299317\n",
            "The training process is:  FalseThe delivered reward -5.887283827001579\n",
            "The delivered reward -5.910738831560158\n",
            "\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.6892510497845559\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.6486707\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.7800645261970438\n",
            "The training process is:  False\n",
            "The reward is:  -0.7723329726535866\n",
            "The training process is:  False\n",
            "The reward is:  -0.7698399222945462\n",
            "The training process is:  False\n",
            "The reward is:  -0.6778671012286628\n",
            "The training process is:  False\n",
            "The reward is:  -0.6726333340563483\n",
            "The reward is: The training process is:   False\n",
            "-0.7489668496956072\n",
            "The reward is: The training process is:   -0.3969026854605967False\n",
            "The training process is: \n",
            " False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 110 | Ep_r: -6\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.7858200453633273\n",
            "The training process is:  False\n",
            "The delivered reward -5.927267882972608\n",
            "The reward is:  -0.3867822604776968\n",
            "The training process is:  False\n",
            "The reward is:  -0.7609424345330614\n",
            "The training process is:  False\n",
            "The reward is:  -0.6282302848557665\n",
            "The training process is:  False\n",
            "The reward is:  -0.4075057509399005\n",
            "The training process is:  False\n",
            "The reward is:  -0.4010515631704575\n",
            "The training process is:  False\n",
            "The reward is: The reward is:   -0.7567896490893853\n",
            "-0.6130057772983142The training process is: \n",
            " The training process is:  FalseFalse\n",
            "******** sync has started ********\n",
            "\n",
            "v_s_ is:  The reward is: 1.5867172 \n",
            "-0.48647358074032654\n",
            "****** sync is finished **********\n",
            "The training process is:  False\n",
            "The reward is:  -0.48031023708111126\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 111 | Ep_r: -6\n",
            "The reward is:  -0.6833603047213983\n",
            "The training process is:  False\n",
            "The reward is:  The delivered reward -5.927496423487482\n",
            "-0.2651094990095754\n",
            "The training process is:  False\n",
            "The reward is:  -0.2485434661218703\n",
            "The training process is:  False\n",
            "The reward is:  The reward is: -0.21539922480507143 -0.5514299879773636\n",
            "\n",
            "The training process is:  The training process is: False \n",
            "False\n",
            "The reward is:  -0.4253080568252761\n",
            "The training process is:  False\n",
            "The reward is:  -0.2164658662649\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  0.30868232\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.4642129166916454\n",
            "The training process is:  False\n",
            "The reward is:  -0.41744235018923226\n",
            "The training process is:  False\n",
            "The reward is:  -0.44694639526533403\n",
            "The training process is:  False\n",
            "The reward is:  -0.16355421356433414\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: The reward is: 112 | Ep_r: -6\n",
            " -0.563885313604086The reward is: \n",
            " -1.0The training process is:  False\n",
            "The training process is:  \n",
            "False\n",
            "The reward is:  The delivered reward -5.903684882187194\n",
            "-0.7262031879540121\n",
            "The training process is:  False\n",
            "The reward is:  -0.6457537626722191\n",
            "The training process is:  False\n",
            "The reward is:  -0.8057423229041423\n",
            "The training process is:  False\n",
            "The reward is:  -0.6289902427527801\n",
            "The training process is:  False\n",
            "The reward is:  -0.8330912755667453\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.6822121486911716\n",
            "The training process is:  False\n",
            "The reward is:  -0.537361898337337\n",
            "The training process is:  False\n",
            "The reward is:  The reward is: -0.585266258979192 -0.5755065955944912\n",
            "The training process is:  False\n",
            "\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 113 | Ep_r: -6\n",
            "The reward is:  -0.6493138024972374\n",
            "The training process is:  False\n",
            "The reward is:  -0.3373083720543953\n",
            "The delivered reward -5.919094244343897\n",
            "The training process is:  False\n",
            "The reward is:  -0.6341676385322712\n",
            "The training process is:  False\n",
            "The reward is:  -0.19569357614002306\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 114 | Ep_r: -6\n",
            "The reward is:  -0.5667149121125513\n",
            "The training process is:  FalseThe delivered reward -5.878068135792698\n",
            "\n",
            "The reward is:  -0.40574231453501125\n",
            "The training process is:  False\n",
            "The reward is:  -0.050532344526812475\n",
            "The training process is:  The reward is: True \n",
            "-0.7511358627277734******** sync has started ********\n",
            "\n",
            "The training process is:  ****** sync is finished **********\n",
            "Falsew_1\n",
            " Ep: 115 | Ep_r: -6\n",
            "The reward is:  -0.6086427982495749\n",
            "The training process is:  False\n",
            "The reward is:  -0.36328199642486336\n",
            "The training process is: The delivered reward -5.8295173501465145\n",
            " False\n",
            "The reward is:  -0.413262572967492\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  -0.0825091\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.6088193837210935\n",
            "The training process is:  False\n",
            "The reward is:  -0.45133147989432565\n",
            "The training process is:  False\n",
            "The reward is:  -0.510534471827506\n",
            "The training process is:  False\n",
            "The reward is:  The reward is: -0.28894105577310947 \n",
            "-0.748381721559354\n",
            "The training process is: The training process is:  False\n",
            " False\n",
            "The reward is:  -0.31216641694600994\n",
            "The training process is:  False\n",
            "The reward is:  -0.3231695601553952\n",
            "The training process is:  False\n",
            "The reward is:  -0.3242953624558899\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 116 | Ep_r: -6\n",
            "The reward is:  -0.7620385781894294\n",
            "The training process is:  False\n",
            "The reward is:  -0.4201850386247269The delivered reward -5.813266627629202\n",
            "\n",
            "The training process is:  False\n",
            "The reward is:  -0.7522783934687156\n",
            "The training process is:  False\n",
            "The reward is:  -0.5221387946589928\n",
            "The training process is:  False\n",
            "The reward is:  -0.5252898996050375\n",
            "The training process is:  False\n",
            "The reward is:  -0.5526216391670703\n",
            "The training process is:  False\n",
            "The reward is:  -0.6081768342045045\n",
            "The training process is: The reward is:  -0.6076496827582256 False\n",
            "The training process is: \n",
            "The reward is:  False\n",
            " -0.39951002784115436\n",
            "The training process is:  False\n",
            "The reward is:  -0.2549296763820548\n",
            "The training process is:  False\n",
            "The reward is:  -0.1347518599627434\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 117 | Ep_r: -6\n",
            "The reward is:  -0.6889941763607647\n",
            "The training process is:  False\n",
            "The reward is: The delivered reward -5.8044531687739545\n",
            " -0.4488935703739182\n",
            "The training process is:  False\n",
            "The reward is:  -0.2958933482357698\n",
            "The training process is: The reward is:   False-0.6252262661369421\n",
            "\n",
            "The reward is: The training process is:  -0.4876602185635505 False\n",
            "\n",
            "The training process is:  False\n",
            "The reward is:  -0.6449433627950851\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  -1.5702829\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.6635568535256834\n",
            "The training process is:  False\n",
            "The reward is:  -0.49215485848051826\n",
            "The training process is:  False\n",
            "The reward is:  -0.5142300807085155\n",
            "The training process is:  False\n",
            "The reward is:  -0.6779486733497849\n",
            "The training process is:  False\n",
            "The reward is:  -0.5336230398537657\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 118 | Ep_r: -6\n",
            "The reward is:  -0.8009247954605424\n",
            "The training process is:  False\n",
            "The reward is: The reward is:  -0.7843980384171452 \n",
            "-0.6538255326471447\n",
            "The training process is: The training process is:  False\n",
            " The delivered reward -5.800887618908688\n",
            "******** sync has started ********\n",
            "False****** sync is finished **********\n",
            "\n",
            " w_0Ep: 119The reward is:   | Ep_r: -6-0.45568904716676084\n",
            "The training process is: \n",
            " False\n",
            "The reward is:  -0.42960740826385085\n",
            "The training process is:  False\n",
            "The delivered reward -5.808706717337505\n",
            "The reward is:  -0.4653154719209304\n",
            "The training process is:  False\n",
            "The reward is:  -0.44295766494518346\n",
            "The training process is:  False\n",
            "The reward is:  -0.48337479646456527\n",
            "The training process is:  False\n",
            "The reward is:  -0.6674926997386442\n",
            "The training process is:  False\n",
            "The reward is:  -0.5085766053708655\n",
            "The training process is:  False\n",
            "The reward is:  -0.618105444699131\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 120 | Ep_r: -6\n",
            "The reward is:  -0.8300584685595671\n",
            "The training process is:  False\n",
            "The reward is: The reward is:  -0.8356036353457531 -1.0\n",
            "The training process is: \n",
            "The training process is: The delivered reward -5.807184069888606\n",
            "  FalseFalse\n",
            "\n",
            "The reward is:  -0.8386226194700896\n",
            "The training process is:  False\n",
            "The reward is:  -0.01039153683967522\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 121 | Ep_r: -6\n",
            "The reward is:  -0.8010601612204435\n",
            "The training process is:  False\n",
            "The delivered reward -5.7742589917918705\n",
            "The reward is:  -0.25104762032491296\n",
            "The training process is:  False\n",
            "The reward is:  0.03030966133154085\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 122 | Ep_r: -6\n",
            "The reward is:  -0.6642212512868202\n",
            "The training process is:  False\n",
            "The reward is: The reward is:  -0.34028681580255304 \n",
            "The training process is: -0.7253979382958304 \n",
            "False\n",
            "The training process is: ******** sync has started ******** \n",
            "The delivered reward -5.7267343830760895\n",
            "Falsev_s_ is:  \n",
            "0.0080873445\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.5923297356079876\n",
            "The training process is:  False\n",
            "The reward is:  -0.6015736558663111\n",
            "The training process is:  False\n",
            "The reward is:  -0.7592929499388239\n",
            "The training process is:  False\n",
            "The reward is:  -0.6135798972622438\n",
            "The training process is:  False\n",
            "The reward is:  -0.5283352420453339\n",
            "The training process is:  False\n",
            "The reward is:  -0.8086344086538932\n",
            "The training process is:  False\n",
            "The reward is:  -0.5788453045605426\n",
            "The training process is:  False\n",
            "The reward is:  -0.45369547229597573\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 123 | Ep_r: -6\n",
            "The reward is:  -0.7596313098152292\n",
            "The training process is:  False\n",
            "The reward is:  -0.5251575244747937\n",
            "The delivered reward -5.728874986578534\n",
            "The training process is:  False\n",
            "The reward is:  -0.3215011937326838\n",
            "The training process is:  False\n",
            "The reward is:  -0.6748504741346988\n",
            "The training process is:  False\n",
            "The reward is:  -0.6906072391811227\n",
            "The training process is:  The reward is:  False\n",
            "-0.5060725268303827\n",
            "The reward is:  The training process is: -0.6952653549663358\n",
            "The training process is:   FalseFalse\n",
            "\n",
            "The reward is:  -0.48583512926344935\n",
            "The training process is:  False\n",
            "The reward is:  -0.48562978177456434\n",
            "The training process is:  False\n",
            "The reward is:  -0.6074967206568149\n",
            "The training process is:  False\n",
            "The reward is:  -0.6126752605271099\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 124 | Ep_r: -6\n",
            "The reward is:  -0.7899862851731331\n",
            "The training process is:  False\n",
            "The reward is:  -0.5991185697512943\n",
            "The training process is:  False\n",
            "The delivered reward -5.730172736598017\n",
            "The reward is:  -0.5588706280928061\n",
            "The training process is:  False\n",
            "The reward is:  -0.5727480490703672\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.634601The reward is: \n",
            "****** sync is finished **********\n",
            " -0.7228437826793099The reward is: \n",
            " The training process is: -0.6285818144282684\n",
            " The training process is: False \n",
            "False\n",
            "The reward is:  -0.4531004867180378\n",
            "The training process is:  False\n",
            "The reward is:  -0.43407729962656205\n",
            "The training process is:  False\n",
            "The reward is:  -0.5113201033570365\n",
            "The training process is:  False\n",
            "The reward is:  -0.5513579469787222\n",
            "The training process is:  False\n",
            "The reward is:  -0.727271204913896\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 125 | Ep_r: -6\n",
            "The reward is:  -0.6086564323498111\n",
            "The training process is:  False\n",
            "The reward is: The delivered reward -5.731135333113137\n",
            " -0.6092211803804715\n",
            "The training process is:  False\n",
            "The reward is:  -0.4551338559470712\n",
            "The training process is:  False\n",
            "The reward is:  -0.34359986215838884The reward is: \n",
            "The training process is:   False-0.722692278090437\n",
            "\n",
            "The reward is: The training process is:   -0.6825682476166112False\n",
            "\n",
            "The training process is:  False\n",
            "The reward is:  -0.4956200157808016\n",
            "The training process is:  False\n",
            "The reward is:  -0.5032748490141453\n",
            "The training process is:  False\n",
            "The reward is:  -0.6756026280674847\n",
            "The training process is:  False\n",
            "The reward is:  -0.44885610620508665\n",
            "The training process is:  False\n",
            "The reward is:  -0.694177975246771\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 126 | Ep_r: -6\n",
            "The reward is:  -0.6988794194782141\n",
            "The training process is:  False\n",
            "The reward is: The delivered reward -5.7289910913096715\n",
            "The reward is:  -0.7222745397497004\n",
            "The training process is:   False\n",
            "-0.8066251209597152\n",
            "The training process is:  False\n",
            "The reward is:  -0.47021267050447835\n",
            "The training process is:  False\n",
            "The reward is:  -0.5375815174255371\n",
            "The training process is:  False\n",
            "The reward is:  -0.30197332948453515\n",
            "The training process is:  False\n",
            "The reward is:  -0.1649834188438833\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 127 | Ep_r: -6\n",
            "The reward is:  -0.732361575105058\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.5897015The delivered reward -5.701503735163539\n",
            "\n",
            "****** sync is finished **********\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.6521353836946017\n",
            "The reward is: The training process is:   -0.7225453918448916\n",
            "The training process is:  FalseFalse\n",
            "\n",
            "The reward is:  -0.6480102302340527\n",
            "The training process is:  False\n",
            "The reward is:  -0.5161399868729698\n",
            "The training process is:  False\n",
            "The reward is:  -0.17047680744107324\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 128 | Ep_r: -6\n",
            "The reward is:  -0.7117979733875375\n",
            "The training process is:  False\n",
            "The reward is:  -0.7075587718816884\n",
            "The training process is:  False\n",
            "The delivered reward -5.681679937645381\n",
            "The reward is:  -0.5164206196798812\n",
            "The training process is:  False\n",
            "The reward is:  -0.5241766948416556\n",
            "The training process is:  False\n",
            "The reward is:  -0.5141033323249575\n",
            "The training process is:  The reward is: False \n",
            "-0.6503589865118755The reward is: \n",
            " -0.49059958957996186\n",
            "The training process is: The training process is:   False\n",
            "False\n",
            "The reward is:  -0.48947796152784334\n",
            "The training process is:  False\n",
            "The reward is:  -0.48053457617409573\n",
            "The training process is:  False\n",
            "The reward is:  -0.4658979219637004\n",
            "The training process is:  False\n",
            "The reward is:  -0.5822116719396908\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 129 | Ep_r: -6\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The delivered reward -5.6796909294019375\n",
            "The reward is:  -0.6911326084124022\n",
            "The training process is:  False\n",
            "The reward is:  -0.6869243036966599\n",
            "The training process is:  False\n",
            "The reward is:  -0.8545804352433283\n",
            "The training process is:  False\n",
            "The reward is:  -0.7733183260837193\n",
            "The training process is:  False\n",
            "The reward is:  -0.7702256629702873\n",
            "The training process is:  False\n",
            "The reward is:  -0.8187308535265778\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.5977336\n",
            "****** sync is finished **********The reward is: \n",
            " -0.638971658337065The reward is: \n",
            " The training process is: -0.8386226194700896 \n",
            "FalseThe training process is: \n",
            " False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.8545478351886674\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 130 | Ep_r: -6\n",
            "The reward is:  -0.6504157355726857\n",
            "The training process is:  False\n",
            "The reward is:  -0.5158672433571554\n",
            "The delivered reward -5.705774846553836\n",
            "The training process is:  False\n",
            "The reward is:  -0.649568554482012\n",
            "The training process is:  False\n",
            "The reward is:  -0.647102871102286\n",
            "The training process is:  False\n",
            "The reward is:  -0.8497301117016949\n",
            "The training process is:  False\n",
            "The reward is:  -0.6137250011539812\n",
            "The training process is:  False\n",
            "The reward is:  -0.2857191887170337\n",
            "The training process is:  False\n",
            "The reward is:  -0.47366445788563655\n",
            "The training process is:  False\n",
            "The reward is:  -0.43120004730265515\n",
            "The reward is: The training process is:   -0.25369947679664817False\n",
            "\n",
            "******** sync has started ********The training process is: \n",
            " ****** sync is finished **********False\n",
            "\n",
            "w_0 The reward is: Ep:  131-0.26119708970336536 \n",
            "| Ep_r: -6\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 132 The delivered reward -5.717140669584719\n",
            "The delivered reward -5.711976160193597\n",
            "| Ep_r: -6\n",
            "The reward is:  -0.2789928500136921\n",
            "The training process is:  False\n",
            "The reward is:  -0.36741962389430033\n",
            "The training process is:  False\n",
            "The reward is:  0.08565652538490236\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 133 | Ep_r: -6\n",
            "The reward is:  -0.4918399520426169\n",
            "The training process is:  The reward is: False \n",
            "-0.6321953335211115\n",
            "The training process is:  False\n",
            "The delivered reward -5.660463958076892\n",
            "The reward is:  -0.7924226115318074\n",
            "The training process is:  False\n",
            "The reward is:  -0.5502740490573333\n",
            "The training process is:  False\n",
            "The reward is:  -0.2604272070205162\n",
            "The training process is:  False\n",
            "The reward is:  -0.4287099791971432\n",
            "The training process is:  False\n",
            "The reward is:  -0.06422139610319581\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 134 | Ep_r: -6\n",
            "The reward is:  -0.8071559663813919\n",
            "The training process is:  False\n",
            "The reward is: The delivered reward -5.631141824260434\n",
            " -0.7169260766327995\n",
            "The training process is:  FalseThe reward is: \n",
            " ******** sync has started ********-0.523370103995938\n",
            "\n",
            "The training process is:  v_s_ is:  0.5798243False\n",
            "\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.6698369065142031\n",
            "The training process is:  False\n",
            "The reward is:  -0.8179361205626506\n",
            "The training process is:  False\n",
            "The reward is:  -0.5540353510218026\n",
            "The training process is:  False\n",
            "The reward is:  -0.5458614965655031\n",
            "The training process is:  False\n",
            "The reward is:  -0.8080220091325347\n",
            "The training process is:  False\n",
            "The reward is:  -0.8014311339567677\n",
            "The training process is:  False\n",
            "The reward is:  -0.5363240802620013\n",
            "The training process is:  FalseThe reward is:  \n",
            "-0.7309732407842737\n",
            "The reward is: The training process is:   False\n",
            "-0.48600825634590955\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 135 | Ep_r: -6\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.6626401989274596\n",
            "The training process is:  FalseThe delivered reward -5.642265779991585\n",
            "\n",
            "The reward is:  -0.6646357308376345\n",
            "The training process is:  False\n",
            "The reward is:  -0.41265733961824347\n",
            "The training process is:  False\n",
            "The reward is:  -0.6382484411493297\n",
            "The training process is:  False\n",
            "The reward is:  -0.6092435899664841\n",
            "The training process is:  False\n",
            "The reward is:  -0.6420461759622919\n",
            "The training process is:  False\n",
            "The reward is:  -0.6406399038395229\n",
            "The training process is:  False\n",
            "The reward is:  -0.6107644091832242\n",
            "The training process is:  The reward is: False -0.845298385510698\n",
            "\n",
            "The reward is: The training process is:   -0.6105356873737862False\n",
            "\n",
            "******** sync has started ********\n",
            "The training process is:  Falsev_s_ is: \n",
            " ******** sync has started ********0.5286441\n",
            "\n",
            "****** sync is finished **********\n",
            "****** sync is finished **********w_1 Ep: \n",
            "136 | Ep_r: -6\n",
            "The reward is:  -0.7716797670664756\n",
            "The training process is:  False\n",
            "The reward is:  -0.8223597385851003\n",
            "The training process is:  False\n",
            "The reward is:  -0.6037933049459854\n",
            "The training process is:  False\n",
            "The delivered reward -5.650757236960248\n",
            "The reward is:  -0.7748306317676052\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  -0.27600288\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.7933298528512825\n",
            "The training process is:  False\n",
            "The reward is:  -0.7828735724548854\n",
            "The training process is:  False\n",
            "The reward is:  -0.34838829523054377\n",
            "The training process is:  False\n",
            "The reward is:  -0.38001433918205524\n",
            "The training process is:  False\n",
            "The reward is:  -0.7942425716973209\n",
            "The training process is:  False\n",
            "The reward is:  -0.6596956225359556\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep:137  | Ep_r: -6\n",
            "The reward is: The reward is:  -0.6108317236449994\n",
            " The training process is:  False-0.8189963718736643\n",
            "The reward is:  -0.5812815858559809\n",
            "\n",
            "The training process is:  The training process is: False\n",
            " FalseThe reward is: \n",
            " -0.45665051509192134\n",
            "The training process is:  False\n",
            "The delivered reward -5.661561741553818\n",
            "The reward is:  -0.8264178329014094\n",
            "The training process is:  False\n",
            "The reward is:  -0.5295190145571554\n",
            "The training process is:  False\n",
            "The reward is:  -0.49643760378263757\n",
            "The training process is:  False\n",
            "The reward is:  -0.48925924421171113\n",
            "The training process is:  False\n",
            "The reward is:  -0.43270699972376103\n",
            "The training process is:  False\n",
            "The reward is:  -0.4325368334180807\n",
            "The training process is:  False\n",
            "The reward is:  -0.7858282582254899\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 138 | Ep_r: -6\n",
            "The reward is:  -1.0The training process is: \n",
            " False\n",
            "The reward is:  -0.8522626762244915\n",
            "The training process is:  False\n",
            "The reward is:  -0.4126818143524158The delivered reward -5.661360820252412\n",
            "\n",
            "The reward is: The training process is:   False-0.4662847786974903\n",
            "\n",
            "The training process is: The reward is:  False\n",
            " -0.3983694420355682\n",
            "The training process is:  False\n",
            "The reward is:  -0.3071577987183379\n",
            "The training process is:  False\n",
            "The reward is:  -0.284555293344836\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.4450173\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.25974054726105533\n",
            "The training process is:  False\n",
            "The reward is:  -0.469513989288145\n",
            "The training process is:  False\n",
            "The reward is:  -0.48273067715628704\n",
            "The training process is:  False\n",
            "The reward is:  -0.6324379497756147\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 139 | Ep_r: -6\n",
            "The reward is:  -0.5147740720842167\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The delivered reward -5.655741713931455\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.49547442707833156\n",
            "The training process is:  False\n",
            "The reward is:  -0.2364344865563551\n",
            "The training process is:  False\n",
            "The reward is:  -0.24973084447588811\n",
            "The training process is: The reward is:   False-0.4990724344252646\n",
            "\n",
            "The training process is:  The reward is: False -0.790651720711212\n",
            "\n",
            "The training process is:  False\n",
            "The reward is:  -0.01874742611197906\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 140 | Ep_r: -6\n",
            "The reward is:  -0.6985516356718968\n",
            "The training process is:  False\n",
            "The reward is: The delivered reward -5.64224242656232\n",
            " -0.7577367236922772\n",
            "The training process is:  False\n",
            "The reward is:  -0.5663212704643212\n",
            "The training process is:  False\n",
            "The reward is:  -0.2338084253516879\n",
            "The training process is:  False\n",
            "The reward is:  -0.33676330389669634\n",
            "The training process is:  False\n",
            "The reward is:  -0.28531899561775353\n",
            "The training process is:  False\n",
            "The reward is:  -0.1968971760708313\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 141 | Ep_r: -6\n",
            "The reward is:  -0.6\n",
            "The training process is:  FalseThe reward is: \n",
            "The reward is:  -0.5031100751736984 \n",
            "The training process is: -1.0\n",
            " FalseThe delivered reward -5.616573977604352\n",
            "The training process is: \n",
            " False\n",
            "The reward is:  -0.6\n",
            "The training process is:  False\n",
            "The reward is:  -0.35844043079832827\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.6111817\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.6020992612451239\n",
            "The training process is:  False\n",
            "The reward is:  -0.6\n",
            "The training process is:  False\n",
            "The reward is:  -0.6\n",
            "The training process is:  False\n",
            "The reward is:  -0.3831931130694298\n",
            "The training process is:  False\n",
            "The reward is:  -0.6\n",
            "The training process is:  False\n",
            "The reward is:  -0.6\n",
            "The training process is:  False\n",
            "******** sync has started ********The reward is: \n",
            " -0.501408834810665****** sync is finished **********\n",
            "\n",
            "The training process is:  w_1False \n",
            "Ep: 142 | Ep_r: -6\n",
            "The reward is:  -0.5576241371655508\n",
            "The training process is:  False\n",
            "The delivered reward -5.619845565879436\n",
            "The reward is:  -0.7407494581357084\n",
            "The training process is:  False\n",
            "The reward is:  -0.30136282804589337\n",
            "The training process is:  False\n",
            "The reward is:  -0.2139084924246693\n",
            "The training process is:  False\n",
            "The reward is:  -0.4488368942455604\n",
            "The training process is:  False\n",
            "The reward is:  -0.6187417865654045\n",
            "The training process is:  False\n",
            "The reward is:  -0.3973848468194442\n",
            "The training process is:  False\n",
            "The reward is:  -0.3049091942709673\n",
            "The training process is:  False\n",
            "The reward is:  -0.4149047344613602\n",
            "The training process is:  False\n",
            "The reward is:  -0.05379302923388214\n",
            "The training process is: The reward is:   True\n",
            "******** sync has started ********\n",
            "-0.50960201877562\n",
            "****** sync is finished **********The training process is: \n",
            " w_1False \n",
            "Ep:******** sync has started ******** \n",
            "****** sync is finished **********143 | Ep_r: -6\n",
            "\n",
            "w_0 Ep:The reward is:  144  -0.7730299784458561\n",
            "| Ep_r: -6The training process is: \n",
            " False\n",
            "The reward is:  -0.5395190283283751\n",
            "The training process is: The delivered reward -5.604169264234327\n",
            "The delivered reward -5.607027133552883\n",
            " False\n",
            "The reward is:  -0.5833672580830637\n",
            "The training process is:  False\n",
            "The reward is:  -0.38843483533107415\n",
            "The training process is:  False\n",
            "The reward is:  -0.3887308028757531\n",
            "The training process is:  False\n",
            "The reward is:  -0.6164126806943722\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  0.48297757\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.4554177620296523\n",
            "The training process is:  False\n",
            "The reward is:  -0.603704591098846\n",
            "The training process is:  False\n",
            "The reward is:  -0.3348397603280782\n",
            "The training process is:  FalseThe reward is: \n",
            " The reward is: -0.3761728265233042 \n",
            "-0.4931609219451377The training process is: \n",
            " The training process is: False \n",
            "False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 145 | Ep_r: -6\n",
            "The reward is:  -0.37234064640263315\n",
            "The training process is:  False\n",
            "The reward is:  -0.8223597385851003\n",
            "The training process is:  FalseThe delivered reward -5.602723038408956\n",
            "\n",
            "The reward is:  -0.7252099581418026\n",
            "The training process is:  False\n",
            "The reward is:  -0.43563489944294354\n",
            "The training process is:  False\n",
            "The reward is:  -0.45579429996804344\n",
            "The training process is:  False\n",
            "The reward is:  -0.6460139228565327\n",
            "The training process is:  False\n",
            "The reward is:  -0.4959600165410258\n",
            "The training process is:  False\n",
            "The reward is:  -0.7873518158051274\n",
            "The training process is:  False\n",
            "The reward is:  -0.8453723300293452\n",
            "The training process is:  False\n",
            "The reward is:  -0.625805114108822\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 146 | Ep_r: -6\n",
            "The reward is:  -0.811504772514548\n",
            "The training process is:  False\n",
            "The reward is:  -0.7710053766502232\n",
            "The training process is:  The delivered reward -5.60881423544368\n",
            "False\n",
            "The reward is:  -0.21671769181914824\n",
            "The training process is:  False\n",
            "The reward is:  -0.2036161546952167\n",
            "The training process is:  False\n",
            "The reward is:  -0.19542206270463525\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 147 | Ep_r: -6\n",
            "The reward is:  -0.8486956100756629\n",
            "The training process is:  False\n",
            "The reward is:  -0.6\n",
            "The training process is:  False\n",
            "The delivered reward -5.5747087536730815\n",
            "The reward is:  -0.2916262759857021\n",
            "The training process is:  False\n",
            "The reward is:  -0.4451284999715375\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  -2.2724605\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.32299610896055336\n",
            "The training process is:  False\n",
            "The reward is:  -0.328850234758393\n",
            "The training process is:  False\n",
            "The reward is:  -0.343420677971843\n",
            "The reward is:  -0.365730757767548The training process is: \n",
            "The training process is:  False\n",
            " False\n",
            "The reward is:  -0.1837596010147804\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 148 | Ep_r: -6\n",
            "The reward is:  -0.615934030537199\n",
            "The training process is:  False\n",
            "The reward is: The delivered reward -5.552606436223735\n",
            " -0.6084329497296302\n",
            "The training process is:  False\n",
            "The reward is:  -0.4086848402986737\n",
            "The training process is:  False\n",
            "The reward is:  -0.4135717379755022\n",
            "The training process is:  False\n",
            "The reward is:  -0.752043522179972\n",
            "The training process is:  False\n",
            "The reward is:  -0.7785219371556773\n",
            "The training process is:  False\n",
            "The reward is:  -0.6579875678134175\n",
            "The training process is:  False\n",
            "The reward is:  -0.8300584685595671\n",
            "The training process is:  False\n",
            "The reward is:  -0.28958623446861054\n",
            "The training process is:  False\n",
            "The reward is:  -0.2947371661665342\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep:The reward is:   149 -0.5260622214525809| Ep_r: -6\n",
            "\n",
            "The training process is: The reward is:  -0.7040792497047765\n",
            " The training process is: False \n",
            "False\n",
            "The reward is:  -0.3743655645035816\n",
            "The training process is:  False\n",
            "The reward is:  -0.3659777921171123\n",
            "The training process is: The delivered reward -5.553575956410345\n",
            " False\n",
            "The reward is:  -0.3496340519085949\n",
            "The training process is:  False\n",
            "The reward is:  -0.46657212230967027\n",
            "The training process is:  False\n",
            "The reward is:  -0.4529470113613819\n",
            "The training process is:  False\n",
            "The reward is:  -0.4427971312455382\n",
            "The training process is:  False\n",
            "The reward is:  -0.6163474556103058\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  0.5140861\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.4694102585200889\n",
            "The training process is:  False\n",
            "The reward is:  -0.8363178690387759\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "The reward is:  w_1-0.740419121794513\n",
            "The training process is:   Ep:False \n",
            "150 | Ep_r: -6\n",
            "The reward is:  -0.7505995941295207\n",
            "The training process is:  False\n",
            "The reward is:  -0.7577723694473296\n",
            "The delivered reward -5.548824681909441\n",
            "The training process is:  False\n",
            "The reward is:  -0.6129217409042815\n",
            "The training process is:  False\n",
            "The reward is:  -0.3525033601014595\n",
            "The training process is:  False\n",
            "The reward is:  -0.20818188286984823\n",
            "The training process is:  False\n",
            "The reward is:  -0.21252517523307865\n",
            "The training process is:  False\n",
            "The reward is:  -0.5711299824927426\n",
            "The training process is:  False\n",
            "The reward is:  -0.3869465414355292\n",
            "The training process is:  False\n",
            "The reward is:  -0.5733343997088282\n",
            "The training process is:  False\n",
            "The reward is:  -0.6694274753036362\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 151 | Ep_r: -6\n",
            "The reward is:  -0.4253278830183258\n",
            "The training process is:  False\n",
            "The reward is:  -0.7153475369691632\n",
            "The delivered reward -5.544289860306609\n",
            "The training process is:  False\n",
            "The reward is:  -0.5094780554362546The reward is: \n",
            " The training process is: -0.4652748601531137 \n",
            "FalseThe training process is: \n",
            " False\n",
            "The reward is:  -0.7102802143238709\n",
            "The training process is:  False\n",
            "The reward is:  -0.7398201818795027\n",
            "The training process is:  False\n",
            "The reward is:  -0.5730779030794103\n",
            "The training process is:  False\n",
            "The reward is:  -0.769580698206454\n",
            "The training process is:  False\n",
            "The reward is:  -0.7730795119614182\n",
            "The training process is:  False\n",
            "The reward is:  -0.7088676301793693\n",
            "The training process is:  False\n",
            "The reward is:  -0.5292885372048088\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 152 | Ep_r: -6\n",
            "The reward is:  -0.6177067809274767The reward is: \n",
            " -0.48807016738457454\n",
            "The training process is:  False\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.4241999The delivered reward -5.552946411273298\n",
            "\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.20262177067150922\n",
            "The training process is:  False\n",
            "The reward is:  -0.023254854460485676\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 153 | Ep_r: -6\n",
            "The reward is:  -0.21875715108480837\n",
            "The training process is:  False\n",
            "The reward is:  The delivered reward -5.505852781221159\n",
            "-0.21129876105617146\n",
            "The training process is:  False\n",
            "The reward is:  -0.42185223203067695\n",
            "The training process is:  The reward is: False \n",
            "-0.5295001515547832\n",
            "The reward is: The training process is:   -0.20034907668367855\n",
            "False\n",
            "The training process is:  False\n",
            "The reward is:  -0.5602574443222046\n",
            "The training process is:  False\n",
            "The reward is:  -0.5505800778825933\n",
            "The training process is:  False\n",
            "The reward is:  0.032972415456882544\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 154 | Ep_r: -5\n",
            "The reward is:  -0.6296143439781536\n",
            "The training process is:  False\n",
            "The reward is: The delivered reward -5.47209547668498\n",
            " -0.6217529773275374\n",
            "The training process is:  False\n",
            "The reward is:  -0.644408938821507The reward is:  -0.09838140970085023\n",
            "The training process is: \n",
            " The training process is: False\n",
            " True\n",
            "The reward is: ******** sync has started ******** \n",
            "****** sync is finished **********\n",
            "-0.5158394626657581\n",
            "w_0The training process is:   Ep: False\n",
            "155 The reward is: | Ep_r: -5 \n",
            "-0.5942390998385625\n",
            "The training process is:  False\n",
            "The reward is:  -0.4464133625017405\n",
            "The training process is:  FalseThe delivered reward -5.453712669034274\n",
            "\n",
            "The reward is:  -0.5765229676542234\n",
            "The training process is:  False\n",
            "The reward is:  -0.46211328761855774\n",
            "The training process is:  False\n",
            "The reward is:  -0.37792540567944616\n",
            "The training process is:  False\n",
            "The reward is:  -0.6155579825334367\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 156 | Ep_r: -5\n",
            "The reward is:  -1.0\n",
            "The training process is:  FalseThe delivered reward -5.454019420630121\n",
            "\n",
            "The reward is:  -0.8303084853446425\n",
            "The training process is:  False\n",
            "The reward is:  -0.535768389457263\n",
            "The training process is:  False\n",
            "The reward is:  -0.6844062757216045\n",
            "The reward is: The training process is:   -1.0False\n",
            "\n",
            "The training process is: ******** sync has started ******** False\n",
            "v_s_ is: \n",
            " 1.5558506\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.49259324593018494\n",
            "The training process is:  False\n",
            "The reward is:  -0.39621678747228\n",
            "The training process is:  False\n",
            "The reward is:  -0.4971066819251499\n",
            "The training process is:  False\n",
            "The reward is:  -0.40292852059026896\n",
            "The training process is:  False\n",
            "The reward is:  -0.7964196232003322\n",
            "The training process is:  False\n",
            "The reward is:  -0.5116460707291797\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 157 | Ep_r: -5\n",
            "The reward is: The reward is:   -1.0-1.0\n",
            "\n",
            "The training process is: The training process is:   FalseFalse\n",
            "\n",
            "The reward is:  -0.40622367659318154\n",
            "The training process is:  False\n",
            "The delivered reward -5.460953167227529\n",
            "The reward is:  -0.38121007269475377\n",
            "The training process is:  False\n",
            "The reward is:  -0.5409837247034188\n",
            "The training process is:  False\n",
            "The reward is:  -0.54099598288936\n",
            "The training process is:  \n",
            "FalseThe reward is:  -0.578529807235306\n",
            "The training process is:  False\n",
            "The reward is:  -0.8009247954605424\n",
            "The training process is:  False\n",
            "The reward is:  -0.49463144477217236\n",
            "The training process is:  False\n",
            "The reward is:  -0.49262333859878815\n",
            "The training process is:  False\n",
            "The reward is:  -0.4078854316365777\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 158 The reward is:  | Ep_r: -5-1.0\n",
            "\n",
            "The training process is: The reward is:  False \n",
            "-1.0\n",
            "The training process is:  False\n",
            "The delivered reward -5.462783718301094\n",
            "The reward is:  -0.7098123697154934\n",
            "The training process is:  False\n",
            "The reward is:  -0.6201512741457459\n",
            "The training process is:  False\n",
            "The reward is:  -0.5199446985644872\n",
            "The training process is:  False\n",
            "The reward is:  -0.5525322856007959\n",
            "The training process is:  False\n",
            "The reward is:  -0.7404410059473342\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.5759428\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.65529633704445\n",
            "The training process is:  False\n",
            "The reward is:  -0.5108868625782407\n",
            "The training process is:  False\n",
            "The reward is:  -0.6211593670425343\n",
            "The training process is:  False\n",
            "The reward is:  -0.4219447545110254\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********The reward is: \n",
            "w_1 Ep: -0.7024905187350654 159\n",
            "The training process is:   | Ep_r: -5False\n",
            "\n",
            "The reward is:  -0.1629490069738678\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 160 | Ep_r: -5The delivered reward -5.471677570669584\n",
            "The delivered reward -5.418590285032627\n",
            "\n",
            "The reward is:  -0.814379872705902\n",
            "The training process is:  False\n",
            "The reward is:  -0.5682169784486049\n",
            "The training process is:  False\n",
            "The reward is:  -0.5759861139738464\n",
            "The training process is:  False\n",
            "The reward is:  -0.47999018162129187\n",
            "The training process is:  False\n",
            "The reward is:  -0.5003397928036162\n",
            "The training process is:  False\n",
            "The reward is: The reward is:  -0.5139086704041688 -0.46904257664314886\n",
            "The training process is: \n",
            " FalseThe training process is:  \n",
            "FalseThe reward is: \n",
            " -0.26456815472204354\n",
            "The training process is:  False\n",
            "The reward is:  -0.6610424093042289\n",
            "The training process is:  False\n",
            "The reward is:  -0.501697445909638\n",
            "The training process is:  False\n",
            "The reward is:  -0.4396703786436621\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 161 | Ep_r: -5\n",
            "The reward is:  -0.6996972965883834\n",
            "The training process is:  False\n",
            "The reward is:  -0.6117070141108443\n",
            "The training process is:  False\n",
            "The delivered reward -5.4171537212300604\n",
            "The reward is:  -0.8218522320306769\n",
            "The training process is:  False\n",
            "The reward is:  -0.8156100632397758\n",
            "The training process is:  False\n",
            "The reward is:  The reward is: -0.6728058162510332 \n",
            "-0.5086054302919856The training process is: \n",
            " The training process is: False \n",
            "FalseThe reward is: \n",
            " -0.5801449001504494\n",
            "The training process is:  False\n",
            "The reward is:  -0.5694063587786136\n",
            "The training process is:  False\n",
            "The reward is:  -0.6777544837297993\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  0.5172017\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.29530651299611066\n",
            "The training process is:  False\n",
            "The reward is:  -0.40992319222880924\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 162 | Ep_r: -5\n",
            "The reward is:  -0.7982690855743779\n",
            "The training process is:  False\n",
            "The reward is:  The reward is: -0.6The delivered reward -5.424524262718805\n",
            " \n",
            "-0.5029794663084202\n",
            "The training process is:  False\n",
            "The training process is:  False\n",
            "The reward is:  -0.8358354730195042\n",
            "The training process is:  False\n",
            "The reward is:  -0.523393719503073\n",
            "The training process is:  False\n",
            "The reward is:  0.014174567360072544\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 163 | Ep_r: -5\n",
            "The reward is:  -0.8513487346245073\n",
            "The training process is:  False\n",
            "The delivered reward -5.397712257198985\n",
            "The reward is:  -0.26690063874103265\n",
            "The training process is:  False\n",
            "The reward is: The reward is:   -0.8483238478400746-0.5217971467150692\n",
            "\n",
            "The training process is: The training process is:  False False\n",
            "******** sync has started ********\n",
            "\n",
            "v_s_ is: The reward is:   -0.84812836043884641.5257288\n",
            "\n",
            "The training process is:  ****** sync is finished **********False\n",
            "\n",
            "The reward is:  -0.7079551822159361\n",
            "The training process is:  False\n",
            "The reward is:  -0.37238803970450246\n",
            "The training process is:  False\n",
            "The reward is:  -0.43689403729586507\n",
            "The training process is:  False\n",
            "The reward is:  -0.2798115670645972\n",
            "The training process is:  False\n",
            "The reward is:  -0.367978465290612\n",
            "The training process is:  False\n",
            "The reward is:  -0.4824287286905028\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 164 | Ep_r: -5\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.6618570812392915\n",
            "The training process is:  False\n",
            "The delivered reward -5.39835671064606\n",
            "The reward is: The reward is:   -0.5323971429206068\n",
            "-0.47012512593481304The training process is: \n",
            " False\n",
            "The training process is:  False\n",
            "The reward is:  -0.31177695530264277\n",
            "The training process is:  False\n",
            "The reward is:  -0.29813415822379524\n",
            "The training process is:  False\n",
            "The reward is:  -0.4186752879422862\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.5879254\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.41126460945215637\n",
            "The training process is:  False\n",
            "The reward is:  -0.4062196437380294\n",
            "The training process is:  False\n",
            "The reward is:  -0.5996508723613487\n",
            "The training process is:  False\n",
            "The reward is:  -0.5504533127961706\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 165 | Ep_r: -5\n",
            "The reward is:  -0.5971338690763879\n",
            "The training process is:  False\n",
            "The reward is:  -0.4183885947378008\n",
            "The training process is:  False\n",
            "The delivered reward -5.396277434179362\n",
            "The reward is:  -0.5543866190913234\n",
            "The training process is:  False\n",
            "The reward is:  -0.3365103119746295\n",
            "The training process is:  False\n",
            "The reward is:  The reward is: -0.39368449772493996 -0.4759450180295358\n",
            "The training process is:  False\n",
            "\n",
            "The training process is: The reward is:  False -0.5776047149130057\n",
            "******** sync has started ********\n",
            "The training process is: \n",
            "****** sync is finished ********** \n",
            "Falsew_0\n",
            " The reward is: Ep:  166-0.6941337075983285\n",
            " The training process is: | Ep_r: -5\n",
            " False\n",
            "The reward is:  -0.5143087755141394\n",
            "The training process is:  False\n",
            "The delivered reward -5.408450568398713\n",
            "The reward is:  -0.411240109885342\n",
            "The training process is:  False\n",
            "The reward is:  -0.49968262902290866\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 167 | Ep_r: -5\n",
            "The reward is:  -0.8289342837268823\n",
            "The training process is:  False\n",
            "The reward is:  -0.5522710617171243The delivered reward -5.405159406213159\n",
            "\n",
            "The training process is:  False\n",
            "The reward is:  -0.5352919484101799\n",
            "The training process is:  False\n",
            "The reward is:  -0.15020610459544606\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 168 | Ep_r: -5\n",
            "The reward is: The reward is:  -1.0 \n",
            "-0.5891924690145084\n",
            "The training process is: The training process is:   FalseFalse\n",
            "The reward is: \n",
            " -0.6452018127099727\n",
            "The training process is: The delivered reward -5.371774846135525\n",
            " False\n",
            "The reward is:  -0.7205010206609728\n",
            "The training process is:  False\n",
            "The reward is:  -0.711748507069994\n",
            "The training process is:  False\n",
            "The reward is:  -0.8055517612907156\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.5542673\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.8096939541693933\n",
            "The training process is:  False\n",
            "The reward is:  -0.6713452035866169\n",
            "The training process is:  False\n",
            "The reward is:  -0.5147238378049319\n",
            "The training process is:  False\n",
            "The reward is:  -0.6690071799203524\n",
            "The training process is:  False\n",
            "The reward is:  The reward is: -0.49583001275701166 -0.6458841067973004\n",
            "\n",
            "The training process is:  False\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 169 | Ep_r: -5\n",
            "The reward is:  -0.2772440052220123\n",
            "The training process is:  False\n",
            "The reward is:  -0.29699010225737366\n",
            "The training process is:  FalseThe delivered reward -5.3884931305738695\n",
            "\n",
            "The reward is:  -0.6463349185354714\n",
            "The training process is:  False\n",
            "The reward is:  -0.36097389202139957\n",
            "The training process is:  False\n",
            "The reward is:  -0.41234289407259883\n",
            "The training process is:  False\n",
            "The reward is:  -0.19213640556957973\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 170 | Ep_r: -5\n",
            "The reward is:  -0.8508017154490835\n",
            "The training process is:  False\n",
            "The reward is: The delivered reward -5.356468421444916\n",
            " -0.5990191205263713\n",
            "The training process is:  False\n",
            "The reward is: The reward is:   -0.6592573679761005-0.8439544745287335\n",
            "\n",
            "The training process is: The training process is:   FalseFalse\n",
            "\n",
            "The reward is:  -0.8416000684876007\n",
            "The training process is:  False\n",
            "The reward is:  -0.7466607660255977\n",
            "The training process is:  False\n",
            "The reward is:  -0.746304945786023\n",
            "The training process is:  False\n",
            "The reward is:  -0.8292342204634793\n",
            "The training process is:  False\n",
            "The reward is:  -0.8266328548798441\n",
            "The training process is:  False\n",
            "The reward is:  -0.5679506539981805\n",
            "The training process is:  False\n",
            "The reward is:  -0.7425734130262966\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 171 | Ep_r: -5\n",
            "The reward is:  -0.5552779153307049\n",
            "The training process is:  False\n",
            "The reward is:  The delivered reward -5.378851059562178\n",
            "-0.5452563958021411\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  -0.8907306\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.3327573500158451\n",
            "The training process is:  False\n",
            "The reward is: The reward is:   -0.44518052866682395-0.71586340952587\n",
            "\n",
            "The training process is: The training process is:  False \n",
            "False\n",
            "The reward is:  -0.4084424378864716\n",
            "The training process is:  False\n",
            "The reward is:  -0.732326440582008\n",
            "The training process is:  False\n",
            "The reward is:  -0.7415910724496781\n",
            "The training process is:  False\n",
            "The reward is:  -0.7472969238843636\n",
            "The training process is:  False\n",
            "The reward is:  -0.5350256146812723\n",
            "The training process is:  False\n",
            "The reward is:  -0.15527599902872397\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 172 | Ep_r: -5\n",
            "The reward is:  -0.5670869315783655\n",
            "The training process is:  FalseThe reward is: \n",
            " -0.43290351484738976The reward is: \n",
            "The training process is:  The delivered reward -5.379753684558428\n",
            " -0.4524167019692209\n",
            "FalseThe training process is: \n",
            " False\n",
            "The reward is:  -0.46873102235239406\n",
            "The training process is:  False\n",
            "The reward is:  -0.4330441616390832\n",
            "The training process is:  False\n",
            "The reward is:  -0.4122996012683454\n",
            "The training process is:  False\n",
            "The reward is:  -0.4073440073314968\n",
            "The training process is:  False\n",
            "The reward is:  -0.7178082946230524\n",
            "The training process is:  False\n",
            "The reward is:  -0.5446350308962262\n",
            "The training process is:  False\n",
            "The reward is:  -0.5616224511371664\n",
            "The training process is:  False\n",
            "The reward is:  -0.39354215105596346\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "The reward is: w_1 -0.5702266911708882 \n",
            "The training process is:  Ep:False\n",
            " 173 | Ep_r: -5\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.7622110621812737\n",
            "The training process is:  The delivered reward -5.375541451251356\n",
            "False\n",
            "The reward is:  -0.6117946869599746\n",
            "The training process is:  False\n",
            "The reward is:  -0.5661229977642045\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.5864\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.558382723468716The reward is: \n",
            " The training process is: -0.2908586983226368 \n",
            "FalseThe training process is: \n",
            " FalseThe reward is:  \n",
            "-0.7664046859527891\n",
            "The training process is:  False\n",
            "The reward is:  -0.7851090702913474\n",
            "The training process is:  False\n",
            "The reward is:  -0.6818848617923685\n",
            "The training process is:  False\n",
            "The reward is:  -0.6467405565057156\n",
            "The training process is:  False\n",
            "The reward is:  -0.43765517272679233\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 174 | Ep_r: -5\n",
            "The reward is:  -0.7635201318126408\n",
            "The training process is:  False\n",
            "The reward is:  The delivered reward -5.389949094915274\n",
            "-0.43942453807435944\n",
            "The training process is:  False\n",
            "The reward is:  -0.4768803035871182\n",
            "The training process is:  False\n",
            "The reward is:  -0.7687449693982883\n",
            "The training process is:  False\n",
            "The reward is:  -0.4371461827714743\n",
            "The training process is:  False\n",
            "The reward is:  -0.47422956298443547\n",
            "The training process is:  False\n",
            "The reward is: The reward is:   -0.5024339554601486-0.38797704661370935\n",
            "\n",
            "The training process is:  The training process is:  FalseFalse\n",
            "\n",
            "The reward is:  -0.5601875885447766\n",
            "The training process is:  False\n",
            "The reward is:  -0.4972958832858003\n",
            "The training process is:  False\n",
            "The reward is:  -0.36781849525622984\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 175 | Ep_r: -5\n",
            "The reward is:  -0.8551809420449944\n",
            "The training process is:  False\n",
            "The reward is:  The delivered reward -5.388926420077874\n",
            "-0.8558727054038944\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.5760067981142385\n",
            "The training process is:  False\n",
            "The reward is:  -0.5638838944852195\n",
            "The training process is:  False\n",
            "The reward is:  -0.5565279290743526\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.6489834\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.845740937960492\n",
            "The training process is:  False\n",
            "The reward is:  -0.5377736609190975\n",
            "The training process is:  False\n",
            "The reward is:  -0.6828976296757796\n",
            "The training process is:  False\n",
            "The reward is:  -0.6815300492813048\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 176The reward is:   -0.5494909843227634| Ep_r: -5\n",
            "\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is: The delivered reward -5.4065913013466895\n",
            " -0.7566658778929162\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.6720275841203791\n",
            "The training process is:  False\n",
            "The reward is:  -0.7577113337328164\n",
            "The training process is:  False\n",
            "The reward is:  -0.4062621621994217\n",
            "The training process is:  False\n",
            "The reward is:  -0.4034349079472516\n",
            "The training process is:  False\n",
            "The reward is:  -0.4013640974284655\n",
            "The training process is:  False\n",
            "The reward is:  -0.3480315583476177\n",
            "The training process is:  False\n",
            "The reward is:  -0.3328860168633016\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 177 | Ep_r: -5\n",
            "The reward is:  -1.0\n",
            "The training process is: The reward is:   False-0.5322118960963925\n",
            "\n",
            "The reward is:  The training process is: -1.0 False\n",
            "The training process is: \n",
            " ******** sync has started ********The delivered reward -5.413309223718544\n",
            "False\n",
            "\n",
            "****** sync is finished **********\n",
            "The reward is: w_0 -0.8575819144496648 Ep:\n",
            " The training process is: 178  | Ep_r: -5False\n",
            "\n",
            "The reward is:  -0.8551971039384514\n",
            "The training process is:  False\n",
            "The reward is:  -0.8505783179425717\n",
            "The training process is:  FalseThe delivered reward -5.410207964519644\n",
            "\n",
            "The reward is:  -0.8481283604388464\n",
            "The training process is:  False\n",
            "The reward is:  -0.8456673645847822\n",
            "The training process is:  False\n",
            "The reward is:  -0.8431970767318626\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.5903472\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.838399440782287\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********The reward is: \n",
            " w_1-1.0 \n",
            "Ep:The training process is:   179False \n",
            "| Ep_r: -5\n",
            "The reward is:  -0.4918202860912967\n",
            "The training process is:  False\n",
            "The reward is:  -0.47351571539412074\n",
            "The delivered reward -5.445493380663133\n",
            "The training process is:  False\n",
            "The reward is:  -0.2534586444863211\n",
            "The training process is:  False\n",
            "The reward is:  -0.23202120627881131\n",
            "The training process is:  False\n",
            "The reward is:  -0.39110693219140813\n",
            "The training process is:  False\n",
            "The reward is:  -0.4128701188794427\n",
            "The training process is:  False\n",
            "The reward is:  -0.406279573749541\n",
            "The training process is:  False\n",
            "The reward is:  -0.17669641740135922\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 180 | Ep_r: -5\n",
            "The reward is:  -0.8260340077201456\n",
            "The training process is:  False\n",
            "The reward is:  -0.6793407175761951\n",
            "The training process is:  False\n",
            "The reward is: The delivered reward -5.4194161358012245\n",
            " -0.6770189509764577\n",
            "The training process is:  False\n",
            "The reward is:  -0.4547775750418044\n",
            "The training process is:  False\n",
            "The reward is:  -0.45575116281632805\n",
            "The training process is:  False\n",
            "The reward is:  -0.6700880390687577\n",
            "The training process is:  False\n",
            "The reward is: The reward is:  -1.0 \n",
            "-0.6681794326409858\n",
            "The training process is: The training process is:   False\n",
            "FalseThe reward is: \n",
            " -0.8255513839300976\n",
            "The training process is:  False\n",
            "The reward is:  -0.8258654504428253\n",
            "The training process is:  False\n",
            "The reward is:  -0.8248703298014395\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 181 | Ep_r: -5\n",
            "The reward is:  -0.8517393995286822\n",
            "The training process is:  False\n",
            "The reward is: The delivered reward -5.434296744943363\n",
            " -0.5744085146099573\n",
            "The training process is:  False\n",
            "The reward is:  -0.2818895510638017\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.5834965\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.28685370117702724\n",
            "The training process is:  False\n",
            "The reward is: The reward is:  -0.6199466627047954 \n",
            "-0.20365816247611773The training process is: \n",
            " The training process is: False \n",
            "False\n",
            "The reward is:  -0.14034226602533492\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 182 | Ep_r: -5\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0The delivered reward -5.403342693442738\n",
            "\n",
            "The training process is:  False\n",
            "The reward is:  -0.8553262705062414\n",
            "The training process is:  False\n",
            "The reward is:  -0.8517563377174661\n",
            "The training process is:  False\n",
            "The reward is:  -0.6671840044177786\n",
            "The training process is:  False\n",
            "The reward is:  The reward is: -0.8161624908041226 \n",
            "-0.65654096651713\n",
            "The training process is: The training process is:  False\n",
            " False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.810441508174066\n",
            "The training process is:  False\n",
            "The reward is:  -0.8086344086538932\n",
            "The training process is:  False\n",
            "The reward is:  -0.8078064554582685\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 183 | Ep_r: -5\n",
            "The reward is:  -0.5360759946541934\n",
            "The training process is:  False\n",
            "The reward is:  -0.7012322702262273\n",
            "The delivered reward -5.435482381265629\n",
            "The training process is:  False\n",
            "The reward is:  -0.5734210894522767\n",
            "The training process is:  False\n",
            "The reward is:  -0.571392169645087\n",
            "The training process is:  False\n",
            "The reward is:  -0.5788050816936028\n",
            "The training process is:  False\n",
            "The reward is: The reward is:   -1.0-0.32080421185016716\n",
            "\n",
            "The training process is: The training process is:   FalseFalse\n",
            "\n",
            "The reward is:  -0.3203493522758425\n",
            "The training process is:  False\n",
            "The reward is:  -0.5629575368172977\n",
            "The training process is:  False\n",
            "The reward is:  -0.32689976328720255\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.449178\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.7174649943994015\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 184 | Ep_r: -5\n",
            "The reward is:  -0.7572212105626401\n",
            "The training process is:  False\n",
            "The reward is:  -0.5024117393342789\n",
            "The training process is: The delivered reward -5.433221582095986\n",
            " False\n",
            "The reward is:  -0.21778135332245677\n",
            "The training process is:  False\n",
            "The reward is:  -0.4996911137371193\n",
            "The training process is:  False\n",
            "The reward is:  -0.05817729473582287\n",
            "The training process is: The reward is:   True-0.6027275870465532\n",
            "\n",
            "The training process is:  ******** sync has started ********False\n",
            "\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 185 | Ep_r: -5\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.8014311339567677The delivered reward -5.39924219339195\n",
            "\n",
            "The training process is:  False\n",
            "The reward is:  -0.8035857462335063\n",
            "The training process is:  False\n",
            "The reward is:  -0.8179028032670006\n",
            "The training process is:  False\n",
            "The reward is:  -0.5421932299700922\n",
            "The training process is:  False\n",
            "The reward is:  -0.5436678969404293\n",
            "The training process is:  False\n",
            "The reward is:  -0.5474344058019724\n",
            "The training process is:  False\n",
            "The reward is:  -0.3612153362834782\n",
            "The training process is:  False\n",
            "The reward is:  -0.3578410548754748\n",
            "The training process is:  False\n",
            "The reward is:  -0.39185020339331667\n",
            "The training process is:  FalseThe reward is: \n",
            " -0.5129206022214268\n",
            "******** sync has started ********The training process is: \n",
            " ****** sync is finished **********\n",
            "Falsew_1\n",
            " Ep: 186 | Ep_r: -5\n",
            "The reward is:  -1.0The delivered reward -5.406920989565251\n",
            "\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.7137107584543546\n",
            "The training process is:  False\n",
            "The reward is:  -0.7085217320733979\n",
            "The training process is:  False\n",
            "The reward is:  -0.8574879964424575\n",
            "The training process is:  False\n",
            "The reward is:  -0.8536290919907819\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.5898274\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.35581752536187994\n",
            "The training process is:  False\n",
            "The reward is:  -0.2462465530261741\n",
            "The training process is:  False\n",
            "The reward is:  -0.3220047603898356\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 187 | Ep_r: -5\n",
            "The reward is:  -0.8496081346418407\n",
            "The training process is:  False\n",
            "The reward is: The reward is:   -0.8202562638473025-0.6005889067524265\n",
            "\n",
            "The training process is: The training process is: The delivered reward -5.423425963846987\n",
            "  FalseFalse\n",
            "\n",
            "The reward is:  -0.6612907779044918\n",
            "The training process is:  False\n",
            "The reward is:  -0.6990867185199993\n",
            "The training process is:  False\n",
            "The reward is:  -0.5003639538728527\n",
            "The training process is:  False\n",
            "The reward is:  -0.4932250356376581\n",
            "The training process is:  False\n",
            "The reward is:  -0.6306355637586151\n",
            "The training process is:  False\n",
            "The reward is:  -0.8290497892815212\n",
            "The training process is:  False\n",
            "The reward is:  -0.5319059738711708\n",
            "The training process is:  False\n",
            "The reward is:  -0.6090342393233414\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 188 | Ep_r: -5\n",
            "The reward is:  -0.567855205804459\n",
            "The training process is:  False\n",
            "The reward is:  -0.7787930618158627\n",
            "The training process is:  False\n",
            "The delivered reward -5.435436268715105\n",
            "The reward is:  -0.7752265143724429\n",
            "The training process is:  False\n",
            "The reward is:  -0.4412718535089459\n",
            "The training process is:  False\n",
            "The reward is:  -0.45264114423526725\n",
            "The training process is:  False\n",
            "The reward is: The reward is:   -0.26535250930803284\n",
            "-0.41732768813966575\n",
            "The training process is: The training process is:  False False\n",
            "\n",
            "The reward is:  -0.4314641432525688\n",
            "The training process is:  False\n",
            "The reward is:  -0.4310655841278672\n",
            "The training process is:  False\n",
            "The reward is:  -0.40384654260522285\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.6480094\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.6171673774852084\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 189 | Ep_r: -5\n",
            "The reward is:  -0.5991319677871225\n",
            "The training process is:  False\n",
            "The reward is:  -0.47466524568775414\n",
            "The training process is:  The delivered reward -5.432728745393113\n",
            "False\n",
            "The reward is:  -0.46901819796148825\n",
            "The training process is:  False\n",
            "The reward is:  -0.31936976732888855\n",
            "The training process is:  False\n",
            "The reward is:  -0.15732295775059518\n",
            "The reward is:  -0.4173883225529863\n",
            "The training process is:  FalseThe training process is: \n",
            "******** sync has started ******** \n",
            "True\n",
            "****** sync is finished **********\n",
            "******** sync has started ********w_0\n",
            " Ep:****** sync is finished **********\n",
            " w_1190  Ep: | Ep_r: -5191 \n",
            "| Ep_r: -5\n",
            "The reward is:  -0.7663963596518234\n",
            "The training process is:  False\n",
            "The delivered reward -5.4466758652985305\n",
            "The delivered reward -5.412404188010703\n",
            "The reward is:  -0.46889110074510354\n",
            "The training process is:  False\n",
            "The reward is:  -0.46208121195267465\n",
            "The training process is:  False\n",
            "The reward is:  -0.7314758031191635\n",
            "The training process is:  False\n",
            "The reward is:  -0.7298026037534184\n",
            "The training process is:  False\n",
            "The reward is:  -0.4328206935848954\n",
            "The training process is:  False\n",
            "The reward is:  -0.351477768009841\n",
            "The training process is:  False\n",
            "The reward is: The reward is:   -0.6123657087824916-0.8359826255153134\n",
            "The training process is: \n",
            "The training process is:   FalseFalse\n",
            "\n",
            "The reward is: ******** sync has started ********\n",
            " -0.6167195619074133v_s_ is:  \n",
            "1.5941654The training process is: \n",
            " ****** sync is finished **********False\n",
            "\n",
            "The reward is:  -0.4667443768997372\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 192 | Ep_r: -5\n",
            "The reward is:  -0.4881333943671435\n",
            "The training process is:  False\n",
            "The reward is:  -0.5854470839641344\n",
            "The training process is:  FalseThe delivered reward -5.414667898014661\n",
            "\n",
            "The reward is:  -0.8035857462335063\n",
            "The training process is:  False\n",
            "The reward is:  -0.8070314068682762\n",
            "The training process is:  False\n",
            "The reward is:  -0.44096731631997504The reward is: \n",
            " The training process is: -0.6618570812392915 False\n",
            "The training process is: \n",
            " FalseThe reward is: \n",
            " -0.6205354491453278\n",
            "The training process is:  False\n",
            "The reward is:  -0.6452671042845446\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.5898929\n",
            "****** sync is finished **********\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.7564798285828733\n",
            "The training process is:  False\n",
            "The reward is:  -0.7571597141911911\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 193 | Ep_r: -5\n",
            "The reward is: The reward is:   -0.4388935385142029\n",
            "-0.4668933214697155\n",
            "The training process is: The training process is:  False False\n",
            "\n",
            "The delivered reward -5.429567289474084\n",
            "The reward is:  -0.3607320930427787\n",
            "The training process is:  False\n",
            "The reward is:  -0.38170125108314534\n",
            "The training process is:  False\n",
            "The reward is:  -0.5483200422138819\n",
            "The training process is:  False\n",
            "The reward is:  -0.6619654283077712\n",
            "The training process is:  False\n",
            "The reward is:  -0.6630856343097273\n",
            "The training process is:  False\n",
            "The reward is:  -0.476793434884246\n",
            "The training process is:  False\n",
            "The reward is:  -0.6937080969399076\n",
            "The training process is:  False\n",
            "The reward is:  -0.4428032023647872\n",
            "The training process is:  False\n",
            "The reward is:  -0.4619931766303512\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "The reward is: ****** sync is finished **********\n",
            " -0.5754573812682079\n",
            "w_1 The training process is: Ep:  False194\n",
            " | Ep_r: -5\n",
            "The reward is:  -0.8418912709677414\n",
            "The training process is:  False\n",
            "The reward is:  The delivered reward -5.426851573391807\n",
            "-0.7366785877286957\n",
            "The training process is:  False\n",
            "The reward is:  -0.4167478956402172\n",
            "The training process is:  False\n",
            "The reward is:  -0.28462023375484446\n",
            "The training process is:  False\n",
            "The reward is:  -0.1200015362696126\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 195 | Ep_r: -5\n",
            "The reward is:  -0.7632941396128125\n",
            "The training process is:  False\n",
            "The reward is:  The delivered reward -5.3965824529015\n",
            "-0.6535010540966951\n",
            "The training process is:  False\n",
            "The reward is:  -0.5580797063555698\n",
            "The training process is:  False\n",
            "The reward is:  -0.4943254131952452\n",
            "The training process is:  False\n",
            "The reward is:  -0.24422002518577637\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  0.4946147\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.3959583471825577\n",
            "The training process is:  False\n",
            "The reward is: The reward is:   -0.6957688159191979-0.3536780739535133\n",
            "\n",
            "The training process is:  FalseThe training process is:  False\n",
            "\n",
            "The reward is:  -0.7113164868802978\n",
            "The training process is:  False\n",
            "The reward is:  -0.39111298981773657\n",
            "The training process is:  False\n",
            "The reward is:  -0.8161624908041226\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 196 | Ep_r: -5\n",
            "The reward is:  -0.5396930329923032\n",
            "The training process is:  False\n",
            "The reward is:  -0.5881968557585137\n",
            "The training process is:  The delivered reward -5.396433115643329\n",
            "False\n",
            "The reward is:  -0.5329440493699837\n",
            "The training process is:  False\n",
            "The reward is:  -0.3096353165437065\n",
            "The training process is:  False\n",
            "The reward is:  -0.3340138751350379\n",
            "The training process is:  False\n",
            "The reward is:  -0.0536807420628004\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 197 | Ep_r: -5\n",
            "The reward is: The reward is:   -0.7049620475195081-0.2971860964170147\n",
            "\n",
            "The training process is: The training process is:   FalseFalse\n",
            "\n",
            "The reward is:  -1.0\n",
            "The delivered reward -5.366050423205519\n",
            "The training process is:  False\n",
            "The reward is:  -0.5120783734456926\n",
            "The training process is:  False\n",
            "The reward is:  -0.1356503858282494\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 198 | Ep_r: -5\n",
            "The reward is:  -0.5063196011488269\n",
            "The training process is:  False\n",
            "The reward is:  -0.5034747207677766\n",
            "The delivered reward -5.331839067530374\n",
            "The training process is:  False\n",
            "The reward is:  -0.7416318160636497\n",
            "The training process is:  False\n",
            "The reward is:  -0.21475927428290387\n",
            "The training process is:  False\n",
            "The reward is:  -0.4930406706232572\n",
            "The training process is:  False\n",
            "The reward is:  -0.5149602466669887\n",
            "The training process is:  False\n",
            "The reward is:  -0.621391807083229\n",
            "The training process is:  False\n",
            "The reward is:  -0.6262809743354869\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.610039\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.4855716682403429\n",
            "The training process is:  False\n",
            "The reward is:  -0.8219794383947894\n",
            "The training process is:  False\n",
            "The reward is: ******** sync has started ******** \n",
            "-0.7128528460098783****** sync is finished **********\n",
            "\n",
            "w_1The training process is:   Ep:False \n",
            "199 | Ep_r: -5\n",
            "The reward is:  -0.8430446536925562\n",
            "The training process is:  False\n",
            "The reward is: The delivered reward -5.333814779031143\n",
            " -0.6065175287158573\n",
            "The training process is:  False\n",
            "The reward is:  -0.6027598899842532\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.5417489969089183\n",
            "The training process is:  False\n",
            "The reward is:  -0.4185674300798995\n",
            "The training process is:  False\n",
            "The reward is:  -0.21190722984730098\n",
            "The training process is:  False\n",
            "The reward is:  -0.2287640914460421\n",
            "The training process is: The reward is:   -0.583792097268757False\n",
            "\n",
            "The training process is:  FalseThe reward is: \n",
            " -0.320336970068928\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 200 | Ep_r: -5\n",
            "The reward is:  -0.7326199467154881\n",
            "The training process is:  False\n",
            "The reward is:  -0.270105954516232\n",
            "The training process is:  FalseThe delivered reward -5.338213099148269\n",
            "\n",
            "The reward is:  -0.6178602881097185\n",
            "The training process is:  False\n",
            "The reward is:  -0.5191913107137652\n",
            "The training process is:  False\n",
            "The reward is:  -0.34543346762358024\n",
            "The training process is:  False\n",
            "The reward is:  -0.21730288454464003\n",
            "The training process is:  The reward is:  -0.5252937810505116False\n",
            "\n",
            "The training process is: The reward is:  False \n",
            "-0.43482474663853105\n",
            "The training process is:  False\n",
            "The reward is:  -0.5043906959740927\n",
            "The training process is:  False\n",
            "The reward is:  -0.32592672245319537\n",
            "The training process is:  False\n",
            "The reward is:  -0.6626724418239325\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 201 | Ep_r: -5\n",
            "The reward is:  -0.7791585924033405\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.5894055\n",
            "****** sync is finished **********\n",
            "The delivered reward -5.331134252747918\n",
            "The reward is:  -0.6429839297220286\n",
            "The training process is:  False\n",
            "The reward is:  -0.8114754445719864\n",
            "The training process is:  False\n",
            "The reward is:  -0.8155268391454016\n",
            "The training process is:  False\n",
            "The reward is:  -0.6159482966981459\n",
            "The training process is:  False\n",
            "The reward is:  -0.20276672595014925\n",
            "The training process is:  False\n",
            "The reward is:  -0.020167196192593283\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 202 | Ep_r: -5\n",
            "The reward is:  -0.5568283077108326\n",
            "The training process is:  False\n",
            "The reward is:  -0.560716516160955\n",
            "The delivered reward -5.316703180467275\n",
            "The training process is:  False\n",
            "The reward is:  -0.7567896490893853\n",
            "The training process is:  False\n",
            "The reward is:  -0.5651734681589151\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.472231607461236\n",
            "The training process is:  False\n",
            "The reward is:  -0.3272745812085291\n",
            "The training process is:  False\n",
            "The reward is:  -0.681947143958735\n",
            "The training process is:  False\n",
            "The reward is:  -0.5459339694697585\n",
            "The training process is:  False\n",
            "The reward is:  -0.8225869758032627\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 203 | Ep_r: -5\n",
            "The reward is:  -0.5931543531359195\n",
            "The training process is:  False\n",
            "The reward is:  -0.6435091356200824\n",
            "The training process is:  False\n",
            "The delivered reward -5.326430970852819\n",
            "The reward is:  -0.7234289469939963\n",
            "The training process is:  False\n",
            "The reward is:  -0.7508502941657939\n",
            "The training process is:  False\n",
            "The reward is:  -0.7435112415299521\n",
            "The training process is:  False\n",
            "The reward is:  -0.5474097573141157\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  -0.5830998\n",
            "****** sync is finished **********The reward is: \n",
            " -0.5058427047333351\n",
            "The training process is:  FalseThe reward is: \n",
            " ******** sync has started ********-0.3527289324284105\n",
            "\n",
            "The training process is: ****** sync is finished ********** \n",
            "Falsew_0\n",
            " Ep: 204The reward is:  -0.6084599674461637\n",
            "The training process is:   False\n",
            "| Ep_r: -5The reward is:  \n",
            "-0.5107941102961391\n",
            "The training process is:  False\n",
            "The reward is: The delivered reward -5.335573690334672\n",
            " -1.0\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 205 | Ep_r: -5\n",
            "The reward is:  -0.4755304018058193\n",
            "The training process is:  False\n",
            "The reward is:  -0.46364957125742273\n",
            "The delivered reward -5.346956420820631\n",
            "The training process is:  False\n",
            "The reward is:  -0.3201889033642794\n",
            "The training process is:  False\n",
            "The reward is:  -0.43495927133610846\n",
            "The training process is:  False\n",
            "The reward is:  -0.580573075324814\n",
            "The training process is:  False\n",
            "The reward is:  -0.49390123999157076\n",
            "The training process is:  False\n",
            "The reward is:  -0.4037865281587504\n",
            "The training process is:  False\n",
            "The reward is:  -0.23277959677509236\n",
            "The training process is:  False\n",
            "The reward is:  -0.824355356018309\n",
            "The training process is:  False\n",
            "The reward is:  -0.4406043243580795\n",
            "The training process is:  False\n",
            "The reward is:  -0.42129431112634963\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 206 | Ep_r: -5\n",
            "The reward is:  -0.6086601113537444\n",
            "The training process is:  False\n",
            "The delivered reward -5.339464070007676\n",
            "The reward is:  -0.7577113337328164\n",
            "The training process is:  False\n",
            "The reward is: The reward is:  -0.5227096117955379 -0.7579551723985605\n",
            "\n",
            "The training process is:  The training process is: False\n",
            " The reward is: False\n",
            " -0.7611117486936149\n",
            "The training process is:  False\n",
            "The reward is:  -0.8358985747529075\n",
            "The training process is:  False\n",
            "The reward is:  -0.833592002284132\n",
            "The training process is:  False\n",
            "The reward is:  -0.8324770440863641\n",
            "The training process is:  False\n",
            "The reward is:  -0.8303311720723299\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.5925994\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.8293032628220433\n",
            "The training process is:  False\n",
            "The reward is:  -0.8273450756106833\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 207 | Ep_r: -5\n",
            "The reward is: The reward is:  -0.7630535457988659\n",
            " The training process is:  -0.41242587989579577False\n",
            "\n",
            "The training process is:  False\n",
            "The reward is:  -0.20100763373593064\n",
            "The training process is: The delivered reward -5.36481328428567\n",
            " False\n",
            "The reward is:  -0.4976503378300595\n",
            "The training process is:  False\n",
            "The reward is:  -0.22781903224160976\n",
            "The training process is:  False\n",
            "The reward is:  -0.7500593750388516\n",
            "The training process is:  False\n",
            "The reward is:  -0.20931263511267278\n",
            "The training process is:  False\n",
            "The reward is:  -0.03435793851249678\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 208 | Ep_r: -5\n",
            "The reward is:  -0.5842442057425675\n",
            "The training process is:  False\n",
            "The reward is:  -0.4515577967414302\n",
            "The training process is:  False\n",
            "The delivered reward -5.334491479766488\n",
            "The reward is: The reward is:   -0.6561626278831751\n",
            "The training process is: -0.7609356693674436 False\n",
            "\n",
            "The training process is: The reward is:   False-0.6501514049354249\n",
            "\n",
            "The training process is:  False\n",
            "The reward is:  -0.46828731461512146\n",
            "The training process is:  False\n",
            "The reward is:  -0.28088857841358716\n",
            "The training process is:  False\n",
            "The reward is:  -0.3853653320043592\n",
            "The training process is:  False\n",
            "The reward is:  -0.5233030425647719\n",
            "The training process is:  False\n",
            "The reward is:  -0.6165899525810096\n",
            "The training process is:  False\n",
            "The reward is:  -0.5009853742787455\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 209 | Ep_r: -5\n",
            "The reward is:  -0.6686013836129527\n",
            "The training process is:  False\n",
            "The reward is: The reward is: The delivered reward -5.332321921266424\n",
            "  -0.47220708658075294-0.6935175060854271\n",
            "\n",
            "The training process is: The training process is:   FalseFalse\n",
            "\n",
            "The reward is:  -0.5765609673364451\n",
            "The training process is:  False\n",
            "The reward is:  -0.14799746377535758\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 210 | Ep_r: -5\n",
            "The reward is:  -0.8239110533901813\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is: The delivered reward -5.2998654752618615\n",
            " 1.5910032\n",
            "****** sync is finished **********The reward is: \n",
            "The reward is:   -0.6586063666861954\n",
            "-0.19475828286172578The training process is: \n",
            " The training process is: False \n",
            "The reward is: True\n",
            " ******** sync has started ********-0.6541241199616851\n",
            "\n",
            "****** sync is finished **********The training process is: \n",
            "w_0  Ep:False\n",
            " 211The reward is:  -0.7343175901655858 \n",
            "The training process is:  False\n",
            "| Ep_r: -5The reward is:  -0.7310329587559916\n",
            "The training process is:  False\n",
            "\n",
            "The reward is:  -0.6645809773627789\n",
            "The training process is:  False\n",
            "The reward is:  The delivered reward -5.278942474873202\n",
            "-0.7277725327674397\n",
            "The training process is:  False\n",
            "The reward is:  -0.654077784006117\n",
            "The training process is:  False\n",
            "The reward is:  -0.6466518312257096\n",
            "The training process is:  False\n",
            "The reward is:  -0.529904665251963\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 212 | Ep_r: -5\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  The delivered reward -5.294402848920207\n",
            "False\n",
            "The reward is:  -1.0\n",
            "The training process is:  The reward is: False \n",
            "-0.8291420627523813The reward is: \n",
            "The training process is:  False \n",
            "-0.6\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.4584527320516091\n",
            "The training process is:  False\n",
            "The reward is:  -0.23369398241011438\n",
            "The training process is:  False\n",
            "The reward is:  -0.2284624429799842\n",
            "The training process is:  False\n",
            "The reward is:  -0.1436402513276181\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 213 | Ep_r: -5\n",
            "The reward is:  -0.6\n",
            "The training process is:  False\n",
            "The reward is:  -0.6\n",
            "The training process is:  False\n",
            "The delivered reward -5.298101314518698\n",
            "The reward is:  -0.6205354491453278\n",
            "The training process is:  False\n",
            "The reward is:  -0.16193232034154606\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 214 The reward is: | Ep_r: -5\n",
            " -0.45175633771746604\n",
            "The training process is: The reward is:   False-0.8260580556913085\n",
            "\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.6355458The delivered reward -5.26494497906838\n",
            "\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.7165347275054856\n",
            "The training process is:  False\n",
            "The reward is:  -0.6713669207224111\n",
            "The training process is:  False\n",
            "The reward is:  -0.2711829230213786\n",
            "The training process is:  False\n",
            "The reward is:  -0.41726204675194084\n",
            "The training process is:  False\n",
            "The reward is:  -0.24500024350371943\n",
            "The training process is:  False\n",
            "The reward is:  -0.6651659590420742\n",
            "The training process is:  False\n",
            "The reward is:  -0.5299292926731212\n",
            "The training process is:  False\n",
            "The reward is:  -0.5114571814309233\n",
            "The training process is:  False\n",
            "The reward is:  -0.3682299197200897The reward is: \n",
            " The training process is:  -0.8481461535461966\n",
            "False\n",
            "******** sync has started ********\n",
            "The training process is: ****** sync is finished **********\n",
            " Falsew_1 \n",
            "Ep: 215 | Ep_r: -5\n",
            "The reward is:  -0.8545152204860378\n",
            "The training process is:  False\n",
            "The reward is:  -0.8511270000710927\n",
            "The training process is:  False\n",
            "The delivered reward -5.264517401978321\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.8471971172285857\n",
            "The training process is:  False\n",
            "The reward is:  -0.4466725871831261\n",
            "The training process is:  False\n",
            "The reward is:  -0.44342511864506456\n",
            "The training process is:  False\n",
            "The reward is:  -0.8429874134854861\n",
            "The training process is:  False\n",
            "The reward is:  -0.4425854750528944\n",
            "The training process is:  False\n",
            "The reward is:  -0.8395086035362815\n",
            "The training process is:  False\n",
            "The reward is:  -0.8392077646516081\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 216 | Ep_r: -5\n",
            "The reward is:  The reward is:  -0.4917791406763296-0.29328502328420214\n",
            "\n",
            "The training process is: The training process is:  False\n",
            " False\n",
            "The reward is:  -0.7155648242298042\n",
            "The training process is: The delivered reward -5.285944490961939\n",
            " False\n",
            "The reward is:  -0.7048365823263044\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.5573869\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.6992278433189895\n",
            "The training process is:  False\n",
            "The reward is:  -0.6907595432464515\n",
            "The training process is:  False\n",
            "The reward is:  -0.7420460960490921\n",
            "The training process is:  False\n",
            "The reward is:  -0.7372829548194664\n",
            "The training process is:  False\n",
            "The reward is:  -0.7268073551705231\n",
            "The training process is:  False\n",
            "The reward is:  -0.7215014362397278\n",
            "The training process is:  False\n",
            "The reward is:  -0.6529935480375263\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 217 | Ep_r: -5\n",
            "The reward is:  -0.708030879854344\n",
            "The training process is:  False\n",
            "The reward is:  -0.4419659013259203\n",
            "The delivered reward -5.301913039293463\n",
            "The training process is: The reward is:   -0.14552405140945623False\n",
            "\n",
            "The training process is:  TrueThe reward is: \n",
            " ******** sync has started ********\n",
            "-0.6855585791877747\n",
            "****** sync is finished **********The training process is: \n",
            "w_0 Ep: False \n",
            "The reward is: 218  -1.0| Ep_r: -5\n",
            "\n",
            "The training process is:  False\n",
            "The reward is:  -0.5625109230004959\n",
            "The training process is:  False\n",
            "The delivered reward -5.274572445187625\n",
            "The reward is:  -0.5508061412066556\n",
            "The training process is:  False\n",
            "The reward is:  -0.18135860358927475\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 219 | Ep_r: -5\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.3870779146481678\n",
            "The training process is: The delivered reward -5.263129031017393\n",
            " False\n",
            "The reward is:  -0.6570986541403867\n",
            "The training process is:  False\n",
            "The reward is:  -0.37170804911949934The reward is:  \n",
            "-0.7898288305858561\n",
            "The training process is:  False\n",
            "The training process is:  False\n",
            "The reward is:  -0.16532663722721513\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 220 | Ep_r: -5\n",
            "The reward is:  -0.5029899745633344\n",
            "The training process is:  False\n",
            "The reward is:  -0.6313904861540722The delivered reward -5.236309853258572\n",
            "\n",
            "The training process is:  False\n",
            "The reward is:  -0.4369102378710476\n",
            "The training process is:  False\n",
            "The reward is:  -0.6921420395310658\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  -1.0285268\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.5311812646454491\n",
            "The training process is:  False\n",
            "The reward is: The reward is:  -0.3784386522011568 -0.8484302581010873\n",
            "\n",
            "The training process is: The training process is:  False \n",
            "False\n",
            "The reward is:  -0.1408111750485307\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 221 | Ep_r: -5\n",
            "The reward is:  -0.6415820282407434\n",
            "The training process is:  False\n",
            "The reward is:  -0.5205306584354267\n",
            "The training process is:  False\n",
            "The delivered reward -5.2170853930261325\n",
            "The reward is:  -0.5204162117059077\n",
            "The training process is:  False\n",
            "The reward is:  -0.6327440838063806\n",
            "The training process is:  False\n",
            "The reward is:  -0.5254007141865181\n",
            "The training process is:  False\n",
            "The reward is:  -0.5560540483931329\n",
            "The training process is:  FalseThe reward is: \n",
            " -0.8457225514070952The reward is: \n",
            " The training process is: -0.8431018495227711 \n",
            "FalseThe training process is: \n",
            " ******** sync has started ********\n",
            "False\n",
            "v_s_ is:  1.5853096The reward is:  \n",
            "-0.4370732749207068\n",
            "****** sync is finished **********The training process is: \n",
            " False\n",
            "The reward is:  -0.44298858385617346\n",
            "The training process is:  False\n",
            "The reward is:  -0.6208126717542287\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 222 | Ep_r: -5\n",
            "The reward is:  -0.49816032778731756\n",
            "The training process is:  False\n",
            "The reward is:  -0.4955322699310411The delivered reward -5.222321580344091\n",
            "\n",
            "The training process is:  False\n",
            "The reward is:  -0.6520595272989578\n",
            "The training process is:  False\n",
            "The reward is:  -0.8024334422060102\n",
            "The training process is:  False\n",
            "The reward is:  -0.6368350612979218\n",
            "The training process is:  False\n",
            "The reward is:  -0.6274521218191358\n",
            "The training process is:  False\n",
            "The reward is: The reward is:   -0.8449089491501851The training process is: \n",
            "-0.5112128129459251\n",
            " The training process is:  FalseFalse\n",
            "\n",
            "The reward is:  -0.7200883896220998\n",
            "The training process is:  False\n",
            "The reward is:  -0.6566575266742001\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  0.3585275\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.5635856342234037\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 223 | Ep_r: -5\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is: The delivered reward -5.23173853567871\n",
            " False\n",
            "The reward is:  -0.4169131408420409\n",
            "The training process is:  False\n",
            "The reward is:  -0.3433057148210763\n",
            "The training process is:  False\n",
            "The reward is:  -0.5843993685969856\n",
            "The training process is:  False\n",
            "The reward is:  -0.5384300695901294\n",
            "The training process is:  False\n",
            "The reward is:  -0.2870930585138409\n",
            "The training process is:  False\n",
            "The reward is:  -0.4552023211607167\n",
            "The training process is:  False\n",
            "The reward is:  The reward is:  -0.46030509921624174-0.8445548107416372\n",
            "The training process is: \n",
            " The training process is: False \n",
            "False\n",
            "The reward is:  -0.2808039432900039\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 224 | Ep_r: -5\n",
            "The reward is:  -0.5126050599655402\n",
            "The training process is:  False\n",
            "The delivered reward -5.233085677482234\n",
            "The reward is:  -0.5123635531292681\n",
            "The training process is:  False\n",
            "The reward is:  -0.4547936446191475\n",
            "The training process is:  False\n",
            "The reward is:  -0.31799887039462943\n",
            "The training process is:  False\n",
            "The reward is:  -0.4743801087393466\n",
            "The training process is: \n",
            " FalseThe reward is:  -0.313932311647923\n",
            "The training process is:  False\n",
            "The reward is:  -0.4946595048476349\n",
            "The training process is:  False\n",
            "The reward is:  -0.5211943215940534\n",
            "The training process is:  False\n",
            "The reward is: The reward is:  -0.6600244514614799 \n",
            "The training process is:  -1.0False\n",
            "\n",
            "The reward is: The training process is:  False\n",
            " -0.828214060399621\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 225 | Ep_r: -5\n",
            "The reward is:  -0.7250174736429262\n",
            "The training process is:  False\n",
            "The reward is:  -0.5701723445373275\n",
            "The training process is:  The delivered reward -5.231656479575398\n",
            "False\n",
            "******** sync has started ********\n",
            "v_s_ is:  -0.73620856\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.5699444597660518\n",
            "The training process is:  False\n",
            "The reward is:  -0.4589021720488681\n",
            "The training process is:  False\n",
            "The reward is:  -0.5492267618605721\n",
            "The training process is:  False\n",
            "The reward is:  -0.833722066318537\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.5366980472252803\n",
            "The training process is:  False\n",
            "The reward is: The reward is:   -0.4779271150473251\n",
            "-0.8248703298014395The training process is:  \n",
            "FalseThe training process is: \n",
            " False\n",
            "The reward is:  -0.5237647871576724\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 226 | Ep_r: -5\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.7083906568381069\n",
            "The training process is: False \n",
            "The delivered reward -5.24526309920323\n",
            "The reward is:  -0.6997680622338379\n",
            "The training process is:  False\n",
            "The reward is:  -0.6954734151217197\n",
            "The training process is:  False\n",
            "The reward is:  -0.6912145667180074\n",
            "The training process is:  False\n",
            "The reward is:  -0.5081335963945853\n",
            "The training process is:  False\n",
            "The reward is:  -0.829670394506325\n",
            "The training process is:  False\n",
            "The reward is:  The reward is: -1.0\n",
            " The training process is: -0.3702446775560665 \n",
            "FalseThe training process is: \n",
            "The reward is:   False-1.0\n",
            "\n",
            "The training process is:  False\n",
            "The reward is:  -0.8382977711131938\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 227 | Ep_r: -5\n",
            "The reward is:  -0.7879125257724903\n",
            "The training process is:  False\n",
            "The reward is:  -0.8212642240981104\n",
            "The training process is:  FalseThe delivered reward -5.272519952840455\n",
            "\n",
            "The reward is:  -0.8223597385851003\n",
            "The training process is:  False\n",
            "The reward is:  -0.5927406247287812\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  0.6264319\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.6004286150445304\n",
            "The training process is:  False\n",
            "The reward is:  -0.5823956809099968\n",
            "The training process is:  The reward is:  False\n",
            "-0.7591024611358369The reward is: \n",
            "The training process is:  False \n",
            "-0.33546508794698704\n",
            "The training process is:  False\n",
            "The reward is:  -0.40754108911200204\n",
            "The training process is:  False\n",
            "The reward is:  -0.3985587579559976\n",
            "The training process is:  False\n",
            "The reward is:  -0.3761205079408755\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 228 | Ep_r: -5\n",
            "The reward is:  -0.4866796584565646\n",
            "The training process is:  False\n",
            "The reward is:  The delivered reward -5.277042621832999\n",
            "-0.48404826850888505\n",
            "The training process is:  False\n",
            "The reward is:  -0.3644185937707681\n",
            "The training process is:  False\n",
            "The reward is:  -0.36337855425629895\n",
            "The training process is:  False\n",
            "The reward is:  -0.23243106827504376\n",
            "The training process is:  False\n",
            "The reward is:  -0.37358939567395594\n",
            "The training process is:  False\n",
            "The reward is:  -0.23691075342581694\n",
            "The training process is:  The reward is: False\n",
            "The reward is:  -0.7549107826635555\n",
            "The training process is:   False-0.7035069104673306\n",
            "\n",
            "The training process is:  ******** sync has started ********False\n",
            "****** sync is finished **********\n",
            "The reward is: \n",
            "w_0  -0.14462962347159197\n",
            "Ep:The training process is:  229  True| Ep_r: -5\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "\n",
            "w_1 Ep: 230 | Ep_r: -5\n",
            "The reward is:  -1.0The delivered reward -5.299628499978556\n",
            "The delivered reward -5.280528143241832\n",
            "\n",
            "The training process is:  False\n",
            "The reward is:  -0.8455199956971068\n",
            "The training process is:  False\n",
            "The reward is:  -0.7898288305858561\n",
            "The training process is:  False\n",
            "The reward is:  -0.06188940219233907\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 231 | Ep_r: -5\n",
            "The reward is:  -1.0\n",
            "The training process is:  The delivered reward -5.254695244094167\n",
            "False\n",
            "The reward is:  -0.39840907626102556The reward is: \n",
            " The training process is: -1.0 \n",
            "False\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.7153475369691632\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.4238716\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.7098123697154934\n",
            "The training process is:  False\n",
            "The reward is:  -0.5539811011326506\n",
            "The training process is:  False\n",
            "The reward is:  -0.16193072719005955\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 232The reward is:  -0.42331121160313856 \n",
            "The training process is: | Ep_r: -5 \n",
            "False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is: The delivered reward -5.253559009003299\n",
            " -0.7899469531576586\n",
            "The training process is:  False\n",
            "The reward is:  -0.7874662291826843\n",
            "The training process is:  False\n",
            "The reward is:  -0.781667527992656\n",
            "The training process is:  False\n",
            "The reward is:  -0.7793406766786177\n",
            "The training process is:  False\n",
            "The reward is:  -0.6329916076382035\n",
            "The training process is:  False\n",
            "The reward is:  -0.5113970303218115\n",
            "The training process is:  False\n",
            "The reward is:  -1.0The reward is:  -0.39631333194394824\n",
            "\n",
            "The training process is:  The training process is: False \n",
            "False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.8295787836266871\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 233 | Ep_r: -5\n",
            "The reward is:  -0.35916235040318345\n",
            "The training process is:  False\n",
            "The reward is:  -0.7523940007829394\n",
            "The delivered reward -5.282147306999249\n",
            "The training process is:  False\n",
            "The reward is:  -0.7518668869046342\n",
            "The training process is:  False\n",
            "The reward is:  -0.7516019022948215\n",
            "The training process is:  False\n",
            "The reward is:  -0.4098545755918409\n",
            "The training process is:  FalseThe reward is: \n",
            " -0.3485529196981235\n",
            "The training process is:  False\n",
            "The reward is:  -0.36590907574841236\n",
            "The training process is:  False\n",
            "The reward is:  -0.11360275554330723\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 234 | Ep_r: -5\n",
            "The reward is:  -0.8342830265091432\n",
            "The training process is:  False\n",
            "The reward is:  -0.800004481624747\n",
            "The training process is:  False\n",
            "The delivered reward -5.263756732843011\n",
            "The reward is:  -0.7927641436657997\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  0.2529418\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.7883963168913954\n",
            "The training process is:  False\n",
            "The reward is: The reward is:   -0.4033270247590933\n",
            "The training process is: -0.7839228147929642 \n",
            "FalseThe training process is:  False\n",
            "\n",
            "The reward is:  -0.6323108194772136\n",
            "The training process is:  False\n",
            "The reward is:  -0.6207564115649106\n",
            "The training process is:  False\n",
            "The reward is:  -0.41869879584022546\n",
            "The training process is:  False\n",
            "The reward is:  -0.40672197733379767\n",
            "The training process is:  False\n",
            "The reward is:  -0.3977823461374575\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 235 | Ep_r: -5\n",
            "The reward is:  -0.7746471743402871\n",
            "The training process is:  False\n",
            "The reward is: The delivered reward -5.2758755768529575\n",
            " -0.6950787579843738\n",
            "The training process is:  False\n",
            "The reward is:  -0.8418912709677416\n",
            "The training process is:  False\n",
            "The reward is:  The reward is:  -0.24969412954599823-0.5858137052752351\n",
            "The training process is: \n",
            " The training process is:  FalseFalse\n",
            "\n",
            "The reward is:  -0.37354622743528093\n",
            "The training process is:  False\n",
            "The reward is:  -0.29905083207141503\n",
            "The training process is:  False\n",
            "The reward is:  -0.44664306601693193\n",
            "The training process is:  False\n",
            "The reward is:  -0.38786020369480384\n",
            "The training process is:  False\n",
            "The reward is:  -0.3476859317119526\n",
            "The training process is:  False\n",
            "The reward is:  -0.5614454947846859\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 236 | Ep_r: -5\n",
            "The reward is:  -0.842681374647379\n",
            "The training process is:  False\n",
            "The reward is:  -0.7278176787303432\n",
            "The training process is:  FalseThe reward is: \n",
            "The delivered reward -5.276253447727255\n",
            " -0.2571247118746896The reward is:  \n",
            "The training process is: -0.6497673537740407 False\n",
            "\n",
            "The training process is:  False\n",
            "The reward is:  -0.7127584121629527\n",
            "The training process is:  False\n",
            "The reward is:  -0.8338518999671644\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.5569038\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.8456673645847822\n",
            "The training process is:  False\n",
            "The reward is:  -0.8431018495227711\n",
            "The training process is:  False\n",
            "The reward is:  -0.8430446536925562\n",
            "The training process is:  False\n",
            "The reward is:  -0.790651720711212\n",
            "The training process is:  False\n",
            "The reward is:  -0.642659064198533\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 237 | Ep_r: -5\n",
            "The reward is:  -0.7485529196981234\n",
            "The training process is:  False\n",
            "The reward is:  -0.7537599139381028The delivered reward -5.300810926969899\n",
            "\n",
            "The training process is:  The reward is: False \n",
            "-0.2529503636166893\n",
            "The reward is:  -0.7702013034015247\n",
            "The training process is:  The training process is: False\n",
            " The reward is:  False\n",
            "-0.5339765047835952\n",
            "The training process is:  False\n",
            "The reward is:  -0.7624976370393091\n",
            "The training process is:  False\n",
            "The reward is:  -0.6054376905395527\n",
            "The training process is:  False\n",
            "The reward is:  -0.5509372474358956\n",
            "The training process is:  False\n",
            "The reward is:  -0.5867685138544717\n",
            "The training process is:  False\n",
            "The reward is:  -0.7485529196981234\n",
            "The training process is:  False\n",
            "The reward is:  -0.7452270076468129\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 238 | Ep_r: -5\n",
            "The reward is:  -0.5210857419428528\n",
            "The training process is:  False\n",
            "The reward is:  -0.8132433228030422\n",
            "The training process is: The delivered reward -5.315861934280555\n",
            " False\n",
            "The reward is:  The reward is:  -0.5013210957596865-0.49243725936153\n",
            "The training process is: \n",
            "The training process is:  False\n",
            " False\n",
            "The reward is:  0.07454921632659187\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 239 | Ep_r: -5\n",
            "The reward is:  -0.6825080602363698\n",
            "The training process is:  False\n",
            "The reward is:  -0.13589202978036982\n",
            "The delivered reward -5.28031432437954\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 240 | Ep_r: -5\n",
            "The reward is:  -0.7418947350132468\n",
            "The training process is:  False\n",
            "The reward is:  -0.7420460960490921\n",
            "The training process is:  False\n",
            "The reward is: The delivered reward -5.235695182035911\n",
            " -0.7424983137547547\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.6320285\n",
            "****** sync is finished **********The reward is: \n",
            " -0.5253586594252136The reward is:  \n",
            "-0.7436529845217341The training process is: \n",
            " The training process is: False \n",
            "False\n",
            "******** sync has started ********\n",
            "The reward is: ****** sync is finished ********** -0.5660412526704558\n",
            "w_0\n",
            " The training process is:  FalseEp:\n",
            " The reward is: 241 -0.5654122363589248 | Ep_r: -5\n",
            "\n",
            "The training process is:  False\n",
            "The reward is:  -0.25546918824814163\n",
            "The training process is:  FalseThe delivered reward -5.221426033655384\n",
            "\n",
            "The reward is:  -0.6620942735097455\n",
            "The training process is:  False\n",
            "The reward is:  -0.5153170037565662\n",
            "The training process is:  False\n",
            "The reward is:  -0.5620153390711862\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 242 | Ep_r: -5\n",
            "The reward is:  -0.7414387683284357\n",
            "The training process is:  False\n",
            "The reward is:  -0.4966321960259025The delivered reward -5.230176187548369\n",
            "\n",
            "The training process is:  False\n",
            "The reward is:  -0.36782343876249535\n",
            "The training process is:  False\n",
            "The reward is:  -0.35492449733343817\n",
            "The training process is:  False\n",
            "The reward is:  -0.4404472027086738\n",
            "The training process is:  FalseThe reward is:  \n",
            "-0.441615520549442The reward is: \n",
            " The training process is: -0.5680148674558826 \n",
            "FalseThe training process is: \n",
            " False\n",
            "The reward is:  -0.8152765981527266\n",
            "The training process is:  False\n",
            "The reward is:  -0.497588672606261\n",
            "The training process is:  False\n",
            "The reward is:  -0.3584807534628481\n",
            "The training process is:  False\n",
            "The reward is:  -0.10545712927139994\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 243 | Ep_r: -5\n",
            "The reward is:  -0.6616310892353743\n",
            "The training process is:  False\n",
            "The reward is:  The delivered reward -5.225335266913966\n",
            "-0.8141539675669662\n",
            "The training process is:  False\n",
            "The reward is:  -0.37574959514470724\n",
            "The training process is:  False\n",
            "The reward is:  -0.027149282794542783\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 244 | Ep_r: -5\n",
            "The reward is:  -0.8189963718736643\n",
            "The training process is:  False\n",
            "The reward is: The reward is:   -0.5923230638707958-0.837396946191331\n",
            "\n",
            "The delivered reward -5.191868753592242\n",
            "The training process is: The training process is:  False \n",
            "False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.5588894\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.8415806137957829\n",
            "The training process is:  False\n",
            "The reward is:  -0.5242616935163429\n",
            "The training process is:  False\n",
            "The reward is:  -0.37787433315814073\n",
            "The training process is:  False\n",
            "The reward is:  -0.3446098294165779\n",
            "The training process is:  False\n",
            "The reward is:  -0.6066311687098324\n",
            "The training process is:  False\n",
            "The reward is:  -0.5160352318782975\n",
            "The training process is:  False\n",
            "The reward is:  -0.8398480689899095\n",
            "The training process is:  False\n",
            "The reward is:  -0.6240704894718689\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 245 | Ep_r: -5\n",
            "The reward is:  -0.7941145853288554\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.5641802174844219The delivered reward -5.203263113526337\n",
            "\n",
            "The training process is:  False\n",
            "The reward is:  -1.0\n",
            "The training process is:  False\n",
            "The reward is:  -0.858328960597845\n",
            "The training process is:  False\n",
            "The reward is:  -0.5614132618338743\n",
            "The training process is:  False\n",
            "The reward is:  -0.7722829321684064\n",
            "The training process is:  False\n",
            "The reward is:  -0.42971056196432256The training process is: \n",
            " False\n",
            "The reward is:  -0.26858885300955737\n",
            "The training process is:  False\n",
            "The reward is:  -0.4875970847219058\n",
            "The training process is:  False\n",
            "The reward is:  -0.6006173771310206\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 246 | Ep_r: -5\n",
            "The reward is:  -0.8264178329014094\n",
            "The training process is:  False\n",
            "The reward is:  -0.5707123741543757\n",
            "The training process is:  False\n",
            "The delivered reward -5.2145988207334755\n",
            "The reward is: The reward is:   -0.18909002411248138\n",
            "0.01309122135369909The training process is:  \n",
            "TrueThe training process is:  \n",
            "True******** sync has started ********\n",
            "\n",
            "****** sync is finished ****************** sync has started ********\n",
            "\n",
            "w_1 ****** sync is finished **********Ep:\n",
            " w_0247  Ep:| Ep_r: -5 \n",
            "248 | Ep_r: -5\n",
            "The reward is:  -0.6402033991199583\n",
            "The training process is:  False\n",
            "The reward is: The delivered reward -5.178315034837823\n",
            "The delivered reward -5.14674035812011\n",
            " -0.5996961090319171\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  1.6366069\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.8032255407682118\n",
            "The training process is:  False\n",
            "The reward is:  -0.7816597978952082\n",
            "The training process is:  False\n",
            "The reward is:  -0.8172550162385811\n",
            "The training process is:  False\n",
            "The reward is:  -0.7828155353479224\n",
            "The training process is:  False\n",
            "The reward is:  -0.6983436265271884\n",
            "The training process is:  False\n",
            "The reward is:  -0.6911804289149249\n",
            "The training process is: The reward is:  False \n",
            "-0.7635201318126408\n",
            "The reward is:  -1.0\n",
            "The training process is:  The training process is:  FalseFalse\n",
            "\n",
            "The reward is:  -0.8268948063346816\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 249 | Ep_r: -5\n",
            "The reward is:  -0.5231301177689054\n",
            "The training process is:  False\n",
            "The reward is:  -0.18629705813769226\n",
            "The delivered reward -5.171685697140695\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_1 Ep: 250 | Ep_r: -5\n",
            "The delivered reward -5.127063111928354\n",
            "The delivered reward None\n",
            "The reward is:  -0.3410673775409145\n",
            "The training process is:  False\n",
            "******** sync has started ********\n",
            "v_s_ is:  -0.263003\n",
            "****** sync is finished **********\n",
            "The reward is:  -0.1695797758529064\n",
            "The training process is:  True\n",
            "******** sync has started ********\n",
            "****** sync is finished **********\n",
            "w_0 Ep: 251 | Ep_r: -5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XcsP_t0m9VVw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}